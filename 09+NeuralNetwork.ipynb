{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络\n",
    "\n",
    "## 一、概念\n",
    "\n",
    "神经网络是时下最热的人工智能话题，而神经网络的历史也由来已久，近年来的算力大爆发使人工智能和神经网络发现了彼此。\n",
    "\n",
    "神经网络通过神经元进行组织，数据从上一层神经元流向下一层神经元直到输出神经元，损失函数衡量预测和输出之间的差距，再通过反向传播更新各层神经元的参数。\n",
    "\n",
    "神经网络由如下元素构成：\n",
    "\n",
    "1. 输入层：数据从输入层进入模型\n",
    "\n",
    "\n",
    "2. 隐藏层：数据在隐藏层中进行交互和组合\n",
    "\n",
    "\n",
    "3. 输出层：输出层输出预测结果\n",
    "\n",
    "\n",
    "4. 激活函数：各个神经元的对上一层的输入进行非线性处理的函数\n",
    "\n",
    "\n",
    "5. 损失函数：衡量预测结果和实际结果的差距\n",
    "\n",
    "\n",
    "6. 优化器：即以何种方式更新参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、符号说明\n",
    "\n",
    "- $X$：输入数据，$X\\in R^{p\\times n}$，p代表变量数，n代表样本数\n",
    "\n",
    "\n",
    "- $\\hat Y$：输出数据，$\\hat Y\\in R^{k\\times n}$，n代表样本数，多分类时k代表分类数，二分类和回归时k为1\n",
    "\n",
    "\n",
    "- $Y$：实际结果，$Y\\in R^{k\\times n}$，n代表样本数，多分类时k代表分类数，二分类和回归时k为1\n",
    "\n",
    "\n",
    "- $p_i$：第i层的神经元数，$p_0=p$\n",
    "\n",
    "\n",
    "- $W_i$：从第i-1层向第i层传播的矩阵，$W_i\\in R^{p_{i}\\times p_{i-1}}$，输入层为第0层时，$W_1\\in R^{p_{1}\\times p}$\n",
    "\n",
    "\n",
    "- $\\alpha(z)$：激活函数，每一层每一个神经元的激活函数都可以不同，此处统一用α\n",
    "\n",
    "\n",
    "- $g(z)$：输出层的激活函数，通常和隐藏层的激活函数不同\n",
    "\n",
    "\n",
    "- $b_i$：第i层的偏置项，$b_i \\in R^{p_{i+1}}$\n",
    "\n",
    "\n",
    "- $Z_i$：上一层激活函数的线性组合，$Z_i \\in R^{p_i\\times n}$\n",
    "\n",
    "\n",
    "- $A_i$：线性组合的激活函数值，$A_i \\in R^{p_i\\times n}$\n",
    "\n",
    "\n",
    "- \\* ：逐元素相乘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、Feed Forward 前向传播\n",
    "\n",
    "### 1.从输入层到第一个隐藏层\n",
    "\n",
    "首先是对输入数据的线性组合，由于偏执项是一个向量，对所有n个数据来说都相等。虽然此处维度按照线性代数并不能严格成立（因为$W_1X\\in R^{p_1\\times n}$，$b_1 \\in R^{p_1\\times 1}$），但是由于numpy中的广播（broadcast）机制存在，在编程中以下公式是成立的。如果非要按照数学定义上成立可以对$b_1$乘上一个$1\\times n$的值全为1的向量。\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "        &Z_1 = W_1X + b_1 \\ \\ \\in R^{p_1\\times n}\\\\\n",
    "    \\Leftrightarrow & Z_1 = W_1X + b_11^{1\\times n}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "然后是对第一层的各个神经元进行“激活”，对线性组合进行逐元素的函数计算\n",
    "\n",
    "$$\n",
    "A_1 = \\alpha(Z_1)\\ \\ \\in R^{p_1\\times n}\n",
    "$$\n",
    "\n",
    "### 2.从第i-1层到第i层\n",
    "\n",
    "与输入不同，此时是将上一层的激活函数值进行线性组合：\n",
    "\n",
    "$$\n",
    "Z_i = W_iA_{i-1} + b_i \\ \\ \\in R^{p_i\\times n}\n",
    "$$\n",
    "\n",
    "$$\n",
    "A_i = \\alpha(Z_i)\\ \\ \\in R^{p_i\\times n}\n",
    "$$\n",
    "\n",
    "### 3.从最后一个隐藏层到输出层\n",
    "\n",
    "假设输入层是第0层，第1——m-1层是隐藏层，第m层是输出层。如果是二分类、回归等情况，则输出层只有一个神经元，若是多分类等情况则有多个神经元，将在后面介绍，暂时假定只有一个输出：\n",
    "\n",
    "$$\n",
    "Z_m = W_m A_{m-1} + b_m \\ \\ \\in R^{k\\times n}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat Y = A_m = g(Z_m)\\ \\ \\in R^{k\\times n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、激活函数\n",
    "\n",
    "激活函数有多种多样，本质上都是为了进行非线性组合，还有易于进行求导运算以便更新参数。此处简单介绍几种激活函数\n",
    "\n",
    "### 1.sigmoid函数\n",
    "\n",
    "Sigmoid函数已经在logistic回归中介绍过：\n",
    "\n",
    "$$\n",
    "sigmoid(z)=\\frac{1}{1+e^{-z}}\n",
    "$$\n",
    "\n",
    "它是一种较早期的激活函数，现在多用于最后输出层的激活而不用在隐藏层中，这是因为当x远离原点时它的梯度会非常接近0，会造成非常著名的“梯度消失”的现象。\n",
    "\n",
    "考虑sigmoid函数的导数：\n",
    "\n",
    "$$\n",
    "\\frac{d}{dz} sigmoid(z)=\\frac{e^{-z}}{(1+e^{-z})^2}\n",
    "$$\n",
    "\n",
    "当z=0时其梯度最大为0.25，当神经网络的层数变深时便是指数倍地降低，这便是“梯度消失”最直观和简洁的解释。\n",
    "\n",
    "### 2.Relu（Rectified Linear Unit, 线性整流函数）\n",
    "\n",
    "Relu也曾是红极一时的激活函数，因其简洁的函数形式和导数形式（x大于零导数为1，其他情况为0）使计算成本大大降低，但同时这也带来了神经元没有被激活的情况。这是因为当输入小于0时，输出和梯度都为0，导致神经元“死亡”。\n",
    "\n",
    "$$\n",
    "Relu(z) = max(0, z)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{d}{dz}Relu(z) = \\begin{cases}\n",
    "1 & z>0 \\\\\n",
    "0 & z\\le 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "### 3.leaky Relu\n",
    "\n",
    "leaky Relu是我最喜欢的激活函数，因为它兼具了Relu的优点，且当输入小于零时不会出现神经元死亡的情况，k通常的设置为0.1。\n",
    "\n",
    "$$\n",
    "leakyRelu(z, k) = max(kz, z)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{d}{dz}leakyRelu(z) = \\begin{cases}\n",
    "1 & z>0 \\\\\n",
    "k & z\\le 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "### 4.softmax\n",
    "\n",
    "softmax是专门用于多分类的输出层的激活函数，有两种等价形式，一种是针对K类有K个输出的线性相关的形式（即下式），另一个是针对K类有K-1个输出的线性无关的形式。\n",
    "\n",
    "$$\n",
    "softmax(z) = \\begin{bmatrix}\n",
    "    \\frac{e^{z_1}}{\\sum_{i=1}^ke^{z_i}}\\\\\n",
    "    \\frac{e^{z_2}}{\\sum_{i=1}^ke^{z_i}}\\\\\n",
    "    ...\\\\\n",
    "    \\frac{e^{z_j}}{\\sum_{i=1}^ke^{z_i}}\\\\\n",
    "    ...\\\\\n",
    "    \\frac{e^{z_k}}{\\sum_{i=1}^ke^{z_i}}\\\\\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "    \\hat y_1\\\\\n",
    "    \\hat y_2\\\\\n",
    "    ...\\\\\n",
    "    \\hat y_i\\\\\n",
    "    ...\\\\\n",
    "    \\hat y_k\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "它的针对单一分量的偏导数形式和sigmoid函数极为相似：\n",
    "\n",
    "1. 当分量出现在分母和分子上上时，我们用$a$表示和第i个分量无关的其他分量和：\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    \\frac{d}{dz_i} \\frac{e^{z_i}}{a+e^{z_i}}&= \\frac{e^{z_i}(a+e^{z_i}) - e^{z_i}e^{z_i}}{(a+e^{z_i})^2} \\\\\n",
    "        &= \\frac{ae^{z_i}+a^2-a^2}{(a+e^{z_i})^2} \\\\\n",
    "        &= \\frac{a(e^{z_i}+a)-a^2}{(a+e^{z_i})^2} \\\\\n",
    "        &= \\frac{a}{a+e^{z_i}} - \\left(\\frac{a}{a+e^{z_i}}\\right)^2 \\\\\n",
    "        &= \\frac{a}{a+e^{z_i}}\\left(1-\\frac{a}{a+e^{z_i}}\\right) \\\\\n",
    "        &= \\left(1-\\frac{e^{z_i}}{a+e^{z_i}}\\right)\\frac{e^{z_i}}{a+e^{z_i}}\\\\\n",
    "        &= (1-\\hat y_i)\\hat y_i\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "2. 而当分量只出现在分母上时，我们用b表示分子上的第j个分量，用a表示与第i、j个分量无关的其他分量的和：\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    \\frac{d}{dz_i} \\frac{b}{a+b+e^{z_i}} &= \\frac{-be^{z_i}}{(a+b+e^{z_i})^2}\\\\\n",
    "        &= \\frac{-b(a+b+e^{z_i})+ab+b^2}{(a+b+e^{z_i})^2}\\\\\n",
    "        &= \\frac{-b}{a+b+e^{z_i}}+\\frac{b(a+b)}{(a+b+e^{z_i})^2} \\\\\n",
    "        &= \\frac{-b}{a+b+e^{z_i}}+\\frac{b}{a+b+e^{z_i}}\\left(1-\\frac{e^{z_i}}{a+b+e^{z_i}}\\right)\\\\\n",
    "        &= -\\hat y_j + \\hat y_j(1-\\hat y_i)\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "按照矩阵的求导法则，$m\\times 1$列向量对$n \\times 1$列向量求导的结果应该是$mn \\times 1$维向量，但是此时为了便于计算，我们将其改写成$m\\times n$的矩阵（或者$n\\times m$，看需求）则它的梯度为：\n",
    "\n",
    "$$\n",
    "\\triangledown softmax(z)=\\begin{bmatrix}\n",
    "    \\hat y_1(1-\\hat y_1) & -\\hat y_2 + \\hat y_2(1-\\hat y_1) & \\dots & -\\hat y_k + \\hat y_k(1-\\hat y_1)\\\\\n",
    "    -\\hat y_1 + \\hat y_1(1-\\hat y_2) & \\hat y_2(1-\\hat y_2) & \\dots & -\\hat y_k + \\hat y_k(1-\\hat y_2)\\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    -\\hat y_1 + \\hat y_1(1-\\hat y_k) & -\\hat y_2 + \\hat y_2(1-\\hat y_k) & \\dots & \\hat y_k(1-\\hat y_k)\\\\\n",
    "\\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五、损失函数\n",
    "\n",
    "二分类和回归的损失函数不再赘述，和logistic回归和多元线性回归类似，这里介绍多分类的损失函数。\n",
    "\n",
    "多分类的损失函数和二分类相同，也是通过似然函数进行定义：假设随机变量Y一共有K个取值，第i个样本对第j个取值的概率估计值为：\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(y_i=j) = \\hat y_{ij} \\ \\ j=1,2,...,k \\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "则对n个样本，其似然函数为：\n",
    "\n",
    "$$\n",
    "likelihood(Y, \\hat Y)=\\prod_{i=1}^n\\prod_{j=1}^k \\hat y_{ij}^{I(y_i=j)}\n",
    "$$\n",
    "\n",
    "对其求自然对数，除以样本数进行标准化取负数：\n",
    "\n",
    "$$\n",
    "loss(Y, \\hat Y) = -\\frac1n\\sum_{i=1}^n \\sum_{j=1}^k I(y_i=j)ln(\\hat y_{ij})\n",
    "$$\n",
    "\n",
    "这就是最终的损失函数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 六、Backward propagation 反向传播\n",
    "\n",
    "反向传播是神经网络更新参数最经典也是最有效、最具有广泛性的算法。\n",
    "\n",
    "反向传播的基础仍然是梯度下降法。\n",
    "\n",
    "### 1.输出层到最后一个隐藏层的反向传播\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial y_{ij}}loss = -\\frac1n\\frac{I(y_i=j)}{\\hat y_{ij}}\n",
    "$$\n",
    "\n",
    "由于输出是$\\hat Y \\in R^{k\\times n}$向量，损失对输出层的梯度和输出保持一致的维度：\n",
    "\n",
    "$$\n",
    "\\frac{\\triangledown loss}{\\triangledown \\hat Y}=\n",
    "-\\frac1n\\begin{bmatrix}\n",
    "    \\frac{I(y_1=1)}{\\hat y_{11}} & \\dots & \\frac{I(y_1=k)}{\\hat y_{1k}}\\\\\n",
    "     & \\ddots & \\vdots \\\\\n",
    "    \\frac{I(y_n=1)}{\\hat y_{n1}} & & \\frac{I(y_n=k)}{\\hat y_{nk}}\n",
    "\\end{bmatrix}^T \\in R^{k\\times n}\n",
    "$$\n",
    "\n",
    "对输出层的激活函数有$\\hat Y_i = g(Z_i)=softmax(Z_i)\\in R^{k\\times 1}$，$Z_i\\in R^{k\\times 1}$\n",
    "\n",
    "$$\n",
    "\\frac{\\triangledown\\hat Y}{\\triangledown Z_i} = \n",
    "\\begin{bmatrix}\n",
    "    \\hat y_{i1}(1-\\hat y_{i1}) & -\\hat y_{i2} + \\hat y_{i2}(1-\\hat y_{i1}) & \\dots & -\\hat y_{ik} + \\hat y_{ik}(1-\\hat y_{i1})\\\\\n",
    "    -\\hat y_{i1} + \\hat y_{i1}(1-\\hat y_{i2}) & \\hat y_{i2}(1-\\hat y_{i2}) & \\dots & -\\hat y_{ik} + \\hat y_{ik}(1-\\hat y_{i2})\\\\\n",
    "    \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "    -\\hat y_{i1} + \\hat y_{i1}(1-\\hat y_{ik}) & -\\hat y_{i2} + \\hat y_{i2}(1-\\hat y_{ik}) & \\dots & \\hat y_{ik}(1-\\hat y_{ik})\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "将这个梯度矩阵乘以$\\frac{\\triangledown loss}{\\triangledown \\hat Y}$与之对应的列，如果$y_i=j$的话，这一列将是：\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    -\\hat y_{i1}\\\\\n",
    "    \\dots \\\\\n",
    "    -\\hat y_{ij-1}\\\\\n",
    "    1-\\hat y_{ij}\\\\\n",
    "    -\\hat y_{ij+1}\\\\\n",
    "    \\dots \\\\\n",
    "    -\\hat y_{ik}\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "结合损失对估计值的梯度前的系数$-\\frac1n$于是恰巧有：\n",
    "\n",
    "$$\n",
    "\\frac{\\triangledown loss}{\\triangledown Z_m} = \\frac1n(\\hat Y - Y)\n",
    "$$\n",
    "\n",
    "此时还未涉及到参数的更新，而$Z_m = W_mA_{m-1} + b_m$中$W_m\\in R^{p_m=k\\times p_{m-1}}$、$b_m\\in R^{k\\times 1}$均为参数。\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    &\\frac{\\triangledown Z_m}{\\triangledown W_m} = A_{m-1}\\in R^{p_{m-1}\\times n}\\\\\n",
    "    \\\\\n",
    "    &\\frac{\\triangledown Z_m}{\\triangledown b_m} = 1^{1\\times n} \\in R^{1\\times n}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "将其和之前的梯度结合起来：\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    \\frac{\\triangledown loss}{\\triangledown W_m} &= \\frac{\\triangledown loss}{\\triangledown Z_m}\\left(\\frac{\\triangledown Z_m}{\\triangledown W_m}\\right)^T =\\frac{\\triangledown loss}{\\triangledown Z_m}A_{m-1}^T \\in R^{p_m=k\\times p_{m-1}}\\\\\n",
    "    \\frac{\\triangledown loss}{\\triangledown b_m} &= \\frac{\\triangledown loss}{\\triangledown Z_m} 1^{n\\times 1}\\in R^{k\\times 1}\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### 2.第i层到第i-1层的反向传播\n",
    "\n",
    "从第i层到第i-1层的反向传播和从输出层到最后一个隐藏层的推导相似：\n",
    "\n",
    "假设$\\frac{\\triangledown loss}{\\triangledown Z_i}\\in R^{p_i\\times n}$已知，又$Z_i = W_i A_{i-1} + b_i$，\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    \\frac{\\triangledown Z_{i}}{\\triangledown A_{i-1}} &= W_{i}^T\\in R^{p_{i-1}\\times p_{i}}\\\\\n",
    "    A_{i-1} &= \\begin{bmatrix}\n",
    "            \\alpha (z_{11}) & \\dots & \\alpha (z_{1p_i})\\\\\n",
    "             & \\ddots & \\vdots \\\\\n",
    "            \\alpha (z_{n1}) & &\\alpha(z_{np_i}) \n",
    "          \\end{bmatrix}\\in R^{p_{i-1}\\times n}\\\\\n",
    "       \\frac{\\triangledown A_{i-1}}{\\triangledown Z_{i-1}}&=\\begin{bmatrix}\n",
    "            \\alpha '(z_{11}) & \\dots & \\alpha '(z_{1p_i})\\\\\n",
    "             & \\ddots & \\vdots \\\\\n",
    "            \\alpha '(z_{n1}) & & \\alpha '(z_{np_i}) \n",
    "       \\end{bmatrix}\\in R^{p_{i-1}\\times n}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "\n",
    "其余部分和之前的相同\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    &\\frac{\\triangledown Z_{i-1}}{\\triangledown W_{i-1}} = A_{i-2}\\in R^{p_{i-2}\\times n}\\\\\n",
    "    \\\\\n",
    "    &\\frac{\\triangledown Z_{i-1}}{\\triangledown b_{i-1}} = 1^{1\\times n} \\in R^{1\\times n}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "于是有：\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    \\frac{\\triangledown loss}{\\triangledown Z_{i-1}} &= W_i^T\\frac{\\triangledown loss}{\\triangledown Z_i}* \\frac{\\triangledown A_{i-1}}{\\triangledown Z_{i-1}}\\in R^{p_{i-1 \\times n}} \\\\\n",
    "    \\\\\n",
    "    \\frac{\\triangledown loss}{\\triangledown W_{i-1}} &= \\frac{\\triangledown loss}{\\triangledown Z_{i-1}} A_{i-2}^T \\in R^{p_{i-1}\\times p_{i-2}} \\\\\n",
    "    \\\\\n",
    "    \\frac{\\triangledown loss}{\\triangledown b_{i-1}} &= \\frac{\\triangledown loss}{\\triangledown Z_{i-1}}1^{n\\times 1}\\in R^{p_{i-1}\\times 1}\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.从第一层到输入层\n",
    "\n",
    "从第1层到输入层的反向传播和从第i层到第i-1层的推导相似，区别在于输入是固定的数据，而不再是激活函数值：\n",
    "\n",
    "假设$\\frac{\\triangledown loss}{\\triangledown Z_2}\\in R^{p_2\\times n}$已知，又$Z_2 = W_2 A_{1} + b_2$，$Z_1 = W_1 X + b_1$\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    \\frac{\\triangledown loss}{\\triangledown Z_{1}} &= W_2^T\\frac{\\triangledown loss}{\\triangledown Z_2}* \\frac{\\triangledown A_{1}}{\\triangledown Z_{1}}\\in R^{p_{1 \\times n}} \\\\\n",
    "    \\\\\n",
    "    \\frac{\\triangledown loss}{\\triangledown W_{1}} &= \\frac{\\triangledown loss}{\\triangledown Z_{1}}X^T \\in R^{p_{1}\\times p_{0}} \\\\\n",
    "    \\\\\n",
    "    \\frac{\\triangledown loss}{\\triangledown b_{1}} &= \\frac{\\triangledown loss}{\\triangledown Z_{1}}1^{n\\times 1}\\in R^{p_{1}\\times 1}\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 七、优化器\n",
    "\n",
    "优化器是指优化得到参数的方法，优化器基本都是基于梯度下降方法。如果你在线性回归中不用正规方程求解参数，而是用梯度下降，你会发现随着梯度不断下降，**梯度不断减小**。而这还不是最麻烦的问题，由于线性回归是凸优化，用梯度下降总会收敛到最小值，而神经网络多是非凸问题，梯度下降很可能会困在局部极值**无法收敛**。而且通常神经网络需要很多的数据进行训练，如果每次都像传统的梯度下降那样把所有数据都传入模型，则**计算成本很大**。\n",
    "\n",
    "这里先介绍**SGD**（Stochastic Gradient Descnet，随机梯度下降）优化器。\n",
    "\n",
    "SGD不再把所有的数据都用来进行梯度下降，而是只用小批量（**mini batch**）数据进行梯度下降，常见的选择是从2的4次方（16）到2的10次方之间，选用2的整数次方是根据计算机比特的特点决定的，而之前推导中梯度进行标准化时除以样本数，此时需要除以一批量的样本数。\n",
    "\n",
    "控制梯度下降停止的条件也有所改变，由于神经网络强大的非线性组合能力，训练到收敛会造成过拟合，于是神经网络中用到最多的是早停法，也即小批量进行训练时将全部样本循环数遍（**epoch**）后就立即停下，避免过拟合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 八、应用\n",
    "\n",
    "这次采用的是minist手写数字数据集，从kaggle的入门赛下载下来的训练数据集，有兴趣的可以把自己训练好的型跑一下kaggle上的测试数据集提交一下看看分数。（排名就不必了看了...）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T07:44:53.314072Z",
     "start_time": "2019-03-24T07:44:44.506333Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv('data_set/minist.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T07:44:55.008875Z",
     "start_time": "2019-03-24T07:44:53.496051Z"
    }
   },
   "outputs": [],
   "source": [
    "n = train_data.shape[0]\n",
    "np.random.seed(2099)\n",
    "index = np.random.permutation(n)\n",
    "train_index = index[0: int(0.7*n)]\n",
    "test_index = index[int(0.7*n): n]\n",
    "\n",
    "test_data = train_data.iloc[test_index]\n",
    "test_label = test_data['label']\n",
    "del test_data['label']\n",
    "test_data = np.array(test_data)\n",
    "test_label = np.array(test_label).reshape([n-int(0.7*n), 1])\n",
    "\n",
    "train_data = train_data.iloc[train_index]\n",
    "train_label = train_data['label']\n",
    "del train_data['label']\n",
    "train_data = np.array(train_data)\n",
    "train_label = np.array(train_label).reshape([int(0.7*n), 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T07:45:02.617684Z",
     "start_time": "2019-03-24T07:45:02.604687Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_category(label, num_classes):\n",
    "    n = label.shape[0]\n",
    "    tmp = np.zeros([n, num_classes])\n",
    "    j = 0\n",
    "    for i in label:\n",
    "        tmp[j, i]=1\n",
    "        j += 1\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T07:45:03.681517Z",
     "start_time": "2019-03-24T07:45:03.666523Z"
    }
   },
   "outputs": [],
   "source": [
    "def soft_max(z):\n",
    "    \"\"\"\n",
    "    :param z: input, an p*n matrix\n",
    "    :return: p*n matrix\n",
    "    \"\"\"\n",
    "    e = np.exp(z)\n",
    "    total = np.sum(e, axis=0, keepdims=True)\n",
    "    weight = e / total\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T07:45:04.542383Z",
     "start_time": "2019-03-24T07:45:04.529386Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(y, y_hat):\n",
    "    y = np.argmax(y, axis=0)\n",
    "    y_hat = np.argmax(y_hat, axis=0)\n",
    "    return sum(y == y_hat)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T07:45:05.217278Z",
     "start_time": "2019-03-24T07:45:05.205281Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss(y, y_hat):\n",
    "    \"\"\"\n",
    "    :param y: the ture value p*n matrix\n",
    "    :param y_hat: the predicted value\n",
    "    :return: loss, it's quite computationally expensive\n",
    "                I once simplify it as np.sum(y*y_hat)\n",
    "    \"\"\"\n",
    "    n = y.shape[1]\n",
    "    tmp = y_hat**y\n",
    "    tmp = -np.log(tmp.prod(axis=0)).sum()/n\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T07:45:05.857177Z",
     "start_time": "2019-03-24T07:45:05.841179Z"
    }
   },
   "outputs": [],
   "source": [
    "def leaky_relu(x, k=0.3):\n",
    "    return (x > 0)*x + k*(x < 0)*x\n",
    "\n",
    "\n",
    "def d_leaky_relu(x, k=0.3):\n",
    "    return (x > 0) + k*(x < 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T07:45:06.504074Z",
     "start_time": "2019-03-24T07:45:06.492077Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_w(b, a):\n",
    "    w = np.random.randn(a * b)\n",
    "    w = np.reshape(w, [b, a])\n",
    "    return w\n",
    "\n",
    "\n",
    "def init_b(b):\n",
    "    b = np.zeros([b, 1])\n",
    "    return b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T07:45:07.130985Z",
     "start_time": "2019-03-24T07:45:07.114989Z"
    }
   },
   "outputs": [],
   "source": [
    "def forward(x, parameter, cache):\n",
    "    \"\"\"\n",
    "    :param x:input data p*n matrix\n",
    "    :param parameter: a dict storing parameters\n",
    "    :param cache: a dict storing computation result of each layer\n",
    "    :return: the predicted value\n",
    "    \"\"\"\n",
    "    cache['C1'] = np.dot(parameter['W1'], x) + parameter['b1']\n",
    "    cache['A1'] = leaky_relu(cache['C1'])\n",
    "    cache['C2'] = np.dot(parameter['W2'], cache['A1']) + parameter['b2']\n",
    "    cache['A2'] = leaky_relu(cache['C2'])\n",
    "    cache['C3'] = np.dot(parameter['W3'], cache['A2']) + parameter['b3']\n",
    "    cache['A3'] = soft_max(cache['C3'])\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T07:45:07.800878Z",
     "start_time": "2019-03-24T07:45:07.771882Z"
    }
   },
   "outputs": [],
   "source": [
    "def back_propagation(x, y, parameter, cache, step):\n",
    "    \"\"\"\n",
    "    X 784*n / Y 10*n\n",
    "    dW1 W1 800*784, db1 b1 800*1, A1 C1, 800*n\n",
    "    dW2 W2 400*800, db2 b2 400*1, A2 C2, 400*n\n",
    "    dW3 W3 10*400, db3 b3 10*1, A3 C3, 10*n\n",
    "    :param y: true value\n",
    "    :param parameter: dictionary storing all parameters\n",
    "    :param cache: dictionary storing all the computation in process\n",
    "    :param step: learning rate\n",
    "    :return: updated parameters\n",
    "    \"\"\"\n",
    "    number = y.shape[1]\n",
    "    cache['dC3'] = cache['A3'] - y  # 10*n\n",
    "    cache['dW3'] = np.dot(cache['dC3'], cache['A2'].T)/number  # 10*400\n",
    "    cache['db3'] = np.sum(cache['dC3'], axis=1, keepdims=True)/number  # 10*1\n",
    "    parameter['W3'] = parameter['W3'] - step*cache['dW3']  # 10*400\n",
    "    parameter['b3'] = parameter['b3'] - step*cache['db3']  # 10*1\n",
    "\n",
    "    cache['dC2'] = np.dot(parameter['W3'].T, \n",
    "                          cache['dC3'])*d_leaky_relu(cache['C2'])  # 400*n\n",
    "    cache['dW2'] = np.dot(cache['dC2'], cache['A1'].T)/number  # 400*800\n",
    "    cache['db2'] = np.sum(cache['dC2'], axis=1, keepdims=True)/number  # 400*1\n",
    "    parameter['W2'] = parameter['W2'] - step*cache['dW2']  # 400*800\n",
    "    parameter['b2'] = parameter['b2'] - step*cache['db2']  # 400*1\n",
    "\n",
    "    cache['dC1'] = np.dot(parameter['W2'].T, \n",
    "                          cache['dC2'])*d_leaky_relu(cache['C1'])  # 800*n\n",
    "    cache['dW1'] = np.dot(cache['dC1'], x.T)/number  # 800*784\n",
    "    cache['db1'] = np.sum(cache['dC1'], axis=1, keepdims=True)  # 800*1\n",
    "    parameter['W1'] = parameter['W1'] - step*cache['dW1']  # 800*784\n",
    "    parameter['b1'] = parameter['b1'] - step*cache['db1']  # 800*1\n",
    "    return cache, parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T07:45:08.678740Z",
     "start_time": "2019-03-24T07:45:08.651744Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(x, y, learning_rate=0.001, batch_size=128, epoch=5):\n",
    "    \"\"\"\n",
    "    :param x: training data\n",
    "    :param y: training label\n",
    "    :param learning_rate: the length of a step\n",
    "    :param batch_size: numbers of samples we train in a round\n",
    "    :param epoch: rounds we train through training data\n",
    "    :return: a trained set of parameters\n",
    "    \"\"\"\n",
    "    parameter = dict()\n",
    "    nx = x.shape[1]\n",
    "    parameter['W1'] = init_w(800, 784)/100\n",
    "    parameter['b1'] = init_b(800)\n",
    "    parameter['W2'] = init_w(400, 800)/100\n",
    "    parameter['b2'] = init_b(400)\n",
    "    parameter['W3'] = init_w(10, 400)/100\n",
    "    parameter['b3'] = init_b(10)\n",
    "\n",
    "    index = np.array([], dtype='int')\n",
    "    for i in range(0, nx, batch_size):\n",
    "        index = np.append(index, i)\n",
    "    index = np.append(index, nx)\n",
    "\n",
    "    cache = dict()\n",
    "    for i in range(0, epoch):\n",
    "        for j in range(0, int(nx/batch_size)+1):\n",
    "            one_batch_x = x[:, index[j]:index[j+1]]\n",
    "            one_batch_y = y[:, index[j]:index[j+1]]\n",
    "            cache = forward(one_batch_x, parameter, cache)\n",
    "            prob = loss(one_batch_y, cache['A3'])\n",
    "            acc = accuracy(one_batch_y, cache['A3'])\n",
    "            print(str(i)+'--'+str(j)+'--'+str(index[j+1]))\n",
    "            print('loss: '+str(prob))\n",
    "            print('accuracy: '+str(acc))\n",
    "            [cache, parameter] = back_propagation(one_batch_x, one_batch_y,\n",
    "                                        parameter, cache, step=learning_rate)\n",
    "    return cache, parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T07:45:10.276492Z",
     "start_time": "2019-03-24T07:45:10.101518Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29399, 10)\n",
      "(12601, 10)\n"
     ]
    }
   ],
   "source": [
    "train_label = to_category(train_label, num_classes=10)\n",
    "test_label = to_category(test_label, num_classes=10)\n",
    "\n",
    "print(train_label.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T07:47:13.208819Z",
     "start_time": "2019-03-24T07:45:11.136357Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0--0--128\n",
      "loss: 2.5144562796833654\n",
      "accuracy: 0.0703125\n",
      "0--1--256\n",
      "loss: 2.217050238032897\n",
      "accuracy: 0.1875\n",
      "0--2--384\n",
      "loss: 2.1658027472486903\n",
      "accuracy: 0.234375\n",
      "0--3--512\n",
      "loss: 2.0168412770294104\n",
      "accuracy: 0.296875\n",
      "0--4--640\n",
      "loss: 1.8946818751163836\n",
      "accuracy: 0.40625\n",
      "0--5--768\n",
      "loss: 1.8244820246098055\n",
      "accuracy: 0.421875\n",
      "0--6--896\n",
      "loss: 1.6413233158646316\n",
      "accuracy: 0.515625\n",
      "0--7--1024\n",
      "loss: 1.6209324889136416\n",
      "accuracy: 0.5546875\n",
      "0--8--1152\n",
      "loss: 1.5990883453285492\n",
      "accuracy: 0.5390625\n",
      "0--9--1280\n",
      "loss: 1.385634792789608\n",
      "accuracy: 0.6484375\n",
      "0--10--1408\n",
      "loss: 1.303833712288761\n",
      "accuracy: 0.703125\n",
      "0--11--1536\n",
      "loss: 1.3310439935553542\n",
      "accuracy: 0.6484375\n",
      "0--12--1664\n",
      "loss: 1.1805366474892716\n",
      "accuracy: 0.7265625\n",
      "0--13--1792\n",
      "loss: 1.260705592177902\n",
      "accuracy: 0.6640625\n",
      "0--14--1920\n",
      "loss: 1.1617022979770701\n",
      "accuracy: 0.7109375\n",
      "0--15--2048\n",
      "loss: 1.1734547644587505\n",
      "accuracy: 0.6875\n",
      "0--16--2176\n",
      "loss: 1.0308806471718963\n",
      "accuracy: 0.734375\n",
      "0--17--2304\n",
      "loss: 1.0419973584182476\n",
      "accuracy: 0.71875\n",
      "0--18--2432\n",
      "loss: 0.982214182089478\n",
      "accuracy: 0.78125\n",
      "0--19--2560\n",
      "loss: 1.0488591875437283\n",
      "accuracy: 0.7421875\n",
      "0--20--2688\n",
      "loss: 1.0342548244495975\n",
      "accuracy: 0.6875\n",
      "0--21--2816\n",
      "loss: 1.0185086659398621\n",
      "accuracy: 0.765625\n",
      "0--22--2944\n",
      "loss: 1.051002820444534\n",
      "accuracy: 0.7109375\n",
      "0--23--3072\n",
      "loss: 0.9282233902726331\n",
      "accuracy: 0.7109375\n",
      "0--24--3200\n",
      "loss: 0.8744240635188474\n",
      "accuracy: 0.7890625\n",
      "0--25--3328\n",
      "loss: 0.8244569494972284\n",
      "accuracy: 0.7890625\n",
      "0--26--3456\n",
      "loss: 0.7977779804797371\n",
      "accuracy: 0.78125\n",
      "0--27--3584\n",
      "loss: 0.7676662447960514\n",
      "accuracy: 0.8125\n",
      "0--28--3712\n",
      "loss: 0.7796647625908661\n",
      "accuracy: 0.8046875\n",
      "0--29--3840\n",
      "loss: 0.7544081717094397\n",
      "accuracy: 0.7890625\n",
      "0--30--3968\n",
      "loss: 0.8070503639703792\n",
      "accuracy: 0.7421875\n",
      "0--31--4096\n",
      "loss: 0.7655405946902787\n",
      "accuracy: 0.796875\n",
      "0--32--4224\n",
      "loss: 0.8616568699672724\n",
      "accuracy: 0.75\n",
      "0--33--4352\n",
      "loss: 0.7552023431289551\n",
      "accuracy: 0.8046875\n",
      "0--34--4480\n",
      "loss: 0.7433222356628701\n",
      "accuracy: 0.84375\n",
      "0--35--4608\n",
      "loss: 0.7532108013910165\n",
      "accuracy: 0.796875\n",
      "0--36--4736\n",
      "loss: 0.814190428647501\n",
      "accuracy: 0.7890625\n",
      "0--37--4864\n",
      "loss: 0.6220072638473819\n",
      "accuracy: 0.8125\n",
      "0--38--4992\n",
      "loss: 0.6470966796465027\n",
      "accuracy: 0.84375\n",
      "0--39--5120\n",
      "loss: 0.7499685064324348\n",
      "accuracy: 0.78125\n",
      "0--40--5248\n",
      "loss: 0.7315055664845771\n",
      "accuracy: 0.8125\n",
      "0--41--5376\n",
      "loss: 0.5727038702302014\n",
      "accuracy: 0.875\n",
      "0--42--5504\n",
      "loss: 0.6847071274302589\n",
      "accuracy: 0.8203125\n",
      "0--43--5632\n",
      "loss: 0.7021457761788055\n",
      "accuracy: 0.78125\n",
      "0--44--5760\n",
      "loss: 0.6151359921160389\n",
      "accuracy: 0.8359375\n",
      "0--45--5888\n",
      "loss: 0.7613747692387356\n",
      "accuracy: 0.8046875\n",
      "0--46--6016\n",
      "loss: 0.6592947467208227\n",
      "accuracy: 0.8359375\n",
      "0--47--6144\n",
      "loss: 0.5879875441592406\n",
      "accuracy: 0.8515625\n",
      "0--48--6272\n",
      "loss: 0.6835816107099395\n",
      "accuracy: 0.84375\n",
      "0--49--6400\n",
      "loss: 0.6529306702483856\n",
      "accuracy: 0.828125\n",
      "0--50--6528\n",
      "loss: 0.6633618750802753\n",
      "accuracy: 0.8125\n",
      "0--51--6656\n",
      "loss: 0.5058631434980134\n",
      "accuracy: 0.8828125\n",
      "0--52--6784\n",
      "loss: 0.6311525600106633\n",
      "accuracy: 0.859375\n",
      "0--53--6912\n",
      "loss: 0.5339073062733845\n",
      "accuracy: 0.84375\n",
      "0--54--7040\n",
      "loss: 0.5454118112789327\n",
      "accuracy: 0.875\n",
      "0--55--7168\n",
      "loss: 0.6613946913247553\n",
      "accuracy: 0.8203125\n",
      "0--56--7296\n",
      "loss: 0.5332989237884944\n",
      "accuracy: 0.859375\n",
      "0--57--7424\n",
      "loss: 0.6223232868020128\n",
      "accuracy: 0.8046875\n",
      "0--58--7552\n",
      "loss: 0.604196518083128\n",
      "accuracy: 0.8515625\n",
      "0--59--7680\n",
      "loss: 0.613419671781042\n",
      "accuracy: 0.7890625\n",
      "0--60--7808\n",
      "loss: 0.4894249692370229\n",
      "accuracy: 0.875\n",
      "0--61--7936\n",
      "loss: 0.657183273231297\n",
      "accuracy: 0.8046875\n",
      "0--62--8064\n",
      "loss: 0.5421928692676916\n",
      "accuracy: 0.875\n",
      "0--63--8192\n",
      "loss: 0.5087934491958308\n",
      "accuracy: 0.8828125\n",
      "0--64--8320\n",
      "loss: 0.5005148366749299\n",
      "accuracy: 0.8671875\n",
      "0--65--8448\n",
      "loss: 0.4195915562480516\n",
      "accuracy: 0.90625\n",
      "0--66--8576\n",
      "loss: 0.46682100140049426\n",
      "accuracy: 0.8828125\n",
      "0--67--8704\n",
      "loss: 0.5070714440826076\n",
      "accuracy: 0.84375\n",
      "0--68--8832\n",
      "loss: 0.5842310285878669\n",
      "accuracy: 0.8125\n",
      "0--69--8960\n",
      "loss: 0.57634229921275\n",
      "accuracy: 0.796875\n",
      "0--70--9088\n",
      "loss: 0.4528906176739569\n",
      "accuracy: 0.8984375\n",
      "0--71--9216\n",
      "loss: 0.5432561850787224\n",
      "accuracy: 0.8515625\n",
      "0--72--9344\n",
      "loss: 0.6901474553130629\n",
      "accuracy: 0.75\n",
      "0--73--9472\n",
      "loss: 0.5315023767273102\n",
      "accuracy: 0.8046875\n",
      "0--74--9600\n",
      "loss: 0.6398640322165798\n",
      "accuracy: 0.8125\n",
      "0--75--9728\n",
      "loss: 0.49572381231156143\n",
      "accuracy: 0.84375\n",
      "0--76--9856\n",
      "loss: 0.6074509097457453\n",
      "accuracy: 0.8046875\n",
      "0--77--9984\n",
      "loss: 0.5324287706136872\n",
      "accuracy: 0.8671875\n",
      "0--78--10112\n",
      "loss: 0.48572787122398214\n",
      "accuracy: 0.875\n",
      "0--79--10240\n",
      "loss: 0.6006242921716833\n",
      "accuracy: 0.8515625\n",
      "0--80--10368\n",
      "loss: 0.5951739834223229\n",
      "accuracy: 0.8203125\n",
      "0--81--10496\n",
      "loss: 0.48336886031493415\n",
      "accuracy: 0.8671875\n",
      "0--82--10624\n",
      "loss: 0.5392963149271843\n",
      "accuracy: 0.828125\n",
      "0--83--10752\n",
      "loss: 0.45834187019552136\n",
      "accuracy: 0.9140625\n",
      "0--84--10880\n",
      "loss: 0.46805463326844376\n",
      "accuracy: 0.859375\n",
      "0--85--11008\n",
      "loss: 0.4195068700496333\n",
      "accuracy: 0.8984375\n",
      "0--86--11136\n",
      "loss: 0.4227066246891506\n",
      "accuracy: 0.8671875\n",
      "0--87--11264\n",
      "loss: 0.4943372348738676\n",
      "accuracy: 0.859375\n",
      "0--88--11392\n",
      "loss: 0.5411924886369339\n",
      "accuracy: 0.8671875\n",
      "0--89--11520\n",
      "loss: 0.45092554113525873\n",
      "accuracy: 0.859375\n",
      "0--90--11648\n",
      "loss: 0.464912130932998\n",
      "accuracy: 0.8828125\n",
      "0--91--11776\n",
      "loss: 0.4478056670775561\n",
      "accuracy: 0.890625\n",
      "0--92--11904\n",
      "loss: 0.5370311291331553\n",
      "accuracy: 0.8359375\n",
      "0--93--12032\n",
      "loss: 0.5630288479275366\n",
      "accuracy: 0.8203125\n",
      "0--94--12160\n",
      "loss: 0.4171803691474189\n",
      "accuracy: 0.859375\n",
      "0--95--12288\n",
      "loss: 0.46524645357264005\n",
      "accuracy: 0.8515625\n",
      "0--96--12416\n",
      "loss: 0.45359123350166575\n",
      "accuracy: 0.90625\n",
      "0--97--12544\n",
      "loss: 0.5152949188394549\n",
      "accuracy: 0.859375\n",
      "0--98--12672\n",
      "loss: 0.3421918275751196\n",
      "accuracy: 0.8828125\n",
      "0--99--12800\n",
      "loss: 0.4812717036524752\n",
      "accuracy: 0.875\n",
      "0--100--12928\n",
      "loss: 0.43185703545621723\n",
      "accuracy: 0.8671875\n",
      "0--101--13056\n",
      "loss: 0.4459955408035881\n",
      "accuracy: 0.875\n",
      "0--102--13184\n",
      "loss: 0.3948813414634826\n",
      "accuracy: 0.8984375\n",
      "0--103--13312\n",
      "loss: 0.5328456963084235\n",
      "accuracy: 0.8359375\n",
      "0--104--13440\n",
      "loss: 0.5358278780806194\n",
      "accuracy: 0.8359375\n",
      "0--105--13568\n",
      "loss: 0.5926010910582731\n",
      "accuracy: 0.84375\n",
      "0--106--13696\n",
      "loss: 0.4149401024217997\n",
      "accuracy: 0.890625\n",
      "0--107--13824\n",
      "loss: 0.47152444972215724\n",
      "accuracy: 0.8203125\n",
      "0--108--13952\n",
      "loss: 0.2783783482785894\n",
      "accuracy: 0.9296875\n",
      "0--109--14080\n",
      "loss: 0.4414253984259714\n",
      "accuracy: 0.890625\n",
      "0--110--14208\n",
      "loss: 0.534016753920909\n",
      "accuracy: 0.828125\n",
      "0--111--14336\n",
      "loss: 0.453277161279315\n",
      "accuracy: 0.8984375\n",
      "0--112--14464\n",
      "loss: 0.4059201480843446\n",
      "accuracy: 0.90625\n",
      "0--113--14592\n",
      "loss: 0.4527460669847329\n",
      "accuracy: 0.8828125\n",
      "0--114--14720\n",
      "loss: 0.38021177738584777\n",
      "accuracy: 0.8828125\n",
      "0--115--14848\n",
      "loss: 0.4659196956844336\n",
      "accuracy: 0.84375\n",
      "0--116--14976\n",
      "loss: 0.46408500854516893\n",
      "accuracy: 0.90625\n",
      "0--117--15104\n",
      "loss: 0.3973907757585733\n",
      "accuracy: 0.890625\n",
      "0--118--15232\n",
      "loss: 0.4373244497774972\n",
      "accuracy: 0.859375\n",
      "0--119--15360\n",
      "loss: 0.2861079983495005\n",
      "accuracy: 0.9453125\n",
      "0--120--15488\n",
      "loss: 0.39743434843571407\n",
      "accuracy: 0.8828125\n",
      "0--121--15616\n",
      "loss: 0.444039390421915\n",
      "accuracy: 0.859375\n",
      "0--122--15744\n",
      "loss: 0.5383207455162855\n",
      "accuracy: 0.8046875\n",
      "0--123--15872\n",
      "loss: 0.43430907616143255\n",
      "accuracy: 0.890625\n",
      "0--124--16000\n",
      "loss: 0.42499198428230667\n",
      "accuracy: 0.8984375\n",
      "0--125--16128\n",
      "loss: 0.33490809940522326\n",
      "accuracy: 0.9140625\n",
      "0--126--16256\n",
      "loss: 0.39876944211092635\n",
      "accuracy: 0.90625\n",
      "0--127--16384\n",
      "loss: 0.33841905219324436\n",
      "accuracy: 0.890625\n",
      "0--128--16512\n",
      "loss: 0.43014093013278887\n",
      "accuracy: 0.8671875\n",
      "0--129--16640\n",
      "loss: 0.44087146117967435\n",
      "accuracy: 0.8984375\n",
      "0--130--16768\n",
      "loss: 0.4149286610319117\n",
      "accuracy: 0.8984375\n",
      "0--131--16896\n",
      "loss: 0.5487121150878685\n",
      "accuracy: 0.84375\n",
      "0--132--17024\n",
      "loss: 0.48033160960419186\n",
      "accuracy: 0.8671875\n",
      "0--133--17152\n",
      "loss: 0.2827652008103738\n",
      "accuracy: 0.9375\n",
      "0--134--17280\n",
      "loss: 0.5280190354445662\n",
      "accuracy: 0.84375\n",
      "0--135--17408\n",
      "loss: 0.40136335386886063\n",
      "accuracy: 0.90625\n",
      "0--136--17536\n",
      "loss: 0.43412777178162065\n",
      "accuracy: 0.90625\n",
      "0--137--17664\n",
      "loss: 0.36986659277996203\n",
      "accuracy: 0.890625\n",
      "0--138--17792\n",
      "loss: 0.36390656067434607\n",
      "accuracy: 0.90625\n",
      "0--139--17920\n",
      "loss: 0.37277113417056407\n",
      "accuracy: 0.875\n",
      "0--140--18048\n",
      "loss: 0.3281691140953412\n",
      "accuracy: 0.921875\n",
      "0--141--18176\n",
      "loss: 0.30284969809562756\n",
      "accuracy: 0.9375\n",
      "0--142--18304\n",
      "loss: 0.3724772248149252\n",
      "accuracy: 0.8984375\n",
      "0--143--18432\n",
      "loss: 0.4380878591385008\n",
      "accuracy: 0.8828125\n",
      "0--144--18560\n",
      "loss: 0.37506361842601255\n",
      "accuracy: 0.8984375\n",
      "0--145--18688\n",
      "loss: 0.39088998228135197\n",
      "accuracy: 0.90625\n",
      "0--146--18816\n",
      "loss: 0.35999429639693986\n",
      "accuracy: 0.90625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0--147--18944\n",
      "loss: 0.4114326298069638\n",
      "accuracy: 0.890625\n",
      "0--148--19072\n",
      "loss: 0.41031210578035787\n",
      "accuracy: 0.890625\n",
      "0--149--19200\n",
      "loss: 0.46009855033299535\n",
      "accuracy: 0.8671875\n",
      "0--150--19328\n",
      "loss: 0.3394504977432337\n",
      "accuracy: 0.8984375\n",
      "0--151--19456\n",
      "loss: 0.3800270390012476\n",
      "accuracy: 0.8984375\n",
      "0--152--19584\n",
      "loss: 0.3947237096393335\n",
      "accuracy: 0.859375\n",
      "0--153--19712\n",
      "loss: 0.3841021629213581\n",
      "accuracy: 0.90625\n",
      "0--154--19840\n",
      "loss: 0.3205243187648902\n",
      "accuracy: 0.890625\n",
      "0--155--19968\n",
      "loss: 0.4992907784343232\n",
      "accuracy: 0.859375\n",
      "0--156--20096\n",
      "loss: 0.4204976871912581\n",
      "accuracy: 0.8828125\n",
      "0--157--20224\n",
      "loss: 0.47473556478157025\n",
      "accuracy: 0.890625\n",
      "0--158--20352\n",
      "loss: 0.3297899245674878\n",
      "accuracy: 0.9140625\n",
      "0--159--20480\n",
      "loss: 0.5765076515144314\n",
      "accuracy: 0.8515625\n",
      "0--160--20608\n",
      "loss: 0.5689105012752617\n",
      "accuracy: 0.859375\n",
      "0--161--20736\n",
      "loss: 0.40266185415624056\n",
      "accuracy: 0.9296875\n",
      "0--162--20864\n",
      "loss: 0.4079488638150572\n",
      "accuracy: 0.890625\n",
      "0--163--20992\n",
      "loss: 0.40792975673851656\n",
      "accuracy: 0.875\n",
      "0--164--21120\n",
      "loss: 0.2872802159388109\n",
      "accuracy: 0.9140625\n",
      "0--165--21248\n",
      "loss: 0.28309465528930744\n",
      "accuracy: 0.9140625\n",
      "0--166--21376\n",
      "loss: 0.4824761618666852\n",
      "accuracy: 0.8671875\n",
      "0--167--21504\n",
      "loss: 0.44351047278586536\n",
      "accuracy: 0.890625\n",
      "0--168--21632\n",
      "loss: 0.3832241958223705\n",
      "accuracy: 0.90625\n",
      "0--169--21760\n",
      "loss: 0.3769097063798208\n",
      "accuracy: 0.890625\n",
      "0--170--21888\n",
      "loss: 0.39200909359288477\n",
      "accuracy: 0.8515625\n",
      "0--171--22016\n",
      "loss: 0.3641771654429299\n",
      "accuracy: 0.875\n",
      "0--172--22144\n",
      "loss: 0.5023609432674898\n",
      "accuracy: 0.8359375\n",
      "0--173--22272\n",
      "loss: 0.3721557937065077\n",
      "accuracy: 0.8828125\n",
      "0--174--22400\n",
      "loss: 0.3576019482144596\n",
      "accuracy: 0.90625\n",
      "0--175--22528\n",
      "loss: 0.35543354651101966\n",
      "accuracy: 0.921875\n",
      "0--176--22656\n",
      "loss: 0.31797409572887086\n",
      "accuracy: 0.9140625\n",
      "0--177--22784\n",
      "loss: 0.3133741169958173\n",
      "accuracy: 0.921875\n",
      "0--178--22912\n",
      "loss: 0.3121597299498443\n",
      "accuracy: 0.921875\n",
      "0--179--23040\n",
      "loss: 0.3400229507354354\n",
      "accuracy: 0.9296875\n",
      "0--180--23168\n",
      "loss: 0.32361553850315117\n",
      "accuracy: 0.9296875\n",
      "0--181--23296\n",
      "loss: 0.4994068685631748\n",
      "accuracy: 0.859375\n",
      "0--182--23424\n",
      "loss: 0.3665033227083895\n",
      "accuracy: 0.9140625\n",
      "0--183--23552\n",
      "loss: 0.3808076015139829\n",
      "accuracy: 0.8671875\n",
      "0--184--23680\n",
      "loss: 0.41112087109827855\n",
      "accuracy: 0.859375\n",
      "0--185--23808\n",
      "loss: 0.25294339447569847\n",
      "accuracy: 0.9296875\n",
      "0--186--23936\n",
      "loss: 0.43550023073241034\n",
      "accuracy: 0.859375\n",
      "0--187--24064\n",
      "loss: 0.5443954670852986\n",
      "accuracy: 0.875\n",
      "0--188--24192\n",
      "loss: 0.3275130711997787\n",
      "accuracy: 0.8828125\n",
      "0--189--24320\n",
      "loss: 0.4506671024664212\n",
      "accuracy: 0.8828125\n",
      "0--190--24448\n",
      "loss: 0.36283389855458203\n",
      "accuracy: 0.890625\n",
      "0--191--24576\n",
      "loss: 0.4840784045475447\n",
      "accuracy: 0.84375\n",
      "0--192--24704\n",
      "loss: 0.3273309235119446\n",
      "accuracy: 0.921875\n",
      "0--193--24832\n",
      "loss: 0.36902547357019627\n",
      "accuracy: 0.875\n",
      "0--194--24960\n",
      "loss: 0.38617889969368624\n",
      "accuracy: 0.90625\n",
      "0--195--25088\n",
      "loss: 0.3240239176367957\n",
      "accuracy: 0.9140625\n",
      "0--196--25216\n",
      "loss: 0.399083965780036\n",
      "accuracy: 0.8828125\n",
      "0--197--25344\n",
      "loss: 0.44483693771873845\n",
      "accuracy: 0.8828125\n",
      "0--198--25472\n",
      "loss: 0.5084765802822988\n",
      "accuracy: 0.875\n",
      "0--199--25600\n",
      "loss: 0.3816273765758412\n",
      "accuracy: 0.875\n",
      "0--200--25728\n",
      "loss: 0.33549340057174243\n",
      "accuracy: 0.90625\n",
      "0--201--25856\n",
      "loss: 0.42596543164542394\n",
      "accuracy: 0.84375\n",
      "0--202--25984\n",
      "loss: 0.23221470966040078\n",
      "accuracy: 0.9453125\n",
      "0--203--26112\n",
      "loss: 0.3383040850454929\n",
      "accuracy: 0.9296875\n",
      "0--204--26240\n",
      "loss: 0.28554657833485925\n",
      "accuracy: 0.9296875\n",
      "0--205--26368\n",
      "loss: 0.467886174789014\n",
      "accuracy: 0.859375\n",
      "0--206--26496\n",
      "loss: 0.34802149240598346\n",
      "accuracy: 0.90625\n",
      "0--207--26624\n",
      "loss: 0.3078923210986365\n",
      "accuracy: 0.9140625\n",
      "0--208--26752\n",
      "loss: 0.4087322367446533\n",
      "accuracy: 0.8828125\n",
      "0--209--26880\n",
      "loss: 0.3673793402271704\n",
      "accuracy: 0.8984375\n",
      "0--210--27008\n",
      "loss: 0.3055128566212699\n",
      "accuracy: 0.9140625\n",
      "0--211--27136\n",
      "loss: 0.3459867854151793\n",
      "accuracy: 0.8984375\n",
      "0--212--27264\n",
      "loss: 0.3914355415593235\n",
      "accuracy: 0.9140625\n",
      "0--213--27392\n",
      "loss: 0.4220776143540002\n",
      "accuracy: 0.875\n",
      "0--214--27520\n",
      "loss: 0.22968103295881812\n",
      "accuracy: 0.9453125\n",
      "0--215--27648\n",
      "loss: 0.41668449968419236\n",
      "accuracy: 0.8671875\n",
      "0--216--27776\n",
      "loss: 0.32720253762644524\n",
      "accuracy: 0.890625\n",
      "0--217--27904\n",
      "loss: 0.31349499399099046\n",
      "accuracy: 0.90625\n",
      "0--218--28032\n",
      "loss: 0.2527009781201379\n",
      "accuracy: 0.921875\n",
      "0--219--28160\n",
      "loss: 0.3087098991516306\n",
      "accuracy: 0.8984375\n",
      "0--220--28288\n",
      "loss: 0.43902029596589703\n",
      "accuracy: 0.875\n",
      "0--221--28416\n",
      "loss: 0.3548413974404646\n",
      "accuracy: 0.921875\n",
      "0--222--28544\n",
      "loss: 0.3450215101025608\n",
      "accuracy: 0.890625\n",
      "0--223--28672\n",
      "loss: 0.24524699720009102\n",
      "accuracy: 0.9296875\n",
      "0--224--28800\n",
      "loss: 0.46874000176229375\n",
      "accuracy: 0.859375\n",
      "0--225--28928\n",
      "loss: 0.3578855945733159\n",
      "accuracy: 0.890625\n",
      "0--226--29056\n",
      "loss: 0.3644711639459468\n",
      "accuracy: 0.8828125\n",
      "0--227--29184\n",
      "loss: 0.42358075433792436\n",
      "accuracy: 0.8828125\n",
      "0--228--29312\n",
      "loss: 0.3624121500369032\n",
      "accuracy: 0.9140625\n",
      "0--229--29399\n",
      "loss: 0.3521769928408441\n",
      "accuracy: 0.896551724137931\n",
      "1--0--128\n",
      "loss: 0.4784413933361167\n",
      "accuracy: 0.8671875\n",
      "1--1--256\n",
      "loss: 0.2809984040435429\n",
      "accuracy: 0.90625\n",
      "1--2--384\n",
      "loss: 0.5224073266557672\n",
      "accuracy: 0.859375\n",
      "1--3--512\n",
      "loss: 0.3235940035634032\n",
      "accuracy: 0.890625\n",
      "1--4--640\n",
      "loss: 0.41865132988449877\n",
      "accuracy: 0.8515625\n",
      "1--5--768\n",
      "loss: 0.3722485682686894\n",
      "accuracy: 0.8828125\n",
      "1--6--896\n",
      "loss: 0.3577078536245744\n",
      "accuracy: 0.90625\n",
      "1--7--1024\n",
      "loss: 0.3102148202754932\n",
      "accuracy: 0.90625\n",
      "1--8--1152\n",
      "loss: 0.2817566739136048\n",
      "accuracy: 0.90625\n",
      "1--9--1280\n",
      "loss: 0.37031080057203847\n",
      "accuracy: 0.8671875\n",
      "1--10--1408\n",
      "loss: 0.26918610721712893\n",
      "accuracy: 0.9140625\n",
      "1--11--1536\n",
      "loss: 0.34609346389358664\n",
      "accuracy: 0.875\n",
      "1--12--1664\n",
      "loss: 0.27582413647427456\n",
      "accuracy: 0.921875\n",
      "1--13--1792\n",
      "loss: 0.27419080654011907\n",
      "accuracy: 0.921875\n",
      "1--14--1920\n",
      "loss: 0.2939112637745688\n",
      "accuracy: 0.90625\n",
      "1--15--2048\n",
      "loss: 0.3102518988493187\n",
      "accuracy: 0.8828125\n",
      "1--16--2176\n",
      "loss: 0.33204120765980805\n",
      "accuracy: 0.9453125\n",
      "1--17--2304\n",
      "loss: 0.2822052515498391\n",
      "accuracy: 0.921875\n",
      "1--18--2432\n",
      "loss: 0.33787754391845404\n",
      "accuracy: 0.921875\n",
      "1--19--2560\n",
      "loss: 0.3884173928934721\n",
      "accuracy: 0.8671875\n",
      "1--20--2688\n",
      "loss: 0.28647193344995925\n",
      "accuracy: 0.921875\n",
      "1--21--2816\n",
      "loss: 0.3095969068754494\n",
      "accuracy: 0.8828125\n",
      "1--22--2944\n",
      "loss: 0.39489087785330207\n",
      "accuracy: 0.875\n",
      "1--23--3072\n",
      "loss: 0.34880298762089224\n",
      "accuracy: 0.8671875\n",
      "1--24--3200\n",
      "loss: 0.3037214476423902\n",
      "accuracy: 0.921875\n",
      "1--25--3328\n",
      "loss: 0.28530917506398634\n",
      "accuracy: 0.90625\n",
      "1--26--3456\n",
      "loss: 0.29314643782488764\n",
      "accuracy: 0.9140625\n",
      "1--27--3584\n",
      "loss: 0.23507186548665399\n",
      "accuracy: 0.9296875\n",
      "1--28--3712\n",
      "loss: 0.24446196276152982\n",
      "accuracy: 0.96875\n",
      "1--29--3840\n",
      "loss: 0.300079059540142\n",
      "accuracy: 0.90625\n",
      "1--30--3968\n",
      "loss: 0.3138964229494293\n",
      "accuracy: 0.90625\n",
      "1--31--4096\n",
      "loss: 0.37485050138090525\n",
      "accuracy: 0.8984375\n",
      "1--32--4224\n",
      "loss: 0.40481754889162824\n",
      "accuracy: 0.875\n",
      "1--33--4352\n",
      "loss: 0.3097313623292942\n",
      "accuracy: 0.921875\n",
      "1--34--4480\n",
      "loss: 0.35920632785927703\n",
      "accuracy: 0.8984375\n",
      "1--35--4608\n",
      "loss: 0.38687265900328316\n",
      "accuracy: 0.8984375\n",
      "1--36--4736\n",
      "loss: 0.41814952218396384\n",
      "accuracy: 0.8515625\n",
      "1--37--4864\n",
      "loss: 0.24292502593632326\n",
      "accuracy: 0.921875\n",
      "1--38--4992\n",
      "loss: 0.3298984284439357\n",
      "accuracy: 0.90625\n",
      "1--39--5120\n",
      "loss: 0.35398397172634577\n",
      "accuracy: 0.8984375\n",
      "1--40--5248\n",
      "loss: 0.39377776996960023\n",
      "accuracy: 0.8984375\n",
      "1--41--5376\n",
      "loss: 0.2149024317936732\n",
      "accuracy: 0.9453125\n",
      "1--42--5504\n",
      "loss: 0.30713244667517786\n",
      "accuracy: 0.9140625\n",
      "1--43--5632\n",
      "loss: 0.2937702218335918\n",
      "accuracy: 0.8828125\n",
      "1--44--5760\n",
      "loss: 0.31342263311723545\n",
      "accuracy: 0.921875\n",
      "1--45--5888\n",
      "loss: 0.5137701880222669\n",
      "accuracy: 0.8828125\n",
      "1--46--6016\n",
      "loss: 0.38857735940757243\n",
      "accuracy: 0.8671875\n",
      "1--47--6144\n",
      "loss: 0.2625033273357935\n",
      "accuracy: 0.921875\n",
      "1--48--6272\n",
      "loss: 0.3146359982184206\n",
      "accuracy: 0.8984375\n",
      "1--49--6400\n",
      "loss: 0.32417084676958396\n",
      "accuracy: 0.875\n",
      "1--50--6528\n",
      "loss: 0.4241690693642612\n",
      "accuracy: 0.859375\n",
      "1--51--6656\n",
      "loss: 0.20548885540668363\n",
      "accuracy: 0.9453125\n",
      "1--52--6784\n",
      "loss: 0.3527824271211092\n",
      "accuracy: 0.921875\n",
      "1--53--6912\n",
      "loss: 0.23284593703537668\n",
      "accuracy: 0.9140625\n",
      "1--54--7040\n",
      "loss: 0.2779823398313023\n",
      "accuracy: 0.8984375\n",
      "1--55--7168\n",
      "loss: 0.41709150237123177\n",
      "accuracy: 0.859375\n",
      "1--56--7296\n",
      "loss: 0.2623367208247557\n",
      "accuracy: 0.9296875\n",
      "1--57--7424\n",
      "loss: 0.36704233540956954\n",
      "accuracy: 0.921875\n",
      "1--58--7552\n",
      "loss: 0.3673391609373419\n",
      "accuracy: 0.9375\n",
      "1--59--7680\n",
      "loss: 0.41090676359551226\n",
      "accuracy: 0.875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1--60--7808\n",
      "loss: 0.24343609902013907\n",
      "accuracy: 0.9375\n",
      "1--61--7936\n",
      "loss: 0.4631960912363376\n",
      "accuracy: 0.8828125\n",
      "1--62--8064\n",
      "loss: 0.30408090548921496\n",
      "accuracy: 0.9140625\n",
      "1--63--8192\n",
      "loss: 0.3106892270517312\n",
      "accuracy: 0.9375\n",
      "1--64--8320\n",
      "loss: 0.29241012925739635\n",
      "accuracy: 0.90625\n",
      "1--65--8448\n",
      "loss: 0.21049285400482148\n",
      "accuracy: 0.9375\n",
      "1--66--8576\n",
      "loss: 0.21814655111015233\n",
      "accuracy: 0.953125\n",
      "1--67--8704\n",
      "loss: 0.22486617728784983\n",
      "accuracy: 0.9375\n",
      "1--68--8832\n",
      "loss: 0.3442469318671014\n",
      "accuracy: 0.890625\n",
      "1--69--8960\n",
      "loss: 0.31405442327854927\n",
      "accuracy: 0.890625\n",
      "1--70--9088\n",
      "loss: 0.2512756437475721\n",
      "accuracy: 0.9296875\n",
      "1--71--9216\n",
      "loss: 0.33934086320415857\n",
      "accuracy: 0.8984375\n",
      "1--72--9344\n",
      "loss: 0.48646391609240675\n",
      "accuracy: 0.8359375\n",
      "1--73--9472\n",
      "loss: 0.3472198928436054\n",
      "accuracy: 0.8671875\n",
      "1--74--9600\n",
      "loss: 0.4607340927267417\n",
      "accuracy: 0.90625\n",
      "1--75--9728\n",
      "loss: 0.3246488577845161\n",
      "accuracy: 0.8984375\n",
      "1--76--9856\n",
      "loss: 0.35825968686244286\n",
      "accuracy: 0.875\n",
      "1--77--9984\n",
      "loss: 0.3049351727502574\n",
      "accuracy: 0.921875\n",
      "1--78--10112\n",
      "loss: 0.3121919562288198\n",
      "accuracy: 0.8828125\n",
      "1--79--10240\n",
      "loss: 0.4295420232389461\n",
      "accuracy: 0.8984375\n",
      "1--80--10368\n",
      "loss: 0.3983019736381338\n",
      "accuracy: 0.8828125\n",
      "1--81--10496\n",
      "loss: 0.2665409958645021\n",
      "accuracy: 0.9140625\n",
      "1--82--10624\n",
      "loss: 0.35328706955026573\n",
      "accuracy: 0.890625\n",
      "1--83--10752\n",
      "loss: 0.2779423227207185\n",
      "accuracy: 0.9140625\n",
      "1--84--10880\n",
      "loss: 0.2601522169079653\n",
      "accuracy: 0.9375\n",
      "1--85--11008\n",
      "loss: 0.21878340370101992\n",
      "accuracy: 0.9296875\n",
      "1--86--11136\n",
      "loss: 0.25071160511379764\n",
      "accuracy: 0.9375\n",
      "1--87--11264\n",
      "loss: 0.3591139856502097\n",
      "accuracy: 0.8671875\n",
      "1--88--11392\n",
      "loss: 0.39672080367074136\n",
      "accuracy: 0.890625\n",
      "1--89--11520\n",
      "loss: 0.22977180467997094\n",
      "accuracy: 0.9453125\n",
      "1--90--11648\n",
      "loss: 0.2868004728390251\n",
      "accuracy: 0.9296875\n",
      "1--91--11776\n",
      "loss: 0.27743950034042697\n",
      "accuracy: 0.921875\n",
      "1--92--11904\n",
      "loss: 0.3984753527672429\n",
      "accuracy: 0.8984375\n",
      "1--93--12032\n",
      "loss: 0.3709176959356433\n",
      "accuracy: 0.8984375\n",
      "1--94--12160\n",
      "loss: 0.2705289419573663\n",
      "accuracy: 0.9140625\n",
      "1--95--12288\n",
      "loss: 0.2904986149067824\n",
      "accuracy: 0.9375\n",
      "1--96--12416\n",
      "loss: 0.33194582380738397\n",
      "accuracy: 0.9453125\n",
      "1--97--12544\n",
      "loss: 0.37430277906733767\n",
      "accuracy: 0.8984375\n",
      "1--98--12672\n",
      "loss: 0.1999417758621406\n",
      "accuracy: 0.9375\n",
      "1--99--12800\n",
      "loss: 0.37162875343143553\n",
      "accuracy: 0.9296875\n",
      "1--100--12928\n",
      "loss: 0.28508558399260997\n",
      "accuracy: 0.890625\n",
      "1--101--13056\n",
      "loss: 0.28808935179522466\n",
      "accuracy: 0.9140625\n",
      "1--102--13184\n",
      "loss: 0.20992930406145704\n",
      "accuracy: 0.9453125\n",
      "1--103--13312\n",
      "loss: 0.3735091988241605\n",
      "accuracy: 0.8828125\n",
      "1--104--13440\n",
      "loss: 0.36639050533154693\n",
      "accuracy: 0.8984375\n",
      "1--105--13568\n",
      "loss: 0.42127941663895585\n",
      "accuracy: 0.8984375\n",
      "1--106--13696\n",
      "loss: 0.30563803393494354\n",
      "accuracy: 0.90625\n",
      "1--107--13824\n",
      "loss: 0.3039179067194721\n",
      "accuracy: 0.8984375\n",
      "1--108--13952\n",
      "loss: 0.17619169041092217\n",
      "accuracy: 0.9453125\n",
      "1--109--14080\n",
      "loss: 0.31294737397913575\n",
      "accuracy: 0.8984375\n",
      "1--110--14208\n",
      "loss: 0.3762742150902608\n",
      "accuracy: 0.875\n",
      "1--111--14336\n",
      "loss: 0.3657364604865767\n",
      "accuracy: 0.9140625\n",
      "1--112--14464\n",
      "loss: 0.276047693232034\n",
      "accuracy: 0.921875\n",
      "1--113--14592\n",
      "loss: 0.315607276896158\n",
      "accuracy: 0.8984375\n",
      "1--114--14720\n",
      "loss: 0.2736493509320972\n",
      "accuracy: 0.8984375\n",
      "1--115--14848\n",
      "loss: 0.3034338647475618\n",
      "accuracy: 0.859375\n",
      "1--116--14976\n",
      "loss: 0.3678895103481914\n",
      "accuracy: 0.921875\n",
      "1--117--15104\n",
      "loss: 0.311873122562798\n",
      "accuracy: 0.921875\n",
      "1--118--15232\n",
      "loss: 0.32489399741379676\n",
      "accuracy: 0.890625\n",
      "1--119--15360\n",
      "loss: 0.18223088849386548\n",
      "accuracy: 0.9609375\n",
      "1--120--15488\n",
      "loss: 0.2775342971148901\n",
      "accuracy: 0.921875\n",
      "1--121--15616\n",
      "loss: 0.31650307958091417\n",
      "accuracy: 0.9296875\n",
      "1--122--15744\n",
      "loss: 0.39002690437473786\n",
      "accuracy: 0.8828125\n",
      "1--123--15872\n",
      "loss: 0.2918239983645352\n",
      "accuracy: 0.921875\n",
      "1--124--16000\n",
      "loss: 0.2634624238654544\n",
      "accuracy: 0.9375\n",
      "1--125--16128\n",
      "loss: 0.19652623676170858\n",
      "accuracy: 0.953125\n",
      "1--126--16256\n",
      "loss: 0.2770593850140747\n",
      "accuracy: 0.9375\n",
      "1--127--16384\n",
      "loss: 0.22288115505200634\n",
      "accuracy: 0.9296875\n",
      "1--128--16512\n",
      "loss: 0.30825426253445504\n",
      "accuracy: 0.90625\n",
      "1--129--16640\n",
      "loss: 0.3031483368258479\n",
      "accuracy: 0.90625\n",
      "1--130--16768\n",
      "loss: 0.2897914942258314\n",
      "accuracy: 0.9296875\n",
      "1--131--16896\n",
      "loss: 0.3910639523172185\n",
      "accuracy: 0.8671875\n",
      "1--132--17024\n",
      "loss: 0.417093209706786\n",
      "accuracy: 0.8671875\n",
      "1--133--17152\n",
      "loss: 0.16981852223661753\n",
      "accuracy: 0.9765625\n",
      "1--134--17280\n",
      "loss: 0.4153660560946515\n",
      "accuracy: 0.890625\n",
      "1--135--17408\n",
      "loss: 0.33546864347002825\n",
      "accuracy: 0.9140625\n",
      "1--136--17536\n",
      "loss: 0.3138535351977386\n",
      "accuracy: 0.921875\n",
      "1--137--17664\n",
      "loss: 0.27750742012206653\n",
      "accuracy: 0.9140625\n",
      "1--138--17792\n",
      "loss: 0.2253598944403589\n",
      "accuracy: 0.9375\n",
      "1--139--17920\n",
      "loss: 0.24571241740187483\n",
      "accuracy: 0.921875\n",
      "1--140--18048\n",
      "loss: 0.2312282561599559\n",
      "accuracy: 0.921875\n",
      "1--141--18176\n",
      "loss: 0.19433485944357415\n",
      "accuracy: 0.953125\n",
      "1--142--18304\n",
      "loss: 0.30588490027446635\n",
      "accuracy: 0.90625\n",
      "1--143--18432\n",
      "loss: 0.34284974860461637\n",
      "accuracy: 0.9140625\n",
      "1--144--18560\n",
      "loss: 0.27273742700070447\n",
      "accuracy: 0.9140625\n",
      "1--145--18688\n",
      "loss: 0.2811987983786788\n",
      "accuracy: 0.9375\n",
      "1--146--18816\n",
      "loss: 0.26033479606459353\n",
      "accuracy: 0.921875\n",
      "1--147--18944\n",
      "loss: 0.3268586097310512\n",
      "accuracy: 0.921875\n",
      "1--148--19072\n",
      "loss: 0.3490945240203806\n",
      "accuracy: 0.890625\n",
      "1--149--19200\n",
      "loss: 0.3790747820865246\n",
      "accuracy: 0.90625\n",
      "1--150--19328\n",
      "loss: 0.21662839410198875\n",
      "accuracy: 0.9375\n",
      "1--151--19456\n",
      "loss: 0.2603595533781914\n",
      "accuracy: 0.9453125\n",
      "1--152--19584\n",
      "loss: 0.28275774294314265\n",
      "accuracy: 0.90625\n",
      "1--153--19712\n",
      "loss: 0.3015639863915001\n",
      "accuracy: 0.921875\n",
      "1--154--19840\n",
      "loss: 0.21570631567943796\n",
      "accuracy: 0.9296875\n",
      "1--155--19968\n",
      "loss: 0.3939596911595955\n",
      "accuracy: 0.890625\n",
      "1--156--20096\n",
      "loss: 0.29940220818314184\n",
      "accuracy: 0.921875\n",
      "1--157--20224\n",
      "loss: 0.4052023444565691\n",
      "accuracy: 0.9140625\n",
      "1--158--20352\n",
      "loss: 0.230451142536511\n",
      "accuracy: 0.9453125\n",
      "1--159--20480\n",
      "loss: 0.46845843504096696\n",
      "accuracy: 0.875\n",
      "1--160--20608\n",
      "loss: 0.49584770855640486\n",
      "accuracy: 0.8984375\n",
      "1--161--20736\n",
      "loss: 0.3213300303503326\n",
      "accuracy: 0.921875\n",
      "1--162--20864\n",
      "loss: 0.33239711506166025\n",
      "accuracy: 0.921875\n",
      "1--163--20992\n",
      "loss: 0.309013077594275\n",
      "accuracy: 0.8984375\n",
      "1--164--21120\n",
      "loss: 0.20684476378976668\n",
      "accuracy: 0.9453125\n",
      "1--165--21248\n",
      "loss: 0.1828753456277153\n",
      "accuracy: 0.9453125\n",
      "1--166--21376\n",
      "loss: 0.36682480166017384\n",
      "accuracy: 0.8984375\n",
      "1--167--21504\n",
      "loss: 0.37334932863872355\n",
      "accuracy: 0.8984375\n",
      "1--168--21632\n",
      "loss: 0.3130223202982156\n",
      "accuracy: 0.9296875\n",
      "1--169--21760\n",
      "loss: 0.2600165076204858\n",
      "accuracy: 0.9296875\n",
      "1--170--21888\n",
      "loss: 0.30039068884056314\n",
      "accuracy: 0.90625\n",
      "1--171--22016\n",
      "loss: 0.26650323865358494\n",
      "accuracy: 0.9140625\n",
      "1--172--22144\n",
      "loss: 0.3711276663502726\n",
      "accuracy: 0.8984375\n",
      "1--173--22272\n",
      "loss: 0.2760758573351142\n",
      "accuracy: 0.90625\n",
      "1--174--22400\n",
      "loss: 0.28228296683718684\n",
      "accuracy: 0.9296875\n",
      "1--175--22528\n",
      "loss: 0.2760608740880042\n",
      "accuracy: 0.9296875\n",
      "1--176--22656\n",
      "loss: 0.219883844296249\n",
      "accuracy: 0.921875\n",
      "1--177--22784\n",
      "loss: 0.21697089647196888\n",
      "accuracy: 0.921875\n",
      "1--178--22912\n",
      "loss: 0.23386858464233243\n",
      "accuracy: 0.921875\n",
      "1--179--23040\n",
      "loss: 0.2778967611332675\n",
      "accuracy: 0.9296875\n",
      "1--180--23168\n",
      "loss: 0.23043263862980054\n",
      "accuracy: 0.9453125\n",
      "1--181--23296\n",
      "loss: 0.4145018362570708\n",
      "accuracy: 0.9140625\n",
      "1--182--23424\n",
      "loss: 0.28478993154983884\n",
      "accuracy: 0.9296875\n",
      "1--183--23552\n",
      "loss: 0.2686199481146821\n",
      "accuracy: 0.9140625\n",
      "1--184--23680\n",
      "loss: 0.3194117983505595\n",
      "accuracy: 0.890625\n",
      "1--185--23808\n",
      "loss: 0.1923340955850364\n",
      "accuracy: 0.9453125\n",
      "1--186--23936\n",
      "loss: 0.35014091951697557\n",
      "accuracy: 0.8984375\n",
      "1--187--24064\n",
      "loss: 0.4575791472506003\n",
      "accuracy: 0.875\n",
      "1--188--24192\n",
      "loss: 0.266304389840751\n",
      "accuracy: 0.90625\n",
      "1--189--24320\n",
      "loss: 0.37257096639163995\n",
      "accuracy: 0.8984375\n",
      "1--190--24448\n",
      "loss: 0.29981049085964\n",
      "accuracy: 0.9140625\n",
      "1--191--24576\n",
      "loss: 0.38319733110183973\n",
      "accuracy: 0.8828125\n",
      "1--192--24704\n",
      "loss: 0.24811099374840245\n",
      "accuracy: 0.9296875\n",
      "1--193--24832\n",
      "loss: 0.29674879569454726\n",
      "accuracy: 0.890625\n",
      "1--194--24960\n",
      "loss: 0.32085245057571016\n",
      "accuracy: 0.9140625\n",
      "1--195--25088\n",
      "loss: 0.22514362115236686\n",
      "accuracy: 0.9453125\n",
      "1--196--25216\n",
      "loss: 0.35118332739436897\n",
      "accuracy: 0.90625\n",
      "1--197--25344\n",
      "loss: 0.36331189238058564\n",
      "accuracy: 0.8984375\n",
      "1--198--25472\n",
      "loss: 0.43987897576972745\n",
      "accuracy: 0.8984375\n",
      "1--199--25600\n",
      "loss: 0.2992579234860539\n",
      "accuracy: 0.9140625\n",
      "1--200--25728\n",
      "loss: 0.26666395603067566\n",
      "accuracy: 0.921875\n",
      "1--201--25856\n",
      "loss: 0.33959145954241765\n",
      "accuracy: 0.875\n",
      "1--202--25984\n",
      "loss: 0.18778093420870265\n",
      "accuracy: 0.9453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1--203--26112\n",
      "loss: 0.2865569033984523\n",
      "accuracy: 0.9296875\n",
      "1--204--26240\n",
      "loss: 0.21680094487446883\n",
      "accuracy: 0.9296875\n",
      "1--205--26368\n",
      "loss: 0.40039280850551406\n",
      "accuracy: 0.8828125\n",
      "1--206--26496\n",
      "loss: 0.2612819367944928\n",
      "accuracy: 0.9296875\n",
      "1--207--26624\n",
      "loss: 0.2174146631443534\n",
      "accuracy: 0.9140625\n",
      "1--208--26752\n",
      "loss: 0.34990426155293114\n",
      "accuracy: 0.890625\n",
      "1--209--26880\n",
      "loss: 0.29917253759405366\n",
      "accuracy: 0.9140625\n",
      "1--210--27008\n",
      "loss: 0.26558348395228615\n",
      "accuracy: 0.921875\n",
      "1--211--27136\n",
      "loss: 0.24778017494325774\n",
      "accuracy: 0.90625\n",
      "1--212--27264\n",
      "loss: 0.32988890825283457\n",
      "accuracy: 0.921875\n",
      "1--213--27392\n",
      "loss: 0.34300200385577806\n",
      "accuracy: 0.890625\n",
      "1--214--27520\n",
      "loss: 0.16635328808727912\n",
      "accuracy: 0.9609375\n",
      "1--215--27648\n",
      "loss: 0.3487208999376741\n",
      "accuracy: 0.8828125\n",
      "1--216--27776\n",
      "loss: 0.2690853334690969\n",
      "accuracy: 0.9375\n",
      "1--217--27904\n",
      "loss: 0.2573507878034015\n",
      "accuracy: 0.953125\n",
      "1--218--28032\n",
      "loss: 0.18163438002118937\n",
      "accuracy: 0.953125\n",
      "1--219--28160\n",
      "loss: 0.2488713683519324\n",
      "accuracy: 0.90625\n",
      "1--220--28288\n",
      "loss: 0.38752866962481713\n",
      "accuracy: 0.8984375\n",
      "1--221--28416\n",
      "loss: 0.2919803677785158\n",
      "accuracy: 0.9296875\n",
      "1--222--28544\n",
      "loss: 0.28305228358316903\n",
      "accuracy: 0.921875\n",
      "1--223--28672\n",
      "loss: 0.1790467076772408\n",
      "accuracy: 0.9375\n",
      "1--224--28800\n",
      "loss: 0.4062359630325349\n",
      "accuracy: 0.875\n",
      "1--225--28928\n",
      "loss: 0.2904809504116944\n",
      "accuracy: 0.9140625\n",
      "1--226--29056\n",
      "loss: 0.28241731071444065\n",
      "accuracy: 0.9140625\n",
      "1--227--29184\n",
      "loss: 0.3828682030580231\n",
      "accuracy: 0.8984375\n",
      "1--228--29312\n",
      "loss: 0.28646853430256464\n",
      "accuracy: 0.9375\n",
      "1--229--29399\n",
      "loss: 0.264525579871738\n",
      "accuracy: 0.9425287356321839\n",
      "2--0--128\n",
      "loss: 0.41297480227306166\n",
      "accuracy: 0.8828125\n",
      "2--1--256\n",
      "loss: 0.2095900004345317\n",
      "accuracy: 0.90625\n",
      "2--2--384\n",
      "loss: 0.4498871229439299\n",
      "accuracy: 0.8515625\n",
      "2--3--512\n",
      "loss: 0.24945104584172287\n",
      "accuracy: 0.921875\n",
      "2--4--640\n",
      "loss: 0.35414364952705124\n",
      "accuracy: 0.8828125\n",
      "2--5--768\n",
      "loss: 0.2939646110547809\n",
      "accuracy: 0.890625\n",
      "2--6--896\n",
      "loss: 0.3091939706757324\n",
      "accuracy: 0.9140625\n",
      "2--7--1024\n",
      "loss: 0.2571216924935017\n",
      "accuracy: 0.9375\n",
      "2--8--1152\n",
      "loss: 0.20645909197731965\n",
      "accuracy: 0.9375\n",
      "2--9--1280\n",
      "loss: 0.3104414523823378\n",
      "accuracy: 0.890625\n",
      "2--10--1408\n",
      "loss: 0.2184377474424078\n",
      "accuracy: 0.953125\n",
      "2--11--1536\n",
      "loss: 0.29064085525491307\n",
      "accuracy: 0.90625\n",
      "2--12--1664\n",
      "loss: 0.22491479480563942\n",
      "accuracy: 0.921875\n",
      "2--13--1792\n",
      "loss: 0.21133533665545923\n",
      "accuracy: 0.9296875\n",
      "2--14--1920\n",
      "loss: 0.2423380305127414\n",
      "accuracy: 0.921875\n",
      "2--15--2048\n",
      "loss: 0.24890249562564684\n",
      "accuracy: 0.90625\n",
      "2--16--2176\n",
      "loss: 0.2825886696565393\n",
      "accuracy: 0.9453125\n",
      "2--17--2304\n",
      "loss: 0.21568460776294934\n",
      "accuracy: 0.9453125\n",
      "2--18--2432\n",
      "loss: 0.2926194451140871\n",
      "accuracy: 0.9375\n",
      "2--19--2560\n",
      "loss: 0.32324067560597225\n",
      "accuracy: 0.8671875\n",
      "2--20--2688\n",
      "loss: 0.21445326906897427\n",
      "accuracy: 0.921875\n",
      "2--21--2816\n",
      "loss: 0.24953987833615443\n",
      "accuracy: 0.8984375\n",
      "2--22--2944\n",
      "loss: 0.3165146470961461\n",
      "accuracy: 0.9140625\n",
      "2--23--3072\n",
      "loss: 0.2774181219834073\n",
      "accuracy: 0.8828125\n",
      "2--24--3200\n",
      "loss: 0.24805744825849274\n",
      "accuracy: 0.9296875\n",
      "2--25--3328\n",
      "loss: 0.23212184482675405\n",
      "accuracy: 0.9140625\n",
      "2--26--3456\n",
      "loss: 0.24363453656942102\n",
      "accuracy: 0.9140625\n",
      "2--27--3584\n",
      "loss: 0.17555438548800228\n",
      "accuracy: 0.9375\n",
      "2--28--3712\n",
      "loss: 0.18427846449609042\n",
      "accuracy: 0.96875\n",
      "2--29--3840\n",
      "loss: 0.24317040363624623\n",
      "accuracy: 0.9140625\n",
      "2--30--3968\n",
      "loss: 0.23315855760406995\n",
      "accuracy: 0.9296875\n",
      "2--31--4096\n",
      "loss: 0.3276961566327781\n",
      "accuracy: 0.90625\n",
      "2--32--4224\n",
      "loss: 0.34578156299598417\n",
      "accuracy: 0.890625\n",
      "2--33--4352\n",
      "loss: 0.25333003369876583\n",
      "accuracy: 0.9453125\n",
      "2--34--4480\n",
      "loss: 0.304330179659014\n",
      "accuracy: 0.9140625\n",
      "2--35--4608\n",
      "loss: 0.32914965068180224\n",
      "accuracy: 0.8984375\n",
      "2--36--4736\n",
      "loss: 0.32612436895112773\n",
      "accuracy: 0.8984375\n",
      "2--37--4864\n",
      "loss: 0.19844040141225544\n",
      "accuracy: 0.921875\n",
      "2--38--4992\n",
      "loss: 0.30154239358182244\n",
      "accuracy: 0.9140625\n",
      "2--39--5120\n",
      "loss: 0.29490817403302727\n",
      "accuracy: 0.9140625\n",
      "2--40--5248\n",
      "loss: 0.33970352800268444\n",
      "accuracy: 0.9140625\n",
      "2--41--5376\n",
      "loss: 0.18036859563125068\n",
      "accuracy: 0.9375\n",
      "2--42--5504\n",
      "loss: 0.23739734169580795\n",
      "accuracy: 0.9296875\n",
      "2--43--5632\n",
      "loss: 0.20872885661170665\n",
      "accuracy: 0.921875\n",
      "2--44--5760\n",
      "loss: 0.26648870747809295\n",
      "accuracy: 0.9296875\n",
      "2--45--5888\n",
      "loss: 0.48318595663357655\n",
      "accuracy: 0.8828125\n",
      "2--46--6016\n",
      "loss: 0.33411854859954526\n",
      "accuracy: 0.9140625\n",
      "2--47--6144\n",
      "loss: 0.22126630810781886\n",
      "accuracy: 0.9296875\n",
      "2--48--6272\n",
      "loss: 0.24762541315395326\n",
      "accuracy: 0.9140625\n",
      "2--49--6400\n",
      "loss: 0.2618460908693576\n",
      "accuracy: 0.9140625\n",
      "2--50--6528\n",
      "loss: 0.38869727542848564\n",
      "accuracy: 0.8828125\n",
      "2--51--6656\n",
      "loss: 0.15288891478661581\n",
      "accuracy: 0.953125\n",
      "2--52--6784\n",
      "loss: 0.2977632557217401\n",
      "accuracy: 0.9453125\n",
      "2--53--6912\n",
      "loss: 0.18113345898406846\n",
      "accuracy: 0.9453125\n",
      "2--54--7040\n",
      "loss: 0.22483104816901783\n",
      "accuracy: 0.9140625\n",
      "2--55--7168\n",
      "loss: 0.36130081463700087\n",
      "accuracy: 0.8828125\n",
      "2--56--7296\n",
      "loss: 0.21099641213736348\n",
      "accuracy: 0.9453125\n",
      "2--57--7424\n",
      "loss: 0.3081717897691191\n",
      "accuracy: 0.921875\n",
      "2--58--7552\n",
      "loss: 0.32521651014020203\n",
      "accuracy: 0.9296875\n",
      "2--59--7680\n",
      "loss: 0.3736985536824024\n",
      "accuracy: 0.8984375\n",
      "2--60--7808\n",
      "loss: 0.19962879155877433\n",
      "accuracy: 0.953125\n",
      "2--61--7936\n",
      "loss: 0.4169072655482665\n",
      "accuracy: 0.8984375\n",
      "2--62--8064\n",
      "loss: 0.2502321834652378\n",
      "accuracy: 0.921875\n",
      "2--63--8192\n",
      "loss: 0.2769833967055244\n",
      "accuracy: 0.9375\n",
      "2--64--8320\n",
      "loss: 0.2508444807950252\n",
      "accuracy: 0.90625\n",
      "2--65--8448\n",
      "loss: 0.17624664860032632\n",
      "accuracy: 0.9609375\n",
      "2--66--8576\n",
      "loss: 0.1695451298105187\n",
      "accuracy: 0.9609375\n",
      "2--67--8704\n",
      "loss: 0.16605490863698505\n",
      "accuracy: 0.96875\n",
      "2--68--8832\n",
      "loss: 0.2890405121043577\n",
      "accuracy: 0.9140625\n",
      "2--69--8960\n",
      "loss: 0.24748217026866132\n",
      "accuracy: 0.9140625\n",
      "2--70--9088\n",
      "loss: 0.20861731371885953\n",
      "accuracy: 0.9375\n",
      "2--71--9216\n",
      "loss: 0.2825250780616856\n",
      "accuracy: 0.90625\n",
      "2--72--9344\n",
      "loss: 0.40437825715842696\n",
      "accuracy: 0.859375\n",
      "2--73--9472\n",
      "loss: 0.2839297651552701\n",
      "accuracy: 0.890625\n",
      "2--74--9600\n",
      "loss: 0.3913316358280359\n",
      "accuracy: 0.9140625\n",
      "2--75--9728\n",
      "loss: 0.2796643443951746\n",
      "accuracy: 0.90625\n",
      "2--76--9856\n",
      "loss: 0.28306431578429436\n",
      "accuracy: 0.9140625\n",
      "2--77--9984\n",
      "loss: 0.2528199115950023\n",
      "accuracy: 0.9453125\n",
      "2--78--10112\n",
      "loss: 0.2703128443962728\n",
      "accuracy: 0.9140625\n",
      "2--79--10240\n",
      "loss: 0.37333851028590603\n",
      "accuracy: 0.90625\n",
      "2--80--10368\n",
      "loss: 0.34076243920984\n",
      "accuracy: 0.9140625\n",
      "2--81--10496\n",
      "loss: 0.20895457743901033\n",
      "accuracy: 0.9296875\n",
      "2--82--10624\n",
      "loss: 0.3041723296770102\n",
      "accuracy: 0.8984375\n",
      "2--83--10752\n",
      "loss: 0.22517690243272198\n",
      "accuracy: 0.921875\n",
      "2--84--10880\n",
      "loss: 0.21302591309926117\n",
      "accuracy: 0.9609375\n",
      "2--85--11008\n",
      "loss: 0.16478433959066557\n",
      "accuracy: 0.9765625\n",
      "2--86--11136\n",
      "loss: 0.2121135236552824\n",
      "accuracy: 0.9453125\n",
      "2--87--11264\n",
      "loss: 0.32445617370757185\n",
      "accuracy: 0.875\n",
      "2--88--11392\n",
      "loss: 0.3528661070679706\n",
      "accuracy: 0.90625\n",
      "2--89--11520\n",
      "loss: 0.1737366836425981\n",
      "accuracy: 0.96875\n",
      "2--90--11648\n",
      "loss: 0.22992210437707247\n",
      "accuracy: 0.953125\n",
      "2--91--11776\n",
      "loss: 0.22804092422966646\n",
      "accuracy: 0.9375\n",
      "2--92--11904\n",
      "loss: 0.3633538410500681\n",
      "accuracy: 0.890625\n",
      "2--93--12032\n",
      "loss: 0.31185641448693435\n",
      "accuracy: 0.890625\n",
      "2--94--12160\n",
      "loss: 0.22168841598813654\n",
      "accuracy: 0.9296875\n",
      "2--95--12288\n",
      "loss: 0.24210022962972927\n",
      "accuracy: 0.9453125\n",
      "2--96--12416\n",
      "loss: 0.2852777315806002\n",
      "accuracy: 0.953125\n",
      "2--97--12544\n",
      "loss: 0.3300314858428248\n",
      "accuracy: 0.8984375\n",
      "2--98--12672\n",
      "loss: 0.1695380125611306\n",
      "accuracy: 0.9609375\n",
      "2--99--12800\n",
      "loss: 0.3444474274836723\n",
      "accuracy: 0.9296875\n",
      "2--100--12928\n",
      "loss: 0.23445092300056292\n",
      "accuracy: 0.90625\n",
      "2--101--13056\n",
      "loss: 0.24135903284966692\n",
      "accuracy: 0.9375\n",
      "2--102--13184\n",
      "loss: 0.15821932983029224\n",
      "accuracy: 0.9609375\n",
      "2--103--13312\n",
      "loss: 0.31495741678562933\n",
      "accuracy: 0.9140625\n",
      "2--104--13440\n",
      "loss: 0.31740745583236285\n",
      "accuracy: 0.8984375\n",
      "2--105--13568\n",
      "loss: 0.35893248500338726\n",
      "accuracy: 0.9140625\n",
      "2--106--13696\n",
      "loss: 0.27255210574826105\n",
      "accuracy: 0.90625\n",
      "2--107--13824\n",
      "loss: 0.24901236937188254\n",
      "accuracy: 0.921875\n",
      "2--108--13952\n",
      "loss: 0.14918541007422717\n",
      "accuracy: 0.9453125\n",
      "2--109--14080\n",
      "loss: 0.2657316662022928\n",
      "accuracy: 0.90625\n",
      "2--110--14208\n",
      "loss: 0.32465846459101516\n",
      "accuracy: 0.890625\n",
      "2--111--14336\n",
      "loss: 0.33264665150686673\n",
      "accuracy: 0.921875\n",
      "2--112--14464\n",
      "loss: 0.23596887446704928\n",
      "accuracy: 0.9296875\n",
      "2--113--14592\n",
      "loss: 0.27232160899680324\n",
      "accuracy: 0.9296875\n",
      "2--114--14720\n",
      "loss: 0.24184169560747548\n",
      "accuracy: 0.9140625\n",
      "2--115--14848\n",
      "loss: 0.25579112019798844\n",
      "accuracy: 0.9140625\n",
      "2--116--14976\n",
      "loss: 0.3346408837307868\n",
      "accuracy: 0.9296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2--117--15104\n",
      "loss: 0.2865716975225735\n",
      "accuracy: 0.9296875\n",
      "2--118--15232\n",
      "loss: 0.2842565280211326\n",
      "accuracy: 0.921875\n",
      "2--119--15360\n",
      "loss: 0.15538020811969724\n",
      "accuracy: 0.96875\n",
      "2--120--15488\n",
      "loss: 0.23394176019223806\n",
      "accuracy: 0.9453125\n",
      "2--121--15616\n",
      "loss: 0.27684753801984474\n",
      "accuracy: 0.9453125\n",
      "2--122--15744\n",
      "loss: 0.34217822744201\n",
      "accuracy: 0.8828125\n",
      "2--123--15872\n",
      "loss: 0.2476873090890031\n",
      "accuracy: 0.9375\n",
      "2--124--16000\n",
      "loss: 0.20952110997057602\n",
      "accuracy: 0.9453125\n",
      "2--125--16128\n",
      "loss: 0.16079385670478685\n",
      "accuracy: 0.9609375\n",
      "2--126--16256\n",
      "loss: 0.23832031661395198\n",
      "accuracy: 0.9375\n",
      "2--127--16384\n",
      "loss: 0.1819166619802945\n",
      "accuracy: 0.9453125\n",
      "2--128--16512\n",
      "loss: 0.2632972538770256\n",
      "accuracy: 0.9140625\n",
      "2--129--16640\n",
      "loss: 0.2538021127031236\n",
      "accuracy: 0.921875\n",
      "2--130--16768\n",
      "loss: 0.24752862182365795\n",
      "accuracy: 0.9296875\n",
      "2--131--16896\n",
      "loss: 0.3242916687207346\n",
      "accuracy: 0.8984375\n",
      "2--132--17024\n",
      "loss: 0.38590803523100325\n",
      "accuracy: 0.8671875\n",
      "2--133--17152\n",
      "loss: 0.13423707209333413\n",
      "accuracy: 0.96875\n",
      "2--134--17280\n",
      "loss: 0.3726634636439494\n",
      "accuracy: 0.9140625\n",
      "2--135--17408\n",
      "loss: 0.30706562614343175\n",
      "accuracy: 0.921875\n",
      "2--136--17536\n",
      "loss: 0.2637006784032402\n",
      "accuracy: 0.9296875\n",
      "2--137--17664\n",
      "loss: 0.2354397578666386\n",
      "accuracy: 0.9296875\n",
      "2--138--17792\n",
      "loss: 0.18185277668011546\n",
      "accuracy: 0.953125\n",
      "2--139--17920\n",
      "loss: 0.20712106106030054\n",
      "accuracy: 0.9296875\n",
      "2--140--18048\n",
      "loss: 0.20028584516431272\n",
      "accuracy: 0.9453125\n",
      "2--141--18176\n",
      "loss: 0.160319364638835\n",
      "accuracy: 0.9609375\n",
      "2--142--18304\n",
      "loss: 0.28160381558916414\n",
      "accuracy: 0.9296875\n",
      "2--143--18432\n",
      "loss: 0.3075902570563753\n",
      "accuracy: 0.9140625\n",
      "2--144--18560\n",
      "loss: 0.23262041070688996\n",
      "accuracy: 0.921875\n",
      "2--145--18688\n",
      "loss: 0.2307890658753357\n",
      "accuracy: 0.9453125\n",
      "2--146--18816\n",
      "loss: 0.2332947331744768\n",
      "accuracy: 0.9375\n",
      "2--147--18944\n",
      "loss: 0.29122206283057905\n",
      "accuracy: 0.9375\n",
      "2--148--19072\n",
      "loss: 0.3226329447371223\n",
      "accuracy: 0.9140625\n",
      "2--149--19200\n",
      "loss: 0.3484057641004431\n",
      "accuracy: 0.90625\n",
      "2--150--19328\n",
      "loss: 0.18193152412620817\n",
      "accuracy: 0.9375\n",
      "2--151--19456\n",
      "loss: 0.21459621045630867\n",
      "accuracy: 0.9453125\n",
      "2--152--19584\n",
      "loss: 0.23706438327201323\n",
      "accuracy: 0.921875\n",
      "2--153--19712\n",
      "loss: 0.26355196858347874\n",
      "accuracy: 0.9296875\n",
      "2--154--19840\n",
      "loss: 0.17753591538695165\n",
      "accuracy: 0.9609375\n",
      "2--155--19968\n",
      "loss: 0.33834344892620816\n",
      "accuracy: 0.90625\n",
      "2--156--20096\n",
      "loss: 0.25595326780822314\n",
      "accuracy: 0.9296875\n",
      "2--157--20224\n",
      "loss: 0.3601323478881924\n",
      "accuracy: 0.9140625\n",
      "2--158--20352\n",
      "loss: 0.19457870534273003\n",
      "accuracy: 0.953125\n",
      "2--159--20480\n",
      "loss: 0.4165983639589841\n",
      "accuracy: 0.890625\n",
      "2--160--20608\n",
      "loss: 0.4490528555325763\n",
      "accuracy: 0.8984375\n",
      "2--161--20736\n",
      "loss: 0.28328074415803906\n",
      "accuracy: 0.921875\n",
      "2--162--20864\n",
      "loss: 0.30240956304893885\n",
      "accuracy: 0.9375\n",
      "2--163--20992\n",
      "loss: 0.2568513982365574\n",
      "accuracy: 0.9140625\n",
      "2--164--21120\n",
      "loss: 0.18131250985581687\n",
      "accuracy: 0.953125\n",
      "2--165--21248\n",
      "loss: 0.14699429659741065\n",
      "accuracy: 0.953125\n",
      "2--166--21376\n",
      "loss: 0.31706058902945033\n",
      "accuracy: 0.90625\n",
      "2--167--21504\n",
      "loss: 0.3401551720161289\n",
      "accuracy: 0.90625\n",
      "2--168--21632\n",
      "loss: 0.2844084192199285\n",
      "accuracy: 0.9375\n",
      "2--169--21760\n",
      "loss: 0.21053867827663994\n",
      "accuracy: 0.9296875\n",
      "2--170--21888\n",
      "loss: 0.25823802670581164\n",
      "accuracy: 0.9296875\n",
      "2--171--22016\n",
      "loss: 0.22607249920934472\n",
      "accuracy: 0.9140625\n",
      "2--172--22144\n",
      "loss: 0.3038543092175032\n",
      "accuracy: 0.921875\n",
      "2--173--22272\n",
      "loss: 0.23870646083340874\n",
      "accuracy: 0.9140625\n",
      "2--174--22400\n",
      "loss: 0.24846726691167115\n",
      "accuracy: 0.9296875\n",
      "2--175--22528\n",
      "loss: 0.24470385664476388\n",
      "accuracy: 0.9296875\n",
      "2--176--22656\n",
      "loss: 0.1806124687829641\n",
      "accuracy: 0.9375\n",
      "2--177--22784\n",
      "loss: 0.18273405034756168\n",
      "accuracy: 0.953125\n",
      "2--178--22912\n",
      "loss: 0.2027859933192368\n",
      "accuracy: 0.9296875\n",
      "2--179--23040\n",
      "loss: 0.24986823784187218\n",
      "accuracy: 0.9296875\n",
      "2--180--23168\n",
      "loss: 0.19533859854996083\n",
      "accuracy: 0.9453125\n",
      "2--181--23296\n",
      "loss: 0.3677866376653006\n",
      "accuracy: 0.9296875\n",
      "2--182--23424\n",
      "loss: 0.24554026759027503\n",
      "accuracy: 0.9296875\n",
      "2--183--23552\n",
      "loss: 0.21762196959795094\n",
      "accuracy: 0.921875\n",
      "2--184--23680\n",
      "loss: 0.2662105171886\n",
      "accuracy: 0.921875\n",
      "2--185--23808\n",
      "loss: 0.1660840008670295\n",
      "accuracy: 0.953125\n",
      "2--186--23936\n",
      "loss: 0.31122251628396386\n",
      "accuracy: 0.8984375\n",
      "2--187--24064\n",
      "loss: 0.4162817839341352\n",
      "accuracy: 0.8828125\n",
      "2--188--24192\n",
      "loss: 0.2463413744563606\n",
      "accuracy: 0.9140625\n",
      "2--189--24320\n",
      "loss: 0.3367019328005427\n",
      "accuracy: 0.9296875\n",
      "2--190--24448\n",
      "loss: 0.26800486477491714\n",
      "accuracy: 0.9140625\n",
      "2--191--24576\n",
      "loss: 0.33900175576320246\n",
      "accuracy: 0.90625\n",
      "2--192--24704\n",
      "loss: 0.21309262477867014\n",
      "accuracy: 0.9296875\n",
      "2--193--24832\n",
      "loss: 0.26249411182650456\n",
      "accuracy: 0.890625\n",
      "2--194--24960\n",
      "loss: 0.2911193561797826\n",
      "accuracy: 0.921875\n",
      "2--195--25088\n",
      "loss: 0.18439977161928411\n",
      "accuracy: 0.953125\n",
      "2--196--25216\n",
      "loss: 0.330365452474791\n",
      "accuracy: 0.90625\n",
      "2--197--25344\n",
      "loss: 0.334585838882031\n",
      "accuracy: 0.8984375\n",
      "2--198--25472\n",
      "loss: 0.4080992206256688\n",
      "accuracy: 0.90625\n",
      "2--199--25600\n",
      "loss: 0.2539642070465923\n",
      "accuracy: 0.9296875\n",
      "2--200--25728\n",
      "loss: 0.23080439146098\n",
      "accuracy: 0.9140625\n",
      "2--201--25856\n",
      "loss: 0.29950389239497976\n",
      "accuracy: 0.890625\n",
      "2--202--25984\n",
      "loss: 0.1683527605199734\n",
      "accuracy: 0.9609375\n",
      "2--203--26112\n",
      "loss: 0.25820327049490455\n",
      "accuracy: 0.9296875\n",
      "2--204--26240\n",
      "loss: 0.18991310727076\n",
      "accuracy: 0.9296875\n",
      "2--205--26368\n",
      "loss: 0.36439684022918317\n",
      "accuracy: 0.8984375\n",
      "2--206--26496\n",
      "loss: 0.2314942880110429\n",
      "accuracy: 0.9453125\n",
      "2--207--26624\n",
      "loss: 0.1760921433105188\n",
      "accuracy: 0.9453125\n",
      "2--208--26752\n",
      "loss: 0.31712116087917164\n",
      "accuracy: 0.8984375\n",
      "2--209--26880\n",
      "loss: 0.2595149905503942\n",
      "accuracy: 0.921875\n",
      "2--210--27008\n",
      "loss: 0.24620583498041496\n",
      "accuracy: 0.921875\n",
      "2--211--27136\n",
      "loss: 0.20015425069101084\n",
      "accuracy: 0.921875\n",
      "2--212--27264\n",
      "loss: 0.2982640786128716\n",
      "accuracy: 0.9296875\n",
      "2--213--27392\n",
      "loss: 0.29850288034480765\n",
      "accuracy: 0.90625\n",
      "2--214--27520\n",
      "loss: 0.1436075425045376\n",
      "accuracy: 0.9609375\n",
      "2--215--27648\n",
      "loss: 0.3121079381468088\n",
      "accuracy: 0.9140625\n",
      "2--216--27776\n",
      "loss: 0.2439864043706989\n",
      "accuracy: 0.9453125\n",
      "2--217--27904\n",
      "loss: 0.23118648951350987\n",
      "accuracy: 0.953125\n",
      "2--218--28032\n",
      "loss: 0.15068444648473175\n",
      "accuracy: 0.953125\n",
      "2--219--28160\n",
      "loss: 0.22199905878627463\n",
      "accuracy: 0.921875\n",
      "2--220--28288\n",
      "loss: 0.36430692142134097\n",
      "accuracy: 0.9140625\n",
      "2--221--28416\n",
      "loss: 0.2617141676801218\n",
      "accuracy: 0.9375\n",
      "2--222--28544\n",
      "loss: 0.2536757968269545\n",
      "accuracy: 0.9375\n",
      "2--223--28672\n",
      "loss: 0.14866535987307758\n",
      "accuracy: 0.9609375\n",
      "2--224--28800\n",
      "loss: 0.3690922334210863\n",
      "accuracy: 0.8828125\n",
      "2--225--28928\n",
      "loss: 0.24808380212528044\n",
      "accuracy: 0.921875\n",
      "2--226--29056\n",
      "loss: 0.24341947850466178\n",
      "accuracy: 0.921875\n",
      "2--227--29184\n",
      "loss: 0.3593018392689412\n",
      "accuracy: 0.890625\n",
      "2--228--29312\n",
      "loss: 0.2504936925562804\n",
      "accuracy: 0.9453125\n",
      "2--229--29399\n",
      "loss: 0.22063736761852928\n",
      "accuracy: 0.9425287356321839\n",
      "3--0--128\n",
      "loss: 0.3745320463317935\n",
      "accuracy: 0.8828125\n",
      "3--1--256\n",
      "loss: 0.1765381238641272\n",
      "accuracy: 0.921875\n",
      "3--2--384\n",
      "loss: 0.40850684569412765\n",
      "accuracy: 0.8828125\n",
      "3--3--512\n",
      "loss: 0.20920549231952767\n",
      "accuracy: 0.9296875\n",
      "3--4--640\n",
      "loss: 0.3209794164394881\n",
      "accuracy: 0.8984375\n",
      "3--5--768\n",
      "loss: 0.2534020132463725\n",
      "accuracy: 0.890625\n",
      "3--6--896\n",
      "loss: 0.28704157529416\n",
      "accuracy: 0.9375\n",
      "3--7--1024\n",
      "loss: 0.22639839524472716\n",
      "accuracy: 0.9375\n",
      "3--8--1152\n",
      "loss: 0.16613340746843647\n",
      "accuracy: 0.953125\n",
      "3--9--1280\n",
      "loss: 0.27589608871360144\n",
      "accuracy: 0.9140625\n",
      "3--10--1408\n",
      "loss: 0.18925423851357123\n",
      "accuracy: 0.953125\n",
      "3--11--1536\n",
      "loss: 0.26580849483043123\n",
      "accuracy: 0.921875\n",
      "3--12--1664\n",
      "loss: 0.19104179546796288\n",
      "accuracy: 0.9296875\n",
      "3--13--1792\n",
      "loss: 0.17638583339019945\n",
      "accuracy: 0.9375\n",
      "3--14--1920\n",
      "loss: 0.21448026487541083\n",
      "accuracy: 0.9375\n",
      "3--15--2048\n",
      "loss: 0.22016247088891672\n",
      "accuracy: 0.921875\n",
      "3--16--2176\n",
      "loss: 0.2527047391065319\n",
      "accuracy: 0.9375\n",
      "3--17--2304\n",
      "loss: 0.17981911637562045\n",
      "accuracy: 0.96875\n",
      "3--18--2432\n",
      "loss: 0.2669384703608221\n",
      "accuracy: 0.9375\n",
      "3--19--2560\n",
      "loss: 0.28442579007151547\n",
      "accuracy: 0.8828125\n",
      "3--20--2688\n",
      "loss: 0.17813960353638758\n",
      "accuracy: 0.9140625\n",
      "3--21--2816\n",
      "loss: 0.21865110870211152\n",
      "accuracy: 0.921875\n",
      "3--22--2944\n",
      "loss: 0.27509824083084006\n",
      "accuracy: 0.921875\n",
      "3--23--3072\n",
      "loss: 0.23921142072095103\n",
      "accuracy: 0.8984375\n",
      "3--24--3200\n",
      "loss: 0.21767698820698217\n",
      "accuracy: 0.9296875\n",
      "3--25--3328\n",
      "loss: 0.2028690185466783\n",
      "accuracy: 0.921875\n",
      "3--26--3456\n",
      "loss: 0.21659859824812155\n",
      "accuracy: 0.9296875\n",
      "3--27--3584\n",
      "loss: 0.14589050644142126\n",
      "accuracy: 0.9609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3--28--3712\n",
      "loss: 0.15476434958466345\n",
      "accuracy: 0.9765625\n",
      "3--29--3840\n",
      "loss: 0.20963772021794147\n",
      "accuracy: 0.921875\n",
      "3--30--3968\n",
      "loss: 0.19256686096944586\n",
      "accuracy: 0.9375\n",
      "3--31--4096\n",
      "loss: 0.2935553955288488\n",
      "accuracy: 0.9140625\n",
      "3--32--4224\n",
      "loss: 0.31115805380222594\n",
      "accuracy: 0.890625\n",
      "3--33--4352\n",
      "loss: 0.22228210539054372\n",
      "accuracy: 0.9453125\n",
      "3--34--4480\n",
      "loss: 0.27013937008115496\n",
      "accuracy: 0.9296875\n",
      "3--35--4608\n",
      "loss: 0.2912872807869159\n",
      "accuracy: 0.9140625\n",
      "3--36--4736\n",
      "loss: 0.26385767368979207\n",
      "accuracy: 0.90625\n",
      "3--37--4864\n",
      "loss: 0.17417162311512116\n",
      "accuracy: 0.9375\n",
      "3--38--4992\n",
      "loss: 0.2830441232612647\n",
      "accuracy: 0.9296875\n",
      "3--39--5120\n",
      "loss: 0.2646953684743941\n",
      "accuracy: 0.9296875\n",
      "3--40--5248\n",
      "loss: 0.3062922665270055\n",
      "accuracy: 0.921875\n",
      "3--41--5376\n",
      "loss: 0.16164009720665318\n",
      "accuracy: 0.953125\n",
      "3--42--5504\n",
      "loss: 0.2028410857948995\n",
      "accuracy: 0.9453125\n",
      "3--43--5632\n",
      "loss: 0.16744005831067754\n",
      "accuracy: 0.9609375\n",
      "3--44--5760\n",
      "loss: 0.23576960184583695\n",
      "accuracy: 0.9453125\n",
      "3--45--5888\n",
      "loss: 0.46464843109209664\n",
      "accuracy: 0.875\n",
      "3--46--6016\n",
      "loss: 0.29749890240877874\n",
      "accuracy: 0.921875\n",
      "3--47--6144\n",
      "loss: 0.19931745766829084\n",
      "accuracy: 0.953125\n",
      "3--48--6272\n",
      "loss: 0.207656166694414\n",
      "accuracy: 0.9296875\n",
      "3--49--6400\n",
      "loss: 0.22317985066242266\n",
      "accuracy: 0.9296875\n",
      "3--50--6528\n",
      "loss: 0.3678140432302166\n",
      "accuracy: 0.8984375\n",
      "3--51--6656\n",
      "loss: 0.12557251065903696\n",
      "accuracy: 0.953125\n",
      "3--52--6784\n",
      "loss: 0.26469874588097364\n",
      "accuracy: 0.9453125\n",
      "3--53--6912\n",
      "loss: 0.15396057337516597\n",
      "accuracy: 0.96875\n",
      "3--54--7040\n",
      "loss: 0.1939151494333302\n",
      "accuracy: 0.9296875\n",
      "3--55--7168\n",
      "loss: 0.3240276571713446\n",
      "accuracy: 0.8828125\n",
      "3--56--7296\n",
      "loss: 0.18379087969607352\n",
      "accuracy: 0.953125\n",
      "3--57--7424\n",
      "loss: 0.2700015345309253\n",
      "accuracy: 0.9296875\n",
      "3--58--7552\n",
      "loss: 0.2995463845850529\n",
      "accuracy: 0.9296875\n",
      "3--59--7680\n",
      "loss: 0.34960616187099947\n",
      "accuracy: 0.8984375\n",
      "3--60--7808\n",
      "loss: 0.1747026191435186\n",
      "accuracy: 0.9609375\n",
      "3--61--7936\n",
      "loss: 0.38299777724865003\n",
      "accuracy: 0.8984375\n",
      "3--62--8064\n",
      "loss: 0.21824070092788705\n",
      "accuracy: 0.9296875\n",
      "3--63--8192\n",
      "loss: 0.25641544606764977\n",
      "accuracy: 0.9375\n",
      "3--64--8320\n",
      "loss: 0.2244944078712317\n",
      "accuracy: 0.9140625\n",
      "3--65--8448\n",
      "loss: 0.15681276479948175\n",
      "accuracy: 0.96875\n",
      "3--66--8576\n",
      "loss: 0.14061251204877187\n",
      "accuracy: 0.9765625\n",
      "3--67--8704\n",
      "loss: 0.13624363454139027\n",
      "accuracy: 0.984375\n",
      "3--68--8832\n",
      "loss: 0.25480349136825803\n",
      "accuracy: 0.921875\n",
      "3--69--8960\n",
      "loss: 0.2124945519907393\n",
      "accuracy: 0.9296875\n",
      "3--70--9088\n",
      "loss: 0.18418825324679364\n",
      "accuracy: 0.9375\n",
      "3--71--9216\n",
      "loss: 0.24583423344589847\n",
      "accuracy: 0.9140625\n",
      "3--72--9344\n",
      "loss: 0.34465764876600485\n",
      "accuracy: 0.8671875\n",
      "3--73--9472\n",
      "loss: 0.24346184984273492\n",
      "accuracy: 0.8984375\n",
      "3--74--9600\n",
      "loss: 0.339775300604188\n",
      "accuracy: 0.921875\n",
      "3--75--9728\n",
      "loss: 0.24977602972556884\n",
      "accuracy: 0.9140625\n",
      "3--76--9856\n",
      "loss: 0.2405953563977826\n",
      "accuracy: 0.921875\n",
      "3--77--9984\n",
      "loss: 0.22003559270214168\n",
      "accuracy: 0.953125\n",
      "3--78--10112\n",
      "loss: 0.24085194417613984\n",
      "accuracy: 0.921875\n",
      "3--79--10240\n",
      "loss: 0.3346375985492658\n",
      "accuracy: 0.921875\n",
      "3--80--10368\n",
      "loss: 0.30321625324114737\n",
      "accuracy: 0.9296875\n",
      "3--81--10496\n",
      "loss: 0.17295977350295555\n",
      "accuracy: 0.9296875\n",
      "3--82--10624\n",
      "loss: 0.2758450290857206\n",
      "accuracy: 0.90625\n",
      "3--83--10752\n",
      "loss: 0.19321882182395939\n",
      "accuracy: 0.9375\n",
      "3--84--10880\n",
      "loss: 0.18686850469871336\n",
      "accuracy: 0.96875\n",
      "3--85--11008\n",
      "loss: 0.13565538699071408\n",
      "accuracy: 0.984375\n",
      "3--86--11136\n",
      "loss: 0.1873672214306457\n",
      "accuracy: 0.9375\n",
      "3--87--11264\n",
      "loss: 0.30052036853406994\n",
      "accuracy: 0.8828125\n",
      "3--88--11392\n",
      "loss: 0.32509252712755105\n",
      "accuracy: 0.90625\n",
      "3--89--11520\n",
      "loss: 0.14436656144871424\n",
      "accuracy: 0.9765625\n",
      "3--90--11648\n",
      "loss: 0.19741723433904124\n",
      "accuracy: 0.9609375\n",
      "3--91--11776\n",
      "loss: 0.199206717368618\n",
      "accuracy: 0.9375\n",
      "3--92--11904\n",
      "loss: 0.33926617092585776\n",
      "accuracy: 0.890625\n",
      "3--93--12032\n",
      "loss: 0.2729901199704835\n",
      "accuracy: 0.90625\n",
      "3--94--12160\n",
      "loss: 0.19162003928997215\n",
      "accuracy: 0.9296875\n",
      "3--95--12288\n",
      "loss: 0.21215231893450287\n",
      "accuracy: 0.953125\n",
      "3--96--12416\n",
      "loss: 0.25332895662748023\n",
      "accuracy: 0.953125\n",
      "3--97--12544\n",
      "loss: 0.3003618677233149\n",
      "accuracy: 0.8984375\n",
      "3--98--12672\n",
      "loss: 0.15554875667870727\n",
      "accuracy: 0.96875\n",
      "3--99--12800\n",
      "loss: 0.3243784842657135\n",
      "accuracy: 0.9375\n",
      "3--100--12928\n",
      "loss: 0.20262561838601315\n",
      "accuracy: 0.9375\n",
      "3--101--13056\n",
      "loss: 0.21068553752962627\n",
      "accuracy: 0.9453125\n",
      "3--102--13184\n",
      "loss: 0.13012513994354524\n",
      "accuracy: 0.96875\n",
      "3--103--13312\n",
      "loss: 0.2770658745666306\n",
      "accuracy: 0.9140625\n",
      "3--104--13440\n",
      "loss: 0.28400294694329287\n",
      "accuracy: 0.90625\n",
      "3--105--13568\n",
      "loss: 0.31554719153324196\n",
      "accuracy: 0.9140625\n",
      "3--106--13696\n",
      "loss: 0.24877068126284868\n",
      "accuracy: 0.9140625\n",
      "3--107--13824\n",
      "loss: 0.2154044747494045\n",
      "accuracy: 0.9296875\n",
      "3--108--13952\n",
      "loss: 0.131144160558513\n",
      "accuracy: 0.9453125\n",
      "3--109--14080\n",
      "loss: 0.2373595195423747\n",
      "accuracy: 0.9296875\n",
      "3--110--14208\n",
      "loss: 0.2922304045253362\n",
      "accuracy: 0.90625\n",
      "3--111--14336\n",
      "loss: 0.30749746393031957\n",
      "accuracy: 0.921875\n",
      "3--112--14464\n",
      "loss: 0.20976433386778454\n",
      "accuracy: 0.921875\n",
      "3--113--14592\n",
      "loss: 0.24475433993601697\n",
      "accuracy: 0.9375\n",
      "3--114--14720\n",
      "loss: 0.222466999229747\n",
      "accuracy: 0.9140625\n",
      "3--115--14848\n",
      "loss: 0.23105961423305357\n",
      "accuracy: 0.921875\n",
      "3--116--14976\n",
      "loss: 0.3116676254120633\n",
      "accuracy: 0.921875\n",
      "3--117--15104\n",
      "loss: 0.26789192257455996\n",
      "accuracy: 0.9296875\n",
      "3--118--15232\n",
      "loss: 0.25444517732221655\n",
      "accuracy: 0.9296875\n",
      "3--119--15360\n",
      "loss: 0.13993826454596633\n",
      "accuracy: 0.9609375\n",
      "3--120--15488\n",
      "loss: 0.20500716513045578\n",
      "accuracy: 0.9453125\n",
      "3--121--15616\n",
      "loss: 0.2522686076300354\n",
      "accuracy: 0.953125\n",
      "3--122--15744\n",
      "loss: 0.3120215876278157\n",
      "accuracy: 0.890625\n",
      "3--123--15872\n",
      "loss: 0.22439185976795567\n",
      "accuracy: 0.953125\n",
      "3--124--16000\n",
      "loss: 0.1799474290230641\n",
      "accuracy: 0.953125\n",
      "3--125--16128\n",
      "loss: 0.14147879798266644\n",
      "accuracy: 0.9609375\n",
      "3--126--16256\n",
      "loss: 0.2135019355738374\n",
      "accuracy: 0.9453125\n",
      "3--127--16384\n",
      "loss: 0.15531874735301482\n",
      "accuracy: 0.9453125\n",
      "3--128--16512\n",
      "loss: 0.23679262203443788\n",
      "accuracy: 0.9375\n",
      "3--129--16640\n",
      "loss: 0.22197865983411122\n",
      "accuracy: 0.9375\n",
      "3--130--16768\n",
      "loss: 0.21940627808132357\n",
      "accuracy: 0.9296875\n",
      "3--131--16896\n",
      "loss: 0.28005867536360074\n",
      "accuracy: 0.90625\n",
      "3--132--17024\n",
      "loss: 0.3578435426570293\n",
      "accuracy: 0.8828125\n",
      "3--133--17152\n",
      "loss: 0.11338385456927327\n",
      "accuracy: 0.9765625\n",
      "3--134--17280\n",
      "loss: 0.3415443389693035\n",
      "accuracy: 0.9140625\n",
      "3--135--17408\n",
      "loss: 0.2887996571925874\n",
      "accuracy: 0.9375\n",
      "3--136--17536\n",
      "loss: 0.2285472093088697\n",
      "accuracy: 0.9453125\n",
      "3--137--17664\n",
      "loss: 0.20921180277170026\n",
      "accuracy: 0.9296875\n",
      "3--138--17792\n",
      "loss: 0.15668103143074524\n",
      "accuracy: 0.9609375\n",
      "3--139--17920\n",
      "loss: 0.1838888004431584\n",
      "accuracy: 0.9375\n",
      "3--140--18048\n",
      "loss: 0.18002870963326909\n",
      "accuracy: 0.9453125\n",
      "3--141--18176\n",
      "loss: 0.13937151315372437\n",
      "accuracy: 0.96875\n",
      "3--142--18304\n",
      "loss: 0.2634648618923728\n",
      "accuracy: 0.9296875\n",
      "3--143--18432\n",
      "loss: 0.28571718449796507\n",
      "accuracy: 0.921875\n",
      "3--144--18560\n",
      "loss: 0.20686194032230174\n",
      "accuracy: 0.9453125\n",
      "3--145--18688\n",
      "loss: 0.19763393788576372\n",
      "accuracy: 0.953125\n",
      "3--146--18816\n",
      "loss: 0.2193465554697649\n",
      "accuracy: 0.9296875\n",
      "3--147--18944\n",
      "loss: 0.26585812557861527\n",
      "accuracy: 0.9375\n",
      "3--148--19072\n",
      "loss: 0.30112142216750043\n",
      "accuracy: 0.9140625\n",
      "3--149--19200\n",
      "loss: 0.3243199087337086\n",
      "accuracy: 0.9140625\n",
      "3--150--19328\n",
      "loss: 0.16382241998975583\n",
      "accuracy: 0.9375\n",
      "3--151--19456\n",
      "loss: 0.18563720728314484\n",
      "accuracy: 0.953125\n",
      "3--152--19584\n",
      "loss: 0.20656745037177093\n",
      "accuracy: 0.9296875\n",
      "3--153--19712\n",
      "loss: 0.23810761953499693\n",
      "accuracy: 0.9296875\n",
      "3--154--19840\n",
      "loss: 0.1548725005860651\n",
      "accuracy: 0.9609375\n",
      "3--155--19968\n",
      "loss: 0.298470001184726\n",
      "accuracy: 0.9140625\n",
      "3--156--20096\n",
      "loss: 0.2306427706670859\n",
      "accuracy: 0.9296875\n",
      "3--157--20224\n",
      "loss: 0.3233230351495567\n",
      "accuracy: 0.921875\n",
      "3--158--20352\n",
      "loss: 0.17361598648958626\n",
      "accuracy: 0.953125\n",
      "3--159--20480\n",
      "loss: 0.38208914295336505\n",
      "accuracy: 0.8984375\n",
      "3--160--20608\n",
      "loss: 0.4104934854413442\n",
      "accuracy: 0.8984375\n",
      "3--161--20736\n",
      "loss: 0.25651673267690256\n",
      "accuracy: 0.921875\n",
      "3--162--20864\n",
      "loss: 0.28110807373276336\n",
      "accuracy: 0.9296875\n",
      "3--163--20992\n",
      "loss: 0.2199780238960099\n",
      "accuracy: 0.9453125\n",
      "3--164--21120\n",
      "loss: 0.16732272763335393\n",
      "accuracy: 0.9609375\n",
      "3--165--21248\n",
      "loss: 0.12567062033902904\n",
      "accuracy: 0.953125\n",
      "3--166--21376\n",
      "loss: 0.281199237411468\n",
      "accuracy: 0.9296875\n",
      "3--167--21504\n",
      "loss: 0.315100171083197\n",
      "accuracy: 0.9296875\n",
      "3--168--21632\n",
      "loss: 0.26477824986694243\n",
      "accuracy: 0.9375\n",
      "3--169--21760\n",
      "loss: 0.17936424944034757\n",
      "accuracy: 0.9296875\n",
      "3--170--21888\n",
      "loss: 0.23142626705254665\n",
      "accuracy: 0.953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3--171--22016\n",
      "loss: 0.20269827750146835\n",
      "accuracy: 0.9453125\n",
      "3--172--22144\n",
      "loss: 0.2588965698420835\n",
      "accuracy: 0.9296875\n",
      "3--173--22272\n",
      "loss: 0.21502885393132234\n",
      "accuracy: 0.9375\n",
      "3--174--22400\n",
      "loss: 0.22419890984898766\n",
      "accuracy: 0.9296875\n",
      "3--175--22528\n",
      "loss: 0.22314713745701986\n",
      "accuracy: 0.9296875\n",
      "3--176--22656\n",
      "loss: 0.15580721978836176\n",
      "accuracy: 0.9453125\n",
      "3--177--22784\n",
      "loss: 0.162110652372484\n",
      "accuracy: 0.953125\n",
      "3--178--22912\n",
      "loss: 0.18279046493003864\n",
      "accuracy: 0.9296875\n",
      "3--179--23040\n",
      "loss: 0.22865221778473802\n",
      "accuracy: 0.9296875\n",
      "3--180--23168\n",
      "loss: 0.17347179831609896\n",
      "accuracy: 0.9453125\n",
      "3--181--23296\n",
      "loss: 0.33143032935327177\n",
      "accuracy: 0.9375\n",
      "3--182--23424\n",
      "loss: 0.2190145232734133\n",
      "accuracy: 0.9375\n",
      "3--183--23552\n",
      "loss: 0.18728222620018842\n",
      "accuracy: 0.9453125\n",
      "3--184--23680\n",
      "loss: 0.22847741936658794\n",
      "accuracy: 0.9296875\n",
      "3--185--23808\n",
      "loss: 0.14818933356004754\n",
      "accuracy: 0.953125\n",
      "3--186--23936\n",
      "loss: 0.28452760562922147\n",
      "accuracy: 0.9140625\n",
      "3--187--24064\n",
      "loss: 0.38724581696704\n",
      "accuracy: 0.90625\n",
      "3--188--24192\n",
      "loss: 0.23412607444498348\n",
      "accuracy: 0.9140625\n",
      "3--189--24320\n",
      "loss: 0.31324863102184547\n",
      "accuracy: 0.921875\n",
      "3--190--24448\n",
      "loss: 0.24131707773509908\n",
      "accuracy: 0.9140625\n",
      "3--191--24576\n",
      "loss: 0.3110173913143684\n",
      "accuracy: 0.9375\n",
      "3--192--24704\n",
      "loss: 0.18933270700318267\n",
      "accuracy: 0.9296875\n",
      "3--193--24832\n",
      "loss: 0.23855157983007383\n",
      "accuracy: 0.90625\n",
      "3--194--24960\n",
      "loss: 0.26874594511614863\n",
      "accuracy: 0.921875\n",
      "3--195--25088\n",
      "loss: 0.15928946126189414\n",
      "accuracy: 0.953125\n",
      "3--196--25216\n",
      "loss: 0.31588452324415006\n",
      "accuracy: 0.9140625\n",
      "3--197--25344\n",
      "loss: 0.31726920248946183\n",
      "accuracy: 0.890625\n",
      "3--198--25472\n",
      "loss: 0.3837290845948226\n",
      "accuracy: 0.90625\n",
      "3--199--25600\n",
      "loss: 0.22038921926564425\n",
      "accuracy: 0.9296875\n",
      "3--200--25728\n",
      "loss: 0.2062671181900289\n",
      "accuracy: 0.9296875\n",
      "3--201--25856\n",
      "loss: 0.2740134276749661\n",
      "accuracy: 0.890625\n",
      "3--202--25984\n",
      "loss: 0.15466762721039468\n",
      "accuracy: 0.953125\n",
      "3--203--26112\n",
      "loss: 0.2358239745467462\n",
      "accuracy: 0.9453125\n",
      "3--204--26240\n",
      "loss: 0.17278130579000855\n",
      "accuracy: 0.9296875\n",
      "3--205--26368\n",
      "loss: 0.33698415925294767\n",
      "accuracy: 0.8984375\n",
      "3--206--26496\n",
      "loss: 0.2169866154607956\n",
      "accuracy: 0.9453125\n",
      "3--207--26624\n",
      "loss: 0.15128205002457126\n",
      "accuracy: 0.953125\n",
      "3--208--26752\n",
      "loss: 0.29209547977912753\n",
      "accuracy: 0.90625\n",
      "3--209--26880\n",
      "loss: 0.2283484310448265\n",
      "accuracy: 0.921875\n",
      "3--210--27008\n",
      "loss: 0.22964551457613414\n",
      "accuracy: 0.9296875\n",
      "3--211--27136\n",
      "loss: 0.17002546106690036\n",
      "accuracy: 0.9375\n",
      "3--212--27264\n",
      "loss: 0.2741262246464584\n",
      "accuracy: 0.9375\n",
      "3--213--27392\n",
      "loss: 0.2656441750577784\n",
      "accuracy: 0.921875\n",
      "3--214--27520\n",
      "loss: 0.1285712413813624\n",
      "accuracy: 0.9609375\n",
      "3--215--27648\n",
      "loss: 0.2859290627092792\n",
      "accuracy: 0.921875\n",
      "3--216--27776\n",
      "loss: 0.22680448194467956\n",
      "accuracy: 0.9453125\n",
      "3--217--27904\n",
      "loss: 0.2117715718789138\n",
      "accuracy: 0.953125\n",
      "3--218--28032\n",
      "loss: 0.1314429630482407\n",
      "accuracy: 0.9609375\n",
      "3--219--28160\n",
      "loss: 0.20354789307960947\n",
      "accuracy: 0.9296875\n",
      "3--220--28288\n",
      "loss: 0.34624666484090116\n",
      "accuracy: 0.9140625\n",
      "3--221--28416\n",
      "loss: 0.2404357052827938\n",
      "accuracy: 0.9453125\n",
      "3--222--28544\n",
      "loss: 0.23452090810490678\n",
      "accuracy: 0.9375\n",
      "3--223--28672\n",
      "loss: 0.13009297025790123\n",
      "accuracy: 0.96875\n",
      "3--224--28800\n",
      "loss: 0.3404381906934405\n",
      "accuracy: 0.8828125\n",
      "3--225--28928\n",
      "loss: 0.21532846926624505\n",
      "accuracy: 0.9296875\n",
      "3--226--29056\n",
      "loss: 0.21589707960095458\n",
      "accuracy: 0.9296875\n",
      "3--227--29184\n",
      "loss: 0.33927296560833353\n",
      "accuracy: 0.90625\n",
      "3--228--29312\n",
      "loss: 0.22650685669148865\n",
      "accuracy: 0.9609375\n",
      "3--229--29399\n",
      "loss: 0.19164046936831947\n",
      "accuracy: 0.9540229885057471\n",
      "4--0--128\n",
      "loss: 0.3473088051415014\n",
      "accuracy: 0.90625\n",
      "4--1--256\n",
      "loss: 0.15428242324710867\n",
      "accuracy: 0.9375\n",
      "4--2--384\n",
      "loss: 0.37500307217663864\n",
      "accuracy: 0.90625\n",
      "4--3--512\n",
      "loss: 0.1815322082835928\n",
      "accuracy: 0.953125\n",
      "4--4--640\n",
      "loss: 0.2972646514343184\n",
      "accuracy: 0.9140625\n",
      "4--5--768\n",
      "loss: 0.2269057940372407\n",
      "accuracy: 0.90625\n",
      "4--6--896\n",
      "loss: 0.27017837621791474\n",
      "accuracy: 0.9375\n",
      "4--7--1024\n",
      "loss: 0.20194329997101157\n",
      "accuracy: 0.953125\n",
      "4--8--1152\n",
      "loss: 0.13871473440808663\n",
      "accuracy: 0.96875\n",
      "4--9--1280\n",
      "loss: 0.25156409428341875\n",
      "accuracy: 0.9375\n",
      "4--10--1408\n",
      "loss: 0.16917108262921082\n",
      "accuracy: 0.9453125\n",
      "4--11--1536\n",
      "loss: 0.25106344389194196\n",
      "accuracy: 0.921875\n",
      "4--12--1664\n",
      "loss: 0.16522813941787873\n",
      "accuracy: 0.9375\n",
      "4--13--1792\n",
      "loss: 0.14974199139824937\n",
      "accuracy: 0.9453125\n",
      "4--14--1920\n",
      "loss: 0.19369690187848487\n",
      "accuracy: 0.9375\n",
      "4--15--2048\n",
      "loss: 0.2022024558474352\n",
      "accuracy: 0.9375\n",
      "4--16--2176\n",
      "loss: 0.23041068018716826\n",
      "accuracy: 0.9296875\n",
      "4--17--2304\n",
      "loss: 0.15476320409008287\n",
      "accuracy: 0.96875\n",
      "4--18--2432\n",
      "loss: 0.24931002066930358\n",
      "accuracy: 0.9375\n",
      "4--19--2560\n",
      "loss: 0.25491599937387277\n",
      "accuracy: 0.8984375\n",
      "4--20--2688\n",
      "loss: 0.15476600160173345\n",
      "accuracy: 0.9453125\n",
      "4--21--2816\n",
      "loss: 0.19643573223148397\n",
      "accuracy: 0.9453125\n",
      "4--22--2944\n",
      "loss: 0.24517442339337248\n",
      "accuracy: 0.921875\n",
      "4--23--3072\n",
      "loss: 0.21200875264688832\n",
      "accuracy: 0.90625\n",
      "4--24--3200\n",
      "loss: 0.19505017818358517\n",
      "accuracy: 0.9296875\n",
      "4--25--3328\n",
      "loss: 0.1826320411269322\n",
      "accuracy: 0.9296875\n",
      "4--26--3456\n",
      "loss: 0.19641328210435197\n",
      "accuracy: 0.9375\n",
      "4--27--3584\n",
      "loss: 0.12611286227673485\n",
      "accuracy: 0.9765625\n",
      "4--28--3712\n",
      "loss: 0.13657313203172913\n",
      "accuracy: 0.9765625\n",
      "4--29--3840\n",
      "loss: 0.18324998744253815\n",
      "accuracy: 0.921875\n",
      "4--30--3968\n",
      "loss: 0.1664113700761874\n",
      "accuracy: 0.953125\n",
      "4--31--4096\n",
      "loss: 0.26635131519878735\n",
      "accuracy: 0.921875\n",
      "4--32--4224\n",
      "loss: 0.2853510030561251\n",
      "accuracy: 0.90625\n",
      "4--33--4352\n",
      "loss: 0.20020656143892762\n",
      "accuracy: 0.9453125\n",
      "4--34--4480\n",
      "loss: 0.24249131302136415\n",
      "accuracy: 0.9375\n",
      "4--35--4608\n",
      "loss: 0.26238445519874126\n",
      "accuracy: 0.921875\n",
      "4--36--4736\n",
      "loss: 0.21844266493189404\n",
      "accuracy: 0.921875\n",
      "4--37--4864\n",
      "loss: 0.1561034364678347\n",
      "accuracy: 0.9453125\n",
      "4--38--4992\n",
      "loss: 0.2677910279698471\n",
      "accuracy: 0.9375\n",
      "4--39--5120\n",
      "loss: 0.2427759930482481\n",
      "accuracy: 0.9375\n",
      "4--40--5248\n",
      "loss: 0.27953890523266095\n",
      "accuracy: 0.921875\n",
      "4--41--5376\n",
      "loss: 0.1465806537936306\n",
      "accuracy: 0.953125\n",
      "4--42--5504\n",
      "loss: 0.18123259151700336\n",
      "accuracy: 0.953125\n",
      "4--43--5632\n",
      "loss: 0.1435829575107308\n",
      "accuracy: 0.96875\n",
      "4--44--5760\n",
      "loss: 0.2125016978091369\n",
      "accuracy: 0.9453125\n",
      "4--45--5888\n",
      "loss: 0.4481392480613742\n",
      "accuracy: 0.8984375\n",
      "4--46--6016\n",
      "loss: 0.2702537618802683\n",
      "accuracy: 0.921875\n",
      "4--47--6144\n",
      "loss: 0.18283551723862518\n",
      "accuracy: 0.9453125\n",
      "4--48--6272\n",
      "loss: 0.17867901965222555\n",
      "accuracy: 0.9375\n",
      "4--49--6400\n",
      "loss: 0.19651405392506305\n",
      "accuracy: 0.9453125\n",
      "4--50--6528\n",
      "loss: 0.35061490405634477\n",
      "accuracy: 0.9140625\n",
      "4--51--6656\n",
      "loss: 0.10809483273868442\n",
      "accuracy: 0.9609375\n",
      "4--52--6784\n",
      "loss: 0.240513989807428\n",
      "accuracy: 0.9453125\n",
      "4--53--6912\n",
      "loss: 0.13724038582854647\n",
      "accuracy: 0.96875\n",
      "4--54--7040\n",
      "loss: 0.17101238811748826\n",
      "accuracy: 0.9453125\n",
      "4--55--7168\n",
      "loss: 0.29441668060912407\n",
      "accuracy: 0.90625\n",
      "4--56--7296\n",
      "loss: 0.16452451309253402\n",
      "accuracy: 0.9609375\n",
      "4--57--7424\n",
      "loss: 0.24082398873956268\n",
      "accuracy: 0.9296875\n",
      "4--58--7552\n",
      "loss: 0.2778889909123381\n",
      "accuracy: 0.9375\n",
      "4--59--7680\n",
      "loss: 0.3298402637834492\n",
      "accuracy: 0.8984375\n",
      "4--60--7808\n",
      "loss: 0.1553944237373288\n",
      "accuracy: 0.9609375\n",
      "4--61--7936\n",
      "loss: 0.35485255000983607\n",
      "accuracy: 0.90625\n",
      "4--62--8064\n",
      "loss: 0.1948582347072141\n",
      "accuracy: 0.9296875\n",
      "4--63--8192\n",
      "loss: 0.23878496423497722\n",
      "accuracy: 0.9375\n",
      "4--64--8320\n",
      "loss: 0.2045332184594949\n",
      "accuracy: 0.9296875\n",
      "4--65--8448\n",
      "loss: 0.14264787525536632\n",
      "accuracy: 0.96875\n",
      "4--66--8576\n",
      "loss: 0.11739757367912226\n",
      "accuracy: 0.984375\n",
      "4--67--8704\n",
      "loss: 0.1172478313721293\n",
      "accuracy: 0.984375\n",
      "4--68--8832\n",
      "loss: 0.22946253865868732\n",
      "accuracy: 0.9296875\n",
      "4--69--8960\n",
      "loss: 0.18877786673706287\n",
      "accuracy: 0.9296875\n",
      "4--70--9088\n",
      "loss: 0.16647309722415377\n",
      "accuracy: 0.9375\n",
      "4--71--9216\n",
      "loss: 0.21686925469957624\n",
      "accuracy: 0.921875\n",
      "4--72--9344\n",
      "loss: 0.3004506879534851\n",
      "accuracy: 0.8984375\n",
      "4--73--9472\n",
      "loss: 0.21345709275904298\n",
      "accuracy: 0.9140625\n",
      "4--74--9600\n",
      "loss: 0.299903373615383\n",
      "accuracy: 0.9375\n",
      "4--75--9728\n",
      "loss: 0.2280047940999874\n",
      "accuracy: 0.921875\n",
      "4--76--9856\n",
      "loss: 0.21340339241198036\n",
      "accuracy: 0.9296875\n",
      "4--77--9984\n",
      "loss: 0.1946250906128487\n",
      "accuracy: 0.953125\n",
      "4--78--10112\n",
      "loss: 0.21743654820372293\n",
      "accuracy: 0.9375\n",
      "4--79--10240\n",
      "loss: 0.30261909374368307\n",
      "accuracy: 0.9296875\n",
      "4--80--10368\n",
      "loss: 0.27454156512842964\n",
      "accuracy: 0.9375\n",
      "4--81--10496\n",
      "loss: 0.1464114812107803\n",
      "accuracy: 0.9296875\n",
      "4--82--10624\n",
      "loss: 0.25514153396439165\n",
      "accuracy: 0.921875\n",
      "4--83--10752\n",
      "loss: 0.1709068042614178\n",
      "accuracy: 0.9453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4--84--10880\n",
      "loss: 0.16743564711697892\n",
      "accuracy: 0.96875\n",
      "4--85--11008\n",
      "loss: 0.11638199466205286\n",
      "accuracy: 0.984375\n",
      "4--86--11136\n",
      "loss: 0.16856729568199957\n",
      "accuracy: 0.9375\n",
      "4--87--11264\n",
      "loss: 0.2794145724214695\n",
      "accuracy: 0.8828125\n",
      "4--88--11392\n",
      "loss: 0.3054642257222573\n",
      "accuracy: 0.9140625\n",
      "4--89--11520\n",
      "loss: 0.12453490668140726\n",
      "accuracy: 0.9765625\n",
      "4--90--11648\n",
      "loss: 0.17515790705420367\n",
      "accuracy: 0.9609375\n",
      "4--91--11776\n",
      "loss: 0.17861904539316117\n",
      "accuracy: 0.9375\n",
      "4--92--11904\n",
      "loss: 0.31995014502137664\n",
      "accuracy: 0.8984375\n",
      "4--93--12032\n",
      "loss: 0.2436488524129315\n",
      "accuracy: 0.90625\n",
      "4--94--12160\n",
      "loss: 0.1703556926923637\n",
      "accuracy: 0.9296875\n",
      "4--95--12288\n",
      "loss: 0.18831394732996187\n",
      "accuracy: 0.9609375\n",
      "4--96--12416\n",
      "loss: 0.22949011741845593\n",
      "accuracy: 0.953125\n",
      "4--97--12544\n",
      "loss: 0.27616845829241937\n",
      "accuracy: 0.921875\n",
      "4--98--12672\n",
      "loss: 0.14695358523738591\n",
      "accuracy: 0.9765625\n",
      "4--99--12800\n",
      "loss: 0.30826419021214185\n",
      "accuracy: 0.9375\n",
      "4--100--12928\n",
      "loss: 0.18105837965519433\n",
      "accuracy: 0.9375\n",
      "4--101--13056\n",
      "loss: 0.18731779436385565\n",
      "accuracy: 0.953125\n",
      "4--102--13184\n",
      "loss: 0.11130700355349205\n",
      "accuracy: 0.984375\n",
      "4--103--13312\n",
      "loss: 0.24891680748961395\n",
      "accuracy: 0.921875\n",
      "4--104--13440\n",
      "loss: 0.25547673533514453\n",
      "accuracy: 0.90625\n",
      "4--105--13568\n",
      "loss: 0.2818721579774377\n",
      "accuracy: 0.921875\n",
      "4--106--13696\n",
      "loss: 0.22940536771990566\n",
      "accuracy: 0.9140625\n",
      "4--107--13824\n",
      "loss: 0.19020368644408786\n",
      "accuracy: 0.9375\n",
      "4--108--13952\n",
      "loss: 0.11716078346317024\n",
      "accuracy: 0.9453125\n",
      "4--109--14080\n",
      "loss: 0.21700612276952325\n",
      "accuracy: 0.9375\n",
      "4--110--14208\n",
      "loss: 0.26972577169365375\n",
      "accuracy: 0.921875\n",
      "4--111--14336\n",
      "loss: 0.2887339675476138\n",
      "accuracy: 0.921875\n",
      "4--112--14464\n",
      "loss: 0.18881120132325035\n",
      "accuracy: 0.9375\n",
      "4--113--14592\n",
      "loss: 0.22230948023186783\n",
      "accuracy: 0.9375\n",
      "4--114--14720\n",
      "loss: 0.2090757623249052\n",
      "accuracy: 0.921875\n",
      "4--115--14848\n",
      "loss: 0.2154870685738199\n",
      "accuracy: 0.9375\n",
      "4--116--14976\n",
      "loss: 0.29120060812002957\n",
      "accuracy: 0.921875\n",
      "4--117--15104\n",
      "loss: 0.2516875210804145\n",
      "accuracy: 0.9375\n",
      "4--118--15232\n",
      "loss: 0.22774257295586295\n",
      "accuracy: 0.9375\n",
      "4--119--15360\n",
      "loss: 0.12830747834828649\n",
      "accuracy: 0.9609375\n",
      "4--120--15488\n",
      "loss: 0.18224703284315363\n",
      "accuracy: 0.9453125\n",
      "4--121--15616\n",
      "loss: 0.23220465376461624\n",
      "accuracy: 0.9609375\n",
      "4--122--15744\n",
      "loss: 0.2878933457801678\n",
      "accuracy: 0.8984375\n",
      "4--123--15872\n",
      "loss: 0.20799687716837523\n",
      "accuracy: 0.953125\n",
      "4--124--16000\n",
      "loss: 0.16005518551703846\n",
      "accuracy: 0.96875\n",
      "4--125--16128\n",
      "loss: 0.12793902310279098\n",
      "accuracy: 0.9609375\n",
      "4--126--16256\n",
      "loss: 0.1943362312528348\n",
      "accuracy: 0.9453125\n",
      "4--127--16384\n",
      "loss: 0.13553740913317208\n",
      "accuracy: 0.9453125\n",
      "4--128--16512\n",
      "loss: 0.21666334408277954\n",
      "accuracy: 0.9453125\n",
      "4--129--16640\n",
      "loss: 0.19770677363120415\n",
      "accuracy: 0.9453125\n",
      "4--130--16768\n",
      "loss: 0.19717726710284267\n",
      "accuracy: 0.9609375\n",
      "4--131--16896\n",
      "loss: 0.24574046325169377\n",
      "accuracy: 0.90625\n",
      "4--132--17024\n",
      "loss: 0.33301069539701794\n",
      "accuracy: 0.890625\n",
      "4--133--17152\n",
      "loss: 0.09897151645755026\n",
      "accuracy: 0.9765625\n",
      "4--134--17280\n",
      "loss: 0.31608486211452164\n",
      "accuracy: 0.9140625\n",
      "4--135--17408\n",
      "loss: 0.27509729254516707\n",
      "accuracy: 0.9375\n",
      "4--136--17536\n",
      "loss: 0.2021883310457841\n",
      "accuracy: 0.953125\n",
      "4--137--17664\n",
      "loss: 0.19067923928799974\n",
      "accuracy: 0.9296875\n",
      "4--138--17792\n",
      "loss: 0.13823823582555483\n",
      "accuracy: 0.96875\n",
      "4--139--17920\n",
      "loss: 0.16702620005478624\n",
      "accuracy: 0.9375\n",
      "4--140--18048\n",
      "loss: 0.16477472685298683\n",
      "accuracy: 0.953125\n",
      "4--141--18176\n",
      "loss: 0.12279997343387833\n",
      "accuracy: 0.96875\n",
      "4--142--18304\n",
      "loss: 0.24827728173044322\n",
      "accuracy: 0.9453125\n",
      "4--143--18432\n",
      "loss: 0.26831408180612426\n",
      "accuracy: 0.921875\n",
      "4--144--18560\n",
      "loss: 0.18633816460813352\n",
      "accuracy: 0.9453125\n",
      "4--145--18688\n",
      "loss: 0.17259504479409854\n",
      "accuracy: 0.96875\n",
      "4--146--18816\n",
      "loss: 0.20936105393304863\n",
      "accuracy: 0.921875\n",
      "4--147--18944\n",
      "loss: 0.24438779063885963\n",
      "accuracy: 0.9296875\n",
      "4--148--19072\n",
      "loss: 0.2821565693861163\n",
      "accuracy: 0.9140625\n",
      "4--149--19200\n",
      "loss: 0.30178085789229325\n",
      "accuracy: 0.9140625\n",
      "4--150--19328\n",
      "loss: 0.15150407132577826\n",
      "accuracy: 0.9453125\n",
      "4--151--19456\n",
      "loss: 0.16357548720795784\n",
      "accuracy: 0.96875\n",
      "4--152--19584\n",
      "loss: 0.18377383496196012\n",
      "accuracy: 0.9453125\n",
      "4--153--19712\n",
      "loss: 0.21960075676874746\n",
      "accuracy: 0.9375\n",
      "4--154--19840\n",
      "loss: 0.1391354621446731\n",
      "accuracy: 0.9609375\n",
      "4--155--19968\n",
      "loss: 0.26802971224837496\n",
      "accuracy: 0.9140625\n",
      "4--156--20096\n",
      "loss: 0.21165631545517294\n",
      "accuracy: 0.9296875\n",
      "4--157--20224\n",
      "loss: 0.2920929382788837\n",
      "accuracy: 0.9296875\n",
      "4--158--20352\n",
      "loss: 0.15893823133921198\n",
      "accuracy: 0.9609375\n",
      "4--159--20480\n",
      "loss: 0.3540270337134941\n",
      "accuracy: 0.90625\n",
      "4--160--20608\n",
      "loss: 0.3765765420653161\n",
      "accuracy: 0.8984375\n",
      "4--161--20736\n",
      "loss: 0.2362343120438447\n",
      "accuracy: 0.9296875\n",
      "4--162--20864\n",
      "loss: 0.2632897469588855\n",
      "accuracy: 0.9296875\n",
      "4--163--20992\n",
      "loss: 0.19239745556935745\n",
      "accuracy: 0.9453125\n",
      "4--164--21120\n",
      "loss: 0.15658280690668558\n",
      "accuracy: 0.953125\n",
      "4--165--21248\n",
      "loss: 0.11018677510618216\n",
      "accuracy: 0.96875\n",
      "4--166--21376\n",
      "loss: 0.25330075341720126\n",
      "accuracy: 0.9375\n",
      "4--167--21504\n",
      "loss: 0.29482142117224003\n",
      "accuracy: 0.9296875\n",
      "4--168--21632\n",
      "loss: 0.2496404014411239\n",
      "accuracy: 0.9375\n",
      "4--169--21760\n",
      "loss: 0.15654102018619617\n",
      "accuracy: 0.9375\n",
      "4--170--21888\n",
      "loss: 0.21115331076879118\n",
      "accuracy: 0.9609375\n",
      "4--171--22016\n",
      "loss: 0.186894443692652\n",
      "accuracy: 0.9453125\n",
      "4--172--22144\n",
      "loss: 0.224789668422549\n",
      "accuracy: 0.9609375\n",
      "4--173--22272\n",
      "loss: 0.1973216498892326\n",
      "accuracy: 0.9453125\n",
      "4--174--22400\n",
      "loss: 0.2036453410062981\n",
      "accuracy: 0.9375\n",
      "4--175--22528\n",
      "loss: 0.2050423967411078\n",
      "accuracy: 0.9375\n",
      "4--176--22656\n",
      "loss: 0.13756878484257085\n",
      "accuracy: 0.953125\n",
      "4--177--22784\n",
      "loss: 0.14588562538751845\n",
      "accuracy: 0.953125\n",
      "4--178--22912\n",
      "loss: 0.16834311299517724\n",
      "accuracy: 0.9296875\n",
      "4--179--23040\n",
      "loss: 0.20978379717515488\n",
      "accuracy: 0.9375\n",
      "4--180--23168\n",
      "loss: 0.1581502732882275\n",
      "accuracy: 0.9609375\n",
      "4--181--23296\n",
      "loss: 0.30142223475813135\n",
      "accuracy: 0.9375\n",
      "4--182--23424\n",
      "loss: 0.20020181201133075\n",
      "accuracy: 0.9453125\n",
      "4--183--23552\n",
      "loss: 0.166217960783842\n",
      "accuracy: 0.9453125\n",
      "4--184--23680\n",
      "loss: 0.2004790303811757\n",
      "accuracy: 0.9296875\n",
      "4--185--23808\n",
      "loss: 0.13488663351531902\n",
      "accuracy: 0.9609375\n",
      "4--186--23936\n",
      "loss: 0.2642442750992303\n",
      "accuracy: 0.9140625\n",
      "4--187--24064\n",
      "loss: 0.36344703042870746\n",
      "accuracy: 0.90625\n",
      "4--188--24192\n",
      "loss: 0.22454976873230106\n",
      "accuracy: 0.921875\n",
      "4--189--24320\n",
      "loss: 0.29377585742803103\n",
      "accuracy: 0.9375\n",
      "4--190--24448\n",
      "loss: 0.21915623527578887\n",
      "accuracy: 0.9453125\n",
      "4--191--24576\n",
      "loss: 0.2888051909100393\n",
      "accuracy: 0.9375\n",
      "4--192--24704\n",
      "loss: 0.1700751531583608\n",
      "accuracy: 0.9296875\n",
      "4--193--24832\n",
      "loss: 0.2198196906714845\n",
      "accuracy: 0.9140625\n",
      "4--194--24960\n",
      "loss: 0.25078148984770054\n",
      "accuracy: 0.9296875\n",
      "4--195--25088\n",
      "loss: 0.14153178801175986\n",
      "accuracy: 0.9609375\n",
      "4--196--25216\n",
      "loss: 0.3023061913760594\n",
      "accuracy: 0.921875\n",
      "4--197--25344\n",
      "loss: 0.3033680329707076\n",
      "accuracy: 0.8984375\n",
      "4--198--25472\n",
      "loss: 0.36265597128156274\n",
      "accuracy: 0.90625\n",
      "4--199--25600\n",
      "loss: 0.19358156279830613\n",
      "accuracy: 0.9296875\n",
      "4--200--25728\n",
      "loss: 0.1876284098145668\n",
      "accuracy: 0.9296875\n",
      "4--201--25856\n",
      "loss: 0.254522099241759\n",
      "accuracy: 0.90625\n",
      "4--202--25984\n",
      "loss: 0.1448301971377703\n",
      "accuracy: 0.9609375\n",
      "4--203--26112\n",
      "loss: 0.21639550644067523\n",
      "accuracy: 0.953125\n",
      "4--204--26240\n",
      "loss: 0.16026514121428076\n",
      "accuracy: 0.953125\n",
      "4--205--26368\n",
      "loss: 0.31387583246728834\n",
      "accuracy: 0.90625\n",
      "4--206--26496\n",
      "loss: 0.20744355656488156\n",
      "accuracy: 0.9453125\n",
      "4--207--26624\n",
      "loss: 0.13474342046189247\n",
      "accuracy: 0.96875\n",
      "4--208--26752\n",
      "loss: 0.26879003751392144\n",
      "accuracy: 0.9140625\n",
      "4--209--26880\n",
      "loss: 0.20254818356045182\n",
      "accuracy: 0.9296875\n",
      "4--210--27008\n",
      "loss: 0.21398362656411749\n",
      "accuracy: 0.9453125\n",
      "4--211--27136\n",
      "loss: 0.1491441271215847\n",
      "accuracy: 0.9609375\n",
      "4--212--27264\n",
      "loss: 0.25480025944582774\n",
      "accuracy: 0.9375\n",
      "4--213--27392\n",
      "loss: 0.23771575672541972\n",
      "accuracy: 0.921875\n",
      "4--214--27520\n",
      "loss: 0.11636209717052189\n",
      "accuracy: 0.9609375\n",
      "4--215--27648\n",
      "loss: 0.2646070282105851\n",
      "accuracy: 0.921875\n",
      "4--216--27776\n",
      "loss: 0.21227390437637356\n",
      "accuracy: 0.9453125\n",
      "4--217--27904\n",
      "loss: 0.19590521896421656\n",
      "accuracy: 0.9609375\n",
      "4--218--28032\n",
      "loss: 0.11751416633383338\n",
      "accuracy: 0.9609375\n",
      "4--219--28160\n",
      "loss: 0.18846191980064797\n",
      "accuracy: 0.9296875\n",
      "4--220--28288\n",
      "loss: 0.33051941285664543\n",
      "accuracy: 0.921875\n",
      "4--221--28416\n",
      "loss: 0.22392232273574922\n",
      "accuracy: 0.9453125\n",
      "4--222--28544\n",
      "loss: 0.219323078742186\n",
      "accuracy: 0.9296875\n",
      "4--223--28672\n",
      "loss: 0.1165998121947568\n",
      "accuracy: 0.96875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4--224--28800\n",
      "loss: 0.3165181200996261\n",
      "accuracy: 0.8984375\n",
      "4--225--28928\n",
      "loss: 0.18950658569351692\n",
      "accuracy: 0.9453125\n",
      "4--226--29056\n",
      "loss: 0.19469315971257084\n",
      "accuracy: 0.9453125\n",
      "4--227--29184\n",
      "loss: 0.3202240651737227\n",
      "accuracy: 0.921875\n",
      "4--228--29312\n",
      "loss: 0.20897876309324015\n",
      "accuracy: 0.9609375\n",
      "4--229--29399\n",
      "loss: 0.1699488396563522\n",
      "accuracy: 0.9655172413793104\n"
     ]
    }
   ],
   "source": [
    "cache, parameter = train(x=train_data.T, y=train_label.T, epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T07:48:05.547536Z",
     "start_time": "2019-03-24T07:48:03.469959Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['C1', 'A1', 'C2', 'A2', 'C3', 'A3', 'dC3', 'dW3', 'db3', 'dC2', 'dW2', 'db2', 'dC1', 'dW1', 'db1'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat_label = forward(test_data.T, parameter, cache)\n",
    "hat_label.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T07:48:06.765349Z",
     "start_time": "2019-03-24T07:48:06.750349Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 12601)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hat_label = hat_label['A3']\n",
    "hat_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T07:48:09.081987Z",
     "start_time": "2019-03-24T07:48:09.068983Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2211812376862138"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(test_label.T, hat_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 随机森林\n",
    "\n",
    "## 一、概念\n",
    "\n",
    "随机森林 = bagging+决策树\n",
    "\n",
    "随机森林的思想非常朴素，就是“三个臭皮匠顶个诸葛亮”。\n",
    "\n",
    "### 1. bagging抽样\n",
    "\n",
    "bagging的全称为bootstrap aggregating。\n",
    "\n",
    "bootstrap是统计学中常用的抽样方法，简单而言就是从所有样本中**有放回地抽取一部分样本**进行实验，重复多次进行。\n",
    "\n",
    "抽样好理解，是为了计算简便和节省时间空间，而有放回则是为了避免数据具有“片面性”。有放回的抽样会反复学习数据中特定的特征，而淡化数据的噪声。\n",
    "\n",
    "譬如100个来自标准正态分布的样本中有1个离群值，影响到了这100个样本的均值使其偏离了原点。假设极端情况下无放回地抽取10次，每次抽取10个样本，则无放回的抽取再计算均值进行平均和直接计算所有样本的均值是等价的。而如果是有放回的抽取，则有一定的可能（$0.9^10=0.349$）不会抽取到离群值。\n",
    "\n",
    "而aggregating则意味着我们将bootstrap抽样的结果结合起来，这种结合有简单的做平均，也有对样本进行加权再进行平均。\n",
    "\n",
    "### 2. 决策树\n",
    "\n",
    "此时的决策树称为随机树其实更为合适。回忆决策树部分中我们提到对于固定的样本，决策树也是确定的，因为每一步都在寻找最优的划分，针对一个固定的样本各种划分肯定也是固定的。\n",
    "\n",
    "而随机森林中的树则相对随机，主要体现在四个方面：\n",
    "\n",
    "- 样本随机：用来训练每棵树的样本都是不完全相同的\n",
    "\n",
    "- 变量随机：用来训练每颗树的变量都是从所有变量中随机抽取的一部分变量\n",
    "\n",
    "- 划分变量随机：随机森林中不要求划分的变量一定是最优的变量\n",
    "\n",
    "- 划分节点随机：选定划分变量之后划分节点也不要求是最优的\n",
    "\n",
    "可以见的这样训练出来的一棵决策树性能好不到哪里去，可能正确率只有70%。但是如果有上百棵这样的树进行预测超过半数的树预测正确的概率却是可观的，也就是所谓“三个臭皮匠顶个诸葛亮”。\n",
    "\n",
    "### 3. 集成学习\n",
    "\n",
    "类似于随机森林这样将很多个学习器组合起来的方法称为集成学习方法。\n",
    "\n",
    "集成学习方法将很多个弱学习器组合在一起，获得能和强学习器媲美的性能。\n",
    "\n",
    "集成学习方法仅适合用于弱学习器，像此前我们提过的逻辑回归等方法都是强学习器。将强学习器组合起来的收效是微乎甚微的，因为每个强学习器学习到的参数或者分布相差并不大。拿逻辑回归举例，可能我们用bootstrap抽样每次用一部分学习到的分离超平面是不同的，但是多个学习器学习到的超平面进行平均之后很可能和用全部数据学习到的超平面相差无几。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、应用\n",
    "\n",
    "这次的数据集和分类树一样用的是汽车数据集。\n",
    "\n",
    "我们先把之前的分类树整合成一个类，以便后续bagging的时候调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T10:59:37.943505Z",
     "start_time": "2019-03-23T10:59:37.861521Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "title = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'acc']\n",
    "car = pd.read_csv('data_set/car.data', header=None, names=title)\n",
    "car = car.replace(['more', '5more'], 6)\n",
    "car['doors'] = car['doors'].astype('int')\n",
    "car['persons'] = car['persons'].astype('int')\n",
    "n = car.shape[0]\n",
    "\n",
    "np.random.seed(2099)\n",
    "index = np.random.permutation(n)\n",
    "train_index = index[0: int(0.7 * n)]\n",
    "test_index = index[int(0.7 * n): n]\n",
    "\n",
    "labels = np.unique(car['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T10:59:40.436690Z",
     "start_time": "2019-03-23T10:59:40.342707Z"
    }
   },
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "\n",
    "    def __init__(self, data, check=True):\n",
    "        self.tree = pd.DataFrame({\n",
    "            'split_variable': [None],\n",
    "            'split_value': [None],\n",
    "            'discrete': [None],\n",
    "            'left_prediction': [None],\n",
    "            'right_prediction': [None]\n",
    "        })\n",
    "        tmp = data.dtypes\n",
    "        tmp_set = {\"continuous\": [], \"discrete\": []}\n",
    "        for n, i in enumerate(tmp):\n",
    "            if (i == \"float32\") or (i == \"float64\") or (i == \"int32\") or (i == \"int64\"):\n",
    "                tmp_set[\"continuous\"].append(data.columns[n])\n",
    "            else:\n",
    "                tmp_set[\"discrete\"].append(data.columns[n])\n",
    "        self.variable_set = {\n",
    "            '1': tmp_set\n",
    "        }\n",
    "        if check:\n",
    "            print(\"make sure you get the variable type right\")\n",
    "            print(self.variable_set)\n",
    "\n",
    "    def fit(self, data, target, index, max_layer=5):\n",
    "        try:\n",
    "            self.variable_set[\"1\"][\"continuous\"].remove(target)\n",
    "        except ValueError:\n",
    "            self.variable_set[\"1\"][\"discrete\"].remove(target)\n",
    "\n",
    "        def gini(data, labels, index, target):\n",
    "            data = data.loc[index]\n",
    "            n = data.shape[0]\n",
    "            g = 1\n",
    "            for label in labels:\n",
    "                p = np.sum(data[target] == label) / n\n",
    "                g -= p * p\n",
    "            return g\n",
    "\n",
    "        def conditional_gini(data, labels, split_variable, split_value, target, discrete=True):\n",
    "            n = data.shape[0]\n",
    "            if discrete:\n",
    "                index1 = data[data[split_variable] == split_value].index\n",
    "                index2 = data[data[split_variable] != split_value].index\n",
    "                g1 = gini(data=data, labels=labels, index=index1, target=target)\n",
    "                g2 = gini(data=data, labels=labels, index=index2, target=target)\n",
    "                g = len(index1) / n * g1 + len(index2) / n * g2\n",
    "                return g\n",
    "            else:\n",
    "                index1 = data[data[split_variable] <= split_value].index\n",
    "                index2 = data[data[split_variable] > split_value].index\n",
    "                g1 = gini(data=data, labels=labels, index=index1, target=target)\n",
    "                g2 = gini(data=data, labels=labels, index=index2, target=target)\n",
    "                g = len(index1) / n * g1 + len(index2) / n * g2\n",
    "                return g\n",
    "\n",
    "        def split_val(data, variable, target, discrete=True):\n",
    "            labels = np.unique(data[target])\n",
    "            g = 1\n",
    "            if discrete:\n",
    "                values = np.unique(data[variable])\n",
    "            else:\n",
    "                values = data[variable].copy()\n",
    "            split_value = None\n",
    "            for value in values:\n",
    "                tmp = conditional_gini(data, labels, variable, value, target, discrete)\n",
    "                if tmp < g:\n",
    "                    g = tmp\n",
    "                    split_value = value\n",
    "                else:\n",
    "                    continue\n",
    "            return g, split_value\n",
    "\n",
    "        def split_var(data, target, variable_set):\n",
    "            g = 1\n",
    "            to_split_value = None\n",
    "            to_split_variable = None\n",
    "            tmp_gini = None\n",
    "            tmp_value = None\n",
    "            var_type = None\n",
    "            for dtype in variable_set:\n",
    "                discrete = dtype == 'discrete'\n",
    "                for variable in variable_set[dtype]:\n",
    "                    tmp_gini, tmp_value = split_val(data, variable, target, discrete)\n",
    "                    if g > tmp_gini:\n",
    "                        g = tmp_gini\n",
    "                        to_split_value = tmp_value\n",
    "                        to_split_variable = variable\n",
    "                        var_type = discrete\n",
    "\n",
    "            return g, to_split_variable, to_split_value, var_type\n",
    "\n",
    "        def build_tree(data, index, variable_set, tree, target, max_layer, node=1):\n",
    "            \"\"\"\n",
    "            data: all the data\n",
    "            index: the data on which shall be splited, data won't change in recursion but index\n",
    "            variable_set: variables to be split\n",
    "            tree: a dataframe with node,split_variable,split_value,discrete,leaf,left and right prediction\n",
    "            target: the label variable\n",
    "            node: the node of the tree\n",
    "            \"\"\"\n",
    "            tmp = data.iloc[index]\n",
    "            leaf = len(variable_set[str(node)]['discrete']) == 0\n",
    "            leaf = leaf and len(variable_set[str(node)]['continuous']) == 0\n",
    "            leaf = leaf or len(np.unique(tmp[target])) == 1\n",
    "            print(str(node) + \":\" + str(leaf))\n",
    "            if not leaf:\n",
    "                g, variable, value, discrete = split_var(tmp, target, variable_set[str(node)])\n",
    "                if discrete:\n",
    "                    variable_set[str(node)]['discrete'].remove(variable)\n",
    "                    variable_set[str(node * 2)] = copy.deepcopy(variable_set[str(node)])\n",
    "                    variable_set[str(node * 2 + 1)] = copy.deepcopy(variable_set[str(node)])\n",
    "\n",
    "                    index1 = tmp[tmp[variable] == value].index\n",
    "                    left_prediction = stats.mode(data.iloc[index1][target])[0][0]\n",
    "                    index2 = tmp[tmp[variable] != value].index\n",
    "                    right_prediction = stats.mode(data.iloc[index2][target])[0][0]\n",
    "                else:\n",
    "                    variable_set[str(node)]['continuous'].remove(variable)\n",
    "                    variable_set[str(node * 2)] = copy.deepcopy(variable_set[str(node)])\n",
    "                    variable_set[str(node * 2 + 1)] = copy.deepcopy(variable_set[str(node)])\n",
    "\n",
    "                    index1 = tmp[tmp[variable] <= value].index\n",
    "                    left_prediction = stats.mode(data.iloc[index1][target])[0][0]\n",
    "                    index2 = tmp[tmp[variable] > value].index\n",
    "                    right_prediction = stats.mode(data.iloc[index2][target])[0][0]\n",
    "\n",
    "                tree.loc[node] = [variable, value, discrete, left_prediction, right_prediction]\n",
    "                if node < 2 ** max_layer - 1:\n",
    "                    build_tree(data=data, index=index1, variable_set=variable_set,\n",
    "                               tree=tree, target=target, max_layer=max_layer, node=node * 2)\n",
    "                    build_tree(data=data, index=index2, variable_set=variable_set,\n",
    "                               tree=tree, target=target, max_layer=max_layer, node=node * 2 + 1)\n",
    "\n",
    "        build_tree(data, index, self.variable_set, self.tree, target, max_layer)\n",
    "\n",
    "    def predict(self, data):\n",
    "        n = data.shape[0]\n",
    "        prediction = pd.Series()\n",
    "        for i in range(n):\n",
    "            tmp = data.iloc[i]\n",
    "            leaf = False\n",
    "            node = 1\n",
    "            while not leaf:\n",
    "                variable = self.tree.loc[node]['split_variable']\n",
    "                discrete = self.tree.loc[node]['discrete']\n",
    "                if discrete:\n",
    "                    left = tmp[variable] == self.tree.loc[node]['split_value']\n",
    "                else:\n",
    "                    left = tmp[variable] <= self.tree.loc[node]['split_value']\n",
    "                if left:\n",
    "                    prediction.loc[i] = self.tree.loc[node]['left_prediction']\n",
    "                    node = node * 2\n",
    "                else:\n",
    "                    prediction.loc[i] = self.tree.loc[node]['right_prediction']\n",
    "                    node = node * 2 + 1\n",
    "                leaf = not (node in self.tree.index)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里加了一个树的深度（层数）的参数并且不用手动设置变量类别了，可以用*check=False*参数来取消。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T10:59:42.332565Z",
     "start_time": "2019-03-23T10:59:42.318565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make sure you get the variable type right\n",
      "{'1': {'continuous': ['doors', 'persons'], 'discrete': ['buying', 'maint', 'lug_boot', 'safety', 'acc']}}\n"
     ]
    }
   ],
   "source": [
    "tree = Tree(car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T11:01:37.218538Z",
     "start_time": "2019-03-23T11:00:35.985506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\37922\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:36: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "c:\\users\\37922\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\scipy\\stats\\stats.py:248: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:True\n",
      "3:False\n",
      "6:True\n",
      "7:False\n",
      "14:False\n",
      "28:False\n",
      "56:False\n",
      "112:True\n",
      "113:True\n",
      "57:False\n",
      "114:True\n",
      "115:True\n",
      "29:False\n",
      "58:False\n",
      "116:True\n",
      "117:True\n",
      "59:False\n",
      "118:True\n",
      "119:True\n",
      "15:False\n",
      "30:False\n",
      "60:False\n",
      "120:True\n",
      "121:True\n",
      "61:False\n",
      "122:True\n",
      "123:True\n",
      "31:False\n",
      "62:False\n",
      "124:True\n",
      "125:True\n",
      "63:False\n",
      "126:True\n",
      "127:True\n"
     ]
    }
   ],
   "source": [
    "tree.fit(data=car, index=train_index, target='acc', max_layer=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T11:01:50.624669Z",
     "start_time": "2019-03-23T11:01:50.556680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split_variable</th>\n",
       "      <th>split_value</th>\n",
       "      <th>discrete</th>\n",
       "      <th>left_prediction</th>\n",
       "      <th>right_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>persons</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>unacc</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>safety</td>\n",
       "      <td>low</td>\n",
       "      <td>True</td>\n",
       "      <td>unacc</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>maint</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>True</td>\n",
       "      <td>unacc</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>buying</td>\n",
       "      <td>med</td>\n",
       "      <td>True</td>\n",
       "      <td>acc</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>lug_boot</td>\n",
       "      <td>small</td>\n",
       "      <td>True</td>\n",
       "      <td>unacc</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>doors</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>acc</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>doors</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>acc</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>lug_boot</td>\n",
       "      <td>small</td>\n",
       "      <td>True</td>\n",
       "      <td>unacc</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>doors</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>unacc</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>doors</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>unacc</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>buying</td>\n",
       "      <td>low</td>\n",
       "      <td>True</td>\n",
       "      <td>acc</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lug_boot</td>\n",
       "      <td>small</td>\n",
       "      <td>True</td>\n",
       "      <td>acc</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>doors</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>acc</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>doors</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>acc</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>lug_boot</td>\n",
       "      <td>small</td>\n",
       "      <td>True</td>\n",
       "      <td>unacc</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>doors</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>unacc</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>doors</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>acc</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split_variable split_value discrete left_prediction right_prediction\n",
       "0            None        None     None            None             None\n",
       "1         persons           2    False           unacc            unacc\n",
       "3          safety         low     True           unacc              acc\n",
       "7           maint       vhigh     True           unacc              acc\n",
       "14         buying         med     True             acc            unacc\n",
       "28       lug_boot       small     True           unacc              acc\n",
       "56          doors           3    False             acc            unacc\n",
       "57          doors           2    False             acc              acc\n",
       "29       lug_boot       small     True           unacc            unacc\n",
       "58          doors           2    False           unacc            unacc\n",
       "59          doors           2    False           unacc            unacc\n",
       "15         buying         low     True             acc              acc\n",
       "30       lug_boot       small     True             acc            vgood\n",
       "60          doors           2    False             acc              acc\n",
       "61          doors           2    False             acc            vgood\n",
       "31       lug_boot       small     True           unacc              acc\n",
       "62          doors           2    False           unacc              acc\n",
       "63          doors           3    False             acc              acc"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T11:02:09.681114Z",
     "start_time": "2019-03-23T11:02:05.204983Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy rate is: 0.8304431599229287\n"
     ]
    }
   ],
   "source": [
    "prediction = tree.predict(car.iloc[test_index])\n",
    "prediction.index = test_index\n",
    "\n",
    "rate = np.sum(prediction == car.iloc[test_index]['acc'])/len(prediction)\n",
    "print('the accuracy rate is: '+str(rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到这里的结果和之前基本一致。\n",
    "\n",
    "现在我们需要稍微修改一下选取变量和划分点的方法，并且在应用时让最深层数小于变量数，以便让这棵树随机起来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T12:15:04.264608Z",
     "start_time": "2019-03-23T12:15:04.161623Z"
    }
   },
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "\n",
    "    def __init__(self, data, check=True):\n",
    "        self.tree = pd.DataFrame({\n",
    "            'split_variable': [None],\n",
    "            'split_value': [None],\n",
    "            'discrete': [None],\n",
    "            'left_prediction': [None],\n",
    "            'right_prediction': [None]\n",
    "        })\n",
    "        tmp = data.dtypes\n",
    "        tmp_set = {\"continuous\": [], \"discrete\": []}\n",
    "        for n, i in enumerate(tmp):\n",
    "            if (i == \"float32\") or (i == \"float64\") or (i == \"int32\") or (i == \"int64\"):\n",
    "                tmp_set[\"continuous\"].append(data.columns[n])\n",
    "            else:\n",
    "                tmp_set[\"discrete\"].append(data.columns[n])\n",
    "        self.variable_set = {\n",
    "            '1': tmp_set\n",
    "        }\n",
    "        if check:\n",
    "            print(\"make sure you get the variable type right\")\n",
    "            print(self.variable_set)\n",
    "\n",
    "    def fit(self, data, target, index, max_layer=5):\n",
    "        try:\n",
    "            self.variable_set[\"1\"][\"continuous\"].remove(target)\n",
    "        except ValueError:\n",
    "            self.variable_set[\"1\"][\"discrete\"].remove(target)\n",
    "\n",
    "        global_gini = 1\n",
    "\n",
    "        def gini(data, labels, index, target):\n",
    "            data = data.loc[index]\n",
    "            n = data.shape[0]\n",
    "            g = 1\n",
    "            for label in labels:\n",
    "                p = np.sum(data[target] == label) / n\n",
    "                g -= p * p\n",
    "            return g\n",
    "\n",
    "        def conditional_gini(data, labels, split_variable, split_value, target, discrete=True):\n",
    "            n = data.shape[0]\n",
    "            if discrete:\n",
    "                index1 = data[data[split_variable] == split_value].index\n",
    "                index2 = data[data[split_variable] != split_value].index\n",
    "                g1 = gini(data=data, labels=labels, index=index1, target=target)\n",
    "                g2 = gini(data=data, labels=labels, index=index2, target=target)\n",
    "                g = len(index1) / n * g1 + len(index2) / n * g2\n",
    "                return g\n",
    "            else:\n",
    "                index1 = data[data[split_variable] <= split_value].index\n",
    "                index2 = data[data[split_variable] > split_value].index\n",
    "                g1 = gini(data=data, labels=labels, index=index1, target=target)\n",
    "                g2 = gini(data=data, labels=labels, index=index2, target=target)\n",
    "                g = len(index1) / n * g1 + len(index2) / n * g2\n",
    "                return g\n",
    "\n",
    "        def split_val(data, variable, target, pre_gini, discrete=True):\n",
    "            labels = np.unique(data[target])\n",
    "            if discrete:\n",
    "                values = np.unique(data[variable])\n",
    "            else:\n",
    "                values = np.array(data[variable])\n",
    "            split_value = None\n",
    "            np.random.shuffle(values)\n",
    "            for value in values:\n",
    "                tmp = conditional_gini(data, labels, variable, value, target, discrete)\n",
    "                if tmp < pre_gini:\n",
    "                    pre_gini = tmp\n",
    "                    split_value = value\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            return pre_gini, split_value\n",
    "\n",
    "        def split_var(data, target, variable_set, pre_gini=global_gini):\n",
    "            to_split_value = None\n",
    "            to_split_variable = None\n",
    "            tmp_gini = None\n",
    "            tmp_value = None\n",
    "            var_type = np.random.randint(2)\n",
    "            if var_type:\n",
    "                try:\n",
    "                    var = np.random.randint(len(variable_set[\"discrete\"]))\n",
    "                except ValueError:\n",
    "                    return split_var(data, target, variable_set, pre_gini)\n",
    "                variable = variable_set['discrete'][var]\n",
    "                tmp_gini, tmp_value = split_val(data, variable, target, pre_gini, var_type)\n",
    "                if pre_gini > tmp_gini:\n",
    "                    pre_gini = tmp_gini\n",
    "                    to_split_value = tmp_value\n",
    "                    to_split_variable = variable\n",
    "            else:\n",
    "                try:\n",
    "                    var = np.random.randint(len(variable_set[\"continuous\"]))\n",
    "                except ValueError:\n",
    "                    return split_var(data, target, variable_set, pre_gini)\n",
    "                variable = variable_set['continuous'][var]\n",
    "                tmp_gini, tmp_value = split_val(data, variable, target, pre_gini, var_type)\n",
    "                if pre_gini > tmp_gini:\n",
    "                    pre_gini = tmp_gini\n",
    "                    to_split_value = tmp_value\n",
    "                    to_split_variable = variable\n",
    "            if tmp_gini is None:\n",
    "                return split_var(data, target, variable_set, pre_gini)\n",
    "            else:\n",
    "                return pre_gini, to_split_variable, to_split_value, var_type\n",
    "\n",
    "        def build_tree(data, index, variable_set, tree, target, max_layer, pre_gini=global_gini, node=1):\n",
    "            \"\"\"\n",
    "            data: all the data\n",
    "            index: the data on which shall be splited, data won't change in recursion but index\n",
    "            variable_set: variables to be split\n",
    "            tree: a dataframe with node,split_variable,split_value,discrete,leaf,left and right prediction\n",
    "            target: the label variable\n",
    "            node: the node of the tree\n",
    "            \"\"\"\n",
    "            tmp = data.iloc[index]\n",
    "            leaf = len(variable_set[str(node)]['discrete']) == 0\n",
    "            leaf = leaf and len(variable_set[str(node)]['continuous']) == 0\n",
    "            leaf = leaf or len(np.unique(tmp[target])) == 1\n",
    "            # print(str(node) + \":\" + str(leaf))\n",
    "            if not leaf:\n",
    "                tmp_gini, variable, value, discrete = split_var(tmp, target, variable_set[str(node)])\n",
    "                if variable is not None:\n",
    "                    if discrete:\n",
    "                        variable_set[str(node)]['discrete'].remove(variable)\n",
    "                        variable_set[str(node * 2)] = copy.deepcopy(variable_set[str(node)])\n",
    "                        variable_set[str(node * 2 + 1)] = copy.deepcopy(variable_set[str(node)])\n",
    "\n",
    "                        index1 = tmp[tmp[variable] == value].index\n",
    "                        left_prediction = stats.mode(data.iloc[index1][target])[0][0]\n",
    "                        index2 = tmp[tmp[variable] != value].index\n",
    "                        right_prediction = stats.mode(data.iloc[index2][target])[0][0]\n",
    "                    else:\n",
    "                        variable_set[str(node)]['continuous'].remove(variable)\n",
    "                        variable_set[str(node * 2)] = copy.deepcopy(variable_set[str(node)])\n",
    "                        variable_set[str(node * 2 + 1)] = copy.deepcopy(variable_set[str(node)])\n",
    "\n",
    "                        index1 = tmp[tmp[variable] <= value].index\n",
    "                        left_prediction = stats.mode(data.iloc[index1][target])[0][0]\n",
    "                        index2 = tmp[tmp[variable] > value].index\n",
    "                        right_prediction = stats.mode(data.iloc[index2][target])[0][0]\n",
    "\n",
    "                    tree.loc[node] = [variable, value, discrete, left_prediction, right_prediction]\n",
    "                    if node < 2 ** max_layer - 1:\n",
    "                        build_tree(data=data, index=index1, variable_set=variable_set, tree=tree,\n",
    "                                   target=target, max_layer=max_layer, pre_gini=tmp_gini, node=node * 2)\n",
    "                        build_tree(data=data, index=index2, variable_set=variable_set, tree=tree,\n",
    "                                   target=target, max_layer=max_layer, pre_gini=tmp_gini, node=node * 2 + 1)\n",
    "\n",
    "        build_tree(data, index, self.variable_set, self.tree, target, max_layer)\n",
    "\n",
    "    def predict(self, data):\n",
    "        n = data.shape[0]\n",
    "        prediction = pd.Series()\n",
    "        for i in range(n):\n",
    "            tmp = data.iloc[i]\n",
    "            leaf = False\n",
    "            node = 1\n",
    "            while not leaf:\n",
    "                variable = self.tree.loc[node]['split_variable']\n",
    "                discrete = self.tree.loc[node]['discrete']\n",
    "                if discrete:\n",
    "                    left = tmp[variable] == self.tree.loc[node]['split_value']\n",
    "                else:\n",
    "                    left = tmp[variable] <= self.tree.loc[node]['split_value']\n",
    "                if left:\n",
    "                    prediction.loc[i] = self.tree.loc[node]['left_prediction']\n",
    "                    node = node * 2\n",
    "                else:\n",
    "                    prediction.loc[i] = self.tree.loc[node]['right_prediction']\n",
    "                    node = node * 2 + 1\n",
    "                leaf = not (node in self.tree.index)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改的部分主要有三个：\n",
    "\n",
    "1. 在于*split_var*函数中，选取变量变为随机，此时可能出现某一类的变量被选取完之后无法抽样的可能，所以套用了一步try-except的调用。\n",
    "\n",
    "\n",
    "2. 在*split_val*函数中，将可划分节点进行随机打乱\n",
    "\n",
    "\n",
    "3. 在*fit*函数环境内加入一个局部的基尼系数，防止出现我们划分之后这个划分区间的基尼系数已经足够低，而当我们将这个子区间划分之后基尼系数反而比之前高的情况发生，在决策树的情况下每一步都是最优的划分，我们默认这种情况不会发生（其实也是当时我没有想到...）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-23T12:15:12.480637Z",
     "start_time": "2019-03-23T12:15:05.925604Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\37922\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\ipykernel_launcher.py:38: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy rate is: 0.7129094412331407\n"
     ]
    }
   ],
   "source": [
    "tree = Tree(car, check=False)\n",
    "tree.fit(data=car, index=train_index, target='acc', max_layer=5)\n",
    "\n",
    "prediction = tree.predict(car.iloc[test_index])\n",
    "prediction.index = test_index\n",
    "\n",
    "rate = np.sum(prediction == car.iloc[test_index]['acc'])/len(prediction)\n",
    "print('the accuracy rate is: '+str(rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准确率已经显著降下来了，而且这还是大样本情况，是件好事。试一试bagging一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagging(data, target, test, batch=256, n_tree=500, max_depth=4):\n",
    "    forest = {}\n",
    "    prediction = np.zeros((test.shape[0], 1))\n",
    "    batch_index = data.sample(batch).index\n",
    "    for i in range(n_tree):\n",
    "        tree = Tree(car, check=False)\n",
    "        tree.fit(data=car, index=batch_index, target=target, max_layer=max_depth)\n",
    "        forest[i] = tree\n",
    "        prediction = np.hstack((prediction, np.array(tree.predict(test)).reshape(test.shape[0], 1)))\n",
    "        print(\"the \" + str(i) + \"-th tree have been built\")\n",
    "    prediction = np.delete(prediction, 0, axis=1)\n",
    "    return forest, prediction\n",
    "\n",
    "\n",
    "tmp, prediction = bagging(car.iloc[train_index], target='acc', test=car.iloc[test_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "500棵确实需要训练一段时间...其实耗时最长的并不是训练，而是每棵树对测试集进行预测，我觉得这棵树还能写得更快，这样在bagging的时候耗时就会更短。\n",
    "\n",
    "这里我们的问题是多分类问题，在预测结果的呈现上考虑不一样的任务有不一样的需求，如果我们需要一个结果，那么我们可以对最后的结果逐行取众数。如果我们想要知道（所有分类的）概率值，譬如我们用似然函数评价模型时，那么我们需要统计每一行（也就是每个样本）各个类频次（也就是几百个弱学习器的结果）再做除法。\n",
    "\n",
    "这里的效果提升并不明显，推测是因为数据有偏差，如果你有兴趣详细看一下*acc*变量，你会发现*‘acc’*和*‘unacc’*的比例特别大，导致另外两个类别  *‘good’*，*‘vgood’*的样本比例较少。这种情况下很有可能我们采样时就会导致入样的*‘good’*和*‘vgood’*更少，甚至只有一两个，那么这种情况需要极细地分类才能使分类器产生这样的输出。而我们并不会将所有变量放进模型，这就进一步导致模型的偏差。这种情况需要靠抽样方法进行一定的调整，会在以后给出我了解的一些方法。\n",
    "\n",
    "（我实在不想跑了要跑好久让我偷个懒吧orz）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

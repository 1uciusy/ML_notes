{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 随机森林\n",
    "\n",
    "## 一、概念\n",
    "\n",
    "随机森林 = bagging+决策树\n",
    "\n",
    "随机森林的思想非常朴素，就是“三个臭皮匠顶个诸葛亮”。\n",
    "\n",
    "### 1. bagging抽样\n",
    "\n",
    "bagging的全称为bootstrap aggregating。\n",
    "\n",
    "bootstrap是统计学中常用的抽样方法，简单而言就是从所有样本中**有放回地抽取一部分样本**进行实验，重复多次进行。\n",
    "\n",
    "抽样好理解，是为了计算简便和节省时间空间，而有放回则是为了避免数据具有“片面性”。有放回的抽样会反复学习数据中特定的特征，而淡化数据的噪声。\n",
    "\n",
    "譬如100个来自标准正态分布的样本中有1个离群值，影响到了这100个样本的均值使其偏离了原点。假设极端情况下无放回地抽取10次，每次抽取10个样本，则无放回的抽取再计算均值进行平均和直接计算所有样本的均值是等价的。而如果是有放回的抽取，则有一定的可能（$0.9^10=0.349$）不会抽取到离群值。\n",
    "\n",
    "而aggregating则意味着我们将bootstrap抽样的结果结合起来，这种结合有简单的做平均，也有对样本进行加权再进行平均。\n",
    "\n",
    "### 2. 决策树\n",
    "\n",
    "此时的决策树称为随机树其实更为合适。回忆决策树部分中我们提到对于固定的样本，决策树也是确定的，因为每一步都在寻找最优的划分，针对一个固定的样本各种划分肯定也是固定的。\n",
    "\n",
    "而随机森林中的树则相对随机，主要体现在四个方面：\n",
    "\n",
    "- 样本随机：用来训练每棵树的样本都是不完全相同的\n",
    "\n",
    "- 变量随机：用来训练每颗树的变量都是从所有变量中随机抽取的一部分变量\n",
    "\n",
    "- 划分变量随机：随机森林中不要求划分的变量一定是最优的变量\n",
    "\n",
    "- 划分节点随机：选定划分变量之后划分节点也不要求是最优的\n",
    "\n",
    "可以见的这样训练出来的一棵决策树性能好不到哪里去，可能正确率只有70%。但是如果有上百棵这样的树进行预测超过半数的树预测正确的概率却是可观的，也就是所谓“三个臭皮匠顶个诸葛亮”。\n",
    "\n",
    "### 3. 集成学习\n",
    "\n",
    "类似于随机森林这样将很多个学习器组合起来的方法称为集成学习方法。\n",
    "\n",
    "集成学习方法将很多个弱学习器组合在一起，获得能和强学习器媲美的性能。\n",
    "\n",
    "集成学习方法仅适合用于弱学习器，像此前我们提过的逻辑回归等方法都是强学习器。将强学习器组合起来的收效是微乎甚微的，因为每个强学习器学习到的参数或者分布相差并不大。拿逻辑回归举例，可能我们用bootstrap抽样每次用一部分学习到的分离超平面是不同的，但是多个学习器学习到的超平面进行平均之后很可能和用全部数据学习到的超平面相差无几。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、应用\n",
    "\n",
    "这次的数据集和分类树一样用的是汽车数据集。\n",
    "\n",
    "我们先把之前的分类树整合成一个类，以便后续bagging的时候调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T14:05:45.994701Z",
     "start_time": "2019-04-14T14:05:23.914790Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "title = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'acc']\n",
    "car = pd.read_csv('data_set/car.data', header=None, names=title)\n",
    "car = car.replace(['more', '5more'], 6)\n",
    "car['doors'] = car['doors'].astype('int')\n",
    "car['persons'] = car['persons'].astype('int')\n",
    "n = car.shape[0]\n",
    "\n",
    "np.random.seed(2099)\n",
    "index = np.random.permutation(n)\n",
    "train_index = index[0: int(0.7 * n)]\n",
    "test_index = index[int(0.7 * n): n]\n",
    "\n",
    "labels = np.unique(car['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T14:05:47.563883Z",
     "start_time": "2019-04-14T14:05:47.413905Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "\n",
    "    def __init__(self, data, check=True):\n",
    "        self.tree = pd.DataFrame({\n",
    "            'split_variable': [None],\n",
    "            'split_value': [None],\n",
    "            'discrete': [None],\n",
    "            'left_prediction': [None],\n",
    "            'right_prediction': [None]\n",
    "        })\n",
    "        tmp = data.dtypes\n",
    "        tmp_set = {\"continuous\": [], \"discrete\": []}\n",
    "        for n, i in enumerate(tmp):\n",
    "            if (i == \"float32\") or (i == \"float64\") or (i == \"int32\") or (i == \"int64\"):\n",
    "                tmp_set[\"continuous\"].append(data.columns[n])\n",
    "            else:\n",
    "                tmp_set[\"discrete\"].append(data.columns[n])\n",
    "        self.variable_set = {\n",
    "            '1': tmp_set\n",
    "        }\n",
    "        if check:\n",
    "            print(\"make sure you get the variable type right\")\n",
    "            print(self.variable_set)\n",
    "\n",
    "    def fit(self, data, target, index, max_layer=5):\n",
    "        try:\n",
    "            self.variable_set[\"1\"][\"continuous\"].remove(target)\n",
    "        except ValueError:\n",
    "            self.variable_set[\"1\"][\"discrete\"].remove(target)\n",
    "\n",
    "        def gini(data, labels, index, target):\n",
    "            data = data.loc[index]\n",
    "            n = data.shape[0]\n",
    "            g = 1\n",
    "            for label in labels:\n",
    "                p = np.sum(data[target] == label) / n\n",
    "                g -= p * p\n",
    "            return g\n",
    "\n",
    "        def conditional_gini(data, labels, split_variable, split_value, target, discrete=True):\n",
    "            n = data.shape[0]\n",
    "            if discrete:\n",
    "                index1 = data[data[split_variable] == split_value].index\n",
    "                index2 = data[data[split_variable] != split_value].index\n",
    "                g1 = gini(data=data, labels=labels, index=index1, target=target)\n",
    "                g2 = gini(data=data, labels=labels, index=index2, target=target)\n",
    "                g = len(index1) / n * g1 + len(index2) / n * g2\n",
    "                return g\n",
    "            else:\n",
    "                index1 = data[data[split_variable] <= split_value].index\n",
    "                index2 = data[data[split_variable] > split_value].index\n",
    "                g1 = gini(data=data, labels=labels, index=index1, target=target)\n",
    "                g2 = gini(data=data, labels=labels, index=index2, target=target)\n",
    "                g = len(index1) / n * g1 + len(index2) / n * g2\n",
    "                return g\n",
    "\n",
    "        def split_val(data, variable, target, discrete=True):\n",
    "            labels = np.unique(data[target])\n",
    "            g = 1\n",
    "            if discrete:\n",
    "                values = np.unique(data[variable])\n",
    "            else:\n",
    "                values = data[variable].copy()\n",
    "            split_value = None\n",
    "            for value in values:\n",
    "                tmp = conditional_gini(data, labels, variable, value, target, discrete)\n",
    "                if tmp < g:\n",
    "                    g = tmp\n",
    "                    split_value = value\n",
    "                else:\n",
    "                    continue\n",
    "            return g, split_value\n",
    "\n",
    "        def split_var(data, target, variable_set):\n",
    "            g = 1\n",
    "            to_split_value = None\n",
    "            to_split_variable = None\n",
    "            tmp_gini = None\n",
    "            tmp_value = None\n",
    "            var_type = None\n",
    "            for dtype in variable_set:\n",
    "                discrete = dtype == 'discrete'\n",
    "                for variable in variable_set[dtype]:\n",
    "                    tmp_gini, tmp_value = split_val(data, variable, target, discrete)\n",
    "                    if g > tmp_gini:\n",
    "                        g = tmp_gini\n",
    "                        to_split_value = tmp_value\n",
    "                        to_split_variable = variable\n",
    "                        var_type = discrete\n",
    "\n",
    "            return g, to_split_variable, to_split_value, var_type\n",
    "\n",
    "        def build_tree(data, index, variable_set, tree, target, max_layer, node=1):\n",
    "            \"\"\"\n",
    "            data: all the data\n",
    "            index: the data on which shall be splited, data won't change in recursion but index\n",
    "            variable_set: variables to be split\n",
    "            tree: a dataframe with node,split_variable,split_value,discrete,leaf,left and right prediction\n",
    "            target: the label variable\n",
    "            node: the node of the tree\n",
    "            \"\"\"\n",
    "            tmp = data.iloc[index]\n",
    "            leaf = len(variable_set[str(node)]['discrete']) == 0\n",
    "            leaf = leaf and len(variable_set[str(node)]['continuous']) == 0\n",
    "            leaf = leaf or len(np.unique(tmp[target])) == 1\n",
    "            print(str(node) + \":\" + str(leaf))\n",
    "            if not leaf:\n",
    "                g, variable, value, discrete = split_var(tmp, target, variable_set[str(node)])\n",
    "                if discrete:\n",
    "                    variable_set[str(node)]['discrete'].remove(variable)\n",
    "                    variable_set[str(node * 2)] = copy.deepcopy(variable_set[str(node)])\n",
    "                    variable_set[str(node * 2 + 1)] = copy.deepcopy(variable_set[str(node)])\n",
    "\n",
    "                    index1 = tmp[tmp[variable] == value].index\n",
    "                    left_prediction = stats.mode(data.iloc[index1][target])[0][0]\n",
    "                    index2 = tmp[tmp[variable] != value].index\n",
    "                    right_prediction = stats.mode(data.iloc[index2][target])[0][0]\n",
    "                else:\n",
    "                    variable_set[str(node)]['continuous'].remove(variable)\n",
    "                    variable_set[str(node * 2)] = copy.deepcopy(variable_set[str(node)])\n",
    "                    variable_set[str(node * 2 + 1)] = copy.deepcopy(variable_set[str(node)])\n",
    "\n",
    "                    index1 = tmp[tmp[variable] <= value].index\n",
    "                    left_prediction = stats.mode(data.iloc[index1][target])[0][0]\n",
    "                    index2 = tmp[tmp[variable] > value].index\n",
    "                    right_prediction = stats.mode(data.iloc[index2][target])[0][0]\n",
    "\n",
    "                tree.loc[node] = [variable, value, discrete, left_prediction, right_prediction]\n",
    "                if node < 2 ** max_layer - 1:\n",
    "                    build_tree(data=data, index=index1, variable_set=variable_set,\n",
    "                               tree=tree, target=target, max_layer=max_layer, node=node * 2)\n",
    "                    build_tree(data=data, index=index2, variable_set=variable_set,\n",
    "                               tree=tree, target=target, max_layer=max_layer, node=node * 2 + 1)\n",
    "\n",
    "        build_tree(data, index, self.variable_set, self.tree, target, max_layer)\n",
    "\n",
    "    def predict(self, data):\n",
    "        n = data.shape[0]\n",
    "        prediction = pd.Series()\n",
    "        for i in range(n):\n",
    "            tmp = data.iloc[i]\n",
    "            leaf = False\n",
    "            node = 1\n",
    "            while not leaf:\n",
    "                variable = self.tree.loc[node]['split_variable']\n",
    "                discrete = self.tree.loc[node]['discrete']\n",
    "                if discrete:\n",
    "                    left = tmp[variable] == self.tree.loc[node]['split_value']\n",
    "                else:\n",
    "                    left = tmp[variable] <= self.tree.loc[node]['split_value']\n",
    "                if left:\n",
    "                    prediction.loc[i] = self.tree.loc[node]['left_prediction']\n",
    "                    node = node * 2\n",
    "                else:\n",
    "                    prediction.loc[i] = self.tree.loc[node]['right_prediction']\n",
    "                    node = node * 2 + 1\n",
    "                leaf = not (node in self.tree.index)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里加了一个树的深度（层数）的参数并且不用手动设置变量类别了，可以用*check=False*参数来取消。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T14:05:51.392879Z",
     "start_time": "2019-04-14T14:05:51.377883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make sure you get the variable type right\n",
      "{'1': {'continuous': ['doors', 'persons'], 'discrete': ['buying', 'maint', 'lug_boot', 'safety', 'acc']}}\n"
     ]
    }
   ],
   "source": [
    "tree = Tree(car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T14:06:56.674812Z",
     "start_time": "2019-04-14T14:05:52.706682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\37922\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:36: RuntimeWarning: invalid value encountered in longlong_scalars\n",
      "c:\\users\\37922\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\scipy\\stats\\stats.py:248: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:True\n",
      "3:False\n",
      "6:True\n",
      "7:False\n",
      "14:False\n",
      "28:False\n",
      "56:False\n",
      "112:True\n",
      "113:True\n",
      "57:False\n",
      "114:True\n",
      "115:True\n",
      "29:False\n",
      "58:False\n",
      "116:True\n",
      "117:True\n",
      "59:False\n",
      "118:True\n",
      "119:True\n",
      "15:False\n",
      "30:False\n",
      "60:False\n",
      "120:True\n",
      "121:True\n",
      "61:False\n",
      "122:True\n",
      "123:True\n",
      "31:False\n",
      "62:False\n",
      "124:True\n",
      "125:True\n",
      "63:False\n",
      "126:True\n",
      "127:True\n"
     ]
    }
   ],
   "source": [
    "tree.fit(data=car, index=train_index, target='acc', max_layer=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T14:07:12.488720Z",
     "start_time": "2019-04-14T14:07:12.356738Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>split_variable</th>\n",
       "      <th>split_value</th>\n",
       "      <th>discrete</th>\n",
       "      <th>left_prediction</th>\n",
       "      <th>right_prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>persons</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>unacc</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>safety</td>\n",
       "      <td>low</td>\n",
       "      <td>True</td>\n",
       "      <td>unacc</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>maint</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>True</td>\n",
       "      <td>unacc</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>buying</td>\n",
       "      <td>med</td>\n",
       "      <td>True</td>\n",
       "      <td>acc</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>lug_boot</td>\n",
       "      <td>small</td>\n",
       "      <td>True</td>\n",
       "      <td>unacc</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>doors</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>acc</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>doors</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>acc</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>lug_boot</td>\n",
       "      <td>small</td>\n",
       "      <td>True</td>\n",
       "      <td>unacc</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>doors</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>unacc</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>doors</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>unacc</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>buying</td>\n",
       "      <td>low</td>\n",
       "      <td>True</td>\n",
       "      <td>acc</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>lug_boot</td>\n",
       "      <td>small</td>\n",
       "      <td>True</td>\n",
       "      <td>acc</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>doors</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>acc</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>doors</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>acc</td>\n",
       "      <td>vgood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>lug_boot</td>\n",
       "      <td>small</td>\n",
       "      <td>True</td>\n",
       "      <td>unacc</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>doors</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>unacc</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>doors</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>acc</td>\n",
       "      <td>acc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   split_variable split_value discrete left_prediction right_prediction\n",
       "0            None        None     None            None             None\n",
       "1         persons           2    False           unacc            unacc\n",
       "3          safety         low     True           unacc              acc\n",
       "7           maint       vhigh     True           unacc              acc\n",
       "14         buying         med     True             acc            unacc\n",
       "28       lug_boot       small     True           unacc              acc\n",
       "56          doors           3    False             acc            unacc\n",
       "57          doors           2    False             acc              acc\n",
       "29       lug_boot       small     True           unacc            unacc\n",
       "58          doors           2    False           unacc            unacc\n",
       "59          doors           2    False           unacc            unacc\n",
       "15         buying         low     True             acc              acc\n",
       "30       lug_boot       small     True             acc            vgood\n",
       "60          doors           2    False             acc              acc\n",
       "61          doors           2    False             acc            vgood\n",
       "31       lug_boot       small     True           unacc              acc\n",
       "62          doors           2    False           unacc              acc\n",
       "63          doors           3    False             acc              acc"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T14:07:21.453865Z",
     "start_time": "2019-04-14T14:07:16.901567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy rate is: 0.8304431599229287\n"
     ]
    }
   ],
   "source": [
    "prediction = tree.predict(car.iloc[test_index])\n",
    "prediction.index = test_index\n",
    "\n",
    "rate = np.sum(prediction == car.iloc[test_index]['acc'])/len(prediction)\n",
    "print('the accuracy rate is: '+str(rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到这里的结果和之前基本一致。\n",
    "\n",
    "现在我们需要稍微修改一下选取变量和划分点的方法，并且在应用时让最深层数小于变量数，以便让这棵树随机起来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T14:07:28.199584Z",
     "start_time": "2019-04-14T14:07:28.048097Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "\n",
    "    def __init__(self, data, check=True):\n",
    "        self.tree = pd.DataFrame({\n",
    "            'split_variable': [None],\n",
    "            'split_value': [None],\n",
    "            'discrete': [None],\n",
    "            'left_prediction': [None],\n",
    "            'right_prediction': [None]\n",
    "        })\n",
    "        tmp = data.dtypes\n",
    "        tmp_set = {\"continuous\": [], \"discrete\": []}\n",
    "        for n, i in enumerate(tmp):\n",
    "            if (i == \"float32\") or (i == \"float64\") or (i == \"int32\") or (i == \"int64\"):\n",
    "                tmp_set[\"continuous\"].append(data.columns[n])\n",
    "            else:\n",
    "                tmp_set[\"discrete\"].append(data.columns[n])\n",
    "        self.variable_set = {\n",
    "            '1': tmp_set\n",
    "        }\n",
    "        if check:\n",
    "            print(\"make sure you get the variable type right\")\n",
    "            print(self.variable_set)\n",
    "\n",
    "    def fit(self, data, target, index, max_layer=5):\n",
    "        try:\n",
    "            self.variable_set[\"1\"][\"continuous\"].remove(target)\n",
    "        except ValueError:\n",
    "            self.variable_set[\"1\"][\"discrete\"].remove(target)\n",
    "\n",
    "        global_gini = 1\n",
    "\n",
    "        def gini(data, labels, index, target):\n",
    "            data = data.loc[index]\n",
    "            n = data.shape[0]\n",
    "            g = 1\n",
    "            for label in labels:\n",
    "                p = np.sum(data[target] == label) / n\n",
    "                g -= p * p\n",
    "            return g\n",
    "\n",
    "        def conditional_gini(data, labels, split_variable, split_value, target, discrete=True):\n",
    "            n = data.shape[0]\n",
    "            if discrete:\n",
    "                index1 = data[data[split_variable] == split_value].index\n",
    "                index2 = data[data[split_variable] != split_value].index\n",
    "                g1 = gini(data=data, labels=labels, index=index1, target=target)\n",
    "                g2 = gini(data=data, labels=labels, index=index2, target=target)\n",
    "                g = len(index1) / n * g1 + len(index2) / n * g2\n",
    "                return g\n",
    "            else:\n",
    "                index1 = data[data[split_variable] <= split_value].index\n",
    "                index2 = data[data[split_variable] > split_value].index\n",
    "                g1 = gini(data=data, labels=labels, index=index1, target=target)\n",
    "                g2 = gini(data=data, labels=labels, index=index2, target=target)\n",
    "                g = len(index1) / n * g1 + len(index2) / n * g2\n",
    "                return g\n",
    "\n",
    "        def split_val(data, variable, target, pre_gini, discrete=True):\n",
    "            labels = np.unique(data[target])\n",
    "            if discrete:\n",
    "                values = np.unique(data[variable])\n",
    "            else:\n",
    "                values = np.array(data[variable])\n",
    "            split_value = None\n",
    "            np.random.shuffle(values)\n",
    "            for value in values:\n",
    "                tmp = conditional_gini(data, labels, variable, value, target, discrete)\n",
    "                if tmp < pre_gini:\n",
    "                    pre_gini = tmp\n",
    "                    split_value = value\n",
    "                    break\n",
    "                else:\n",
    "                    continue\n",
    "            return pre_gini, split_value\n",
    "\n",
    "        def split_var(data, target, variable_set, pre_gini=global_gini):\n",
    "            to_split_value = None\n",
    "            to_split_variable = None\n",
    "            tmp_gini = None\n",
    "            tmp_value = None\n",
    "            var_type = np.random.randint(2)\n",
    "            if var_type:\n",
    "                try:\n",
    "                    var = np.random.randint(len(variable_set[\"discrete\"]))\n",
    "                except ValueError:\n",
    "                    return split_var(data, target, variable_set, pre_gini)\n",
    "                variable = variable_set['discrete'][var]\n",
    "                tmp_gini, tmp_value = split_val(data, variable, target, pre_gini, var_type)\n",
    "                if pre_gini > tmp_gini:\n",
    "                    pre_gini = tmp_gini\n",
    "                    to_split_value = tmp_value\n",
    "                    to_split_variable = variable\n",
    "            else:\n",
    "                try:\n",
    "                    var = np.random.randint(len(variable_set[\"continuous\"]))\n",
    "                except ValueError:\n",
    "                    return split_var(data, target, variable_set, pre_gini)\n",
    "                variable = variable_set['continuous'][var]\n",
    "                tmp_gini, tmp_value = split_val(data, variable, target, pre_gini, var_type)\n",
    "                if pre_gini > tmp_gini:\n",
    "                    pre_gini = tmp_gini\n",
    "                    to_split_value = tmp_value\n",
    "                    to_split_variable = variable\n",
    "            if tmp_gini is None:\n",
    "                return split_var(data, target, variable_set, pre_gini)\n",
    "            else:\n",
    "                return pre_gini, to_split_variable, to_split_value, var_type\n",
    "\n",
    "        def build_tree(data, index, variable_set, tree, target, max_layer, pre_gini=global_gini, node=1):\n",
    "            \"\"\"\n",
    "            data: all the data\n",
    "            index: the data on which shall be splited, data won't change in recursion but index\n",
    "            variable_set: variables to be split\n",
    "            tree: a dataframe with node,split_variable,split_value,discrete,leaf,left and right prediction\n",
    "            target: the label variable\n",
    "            node: the node of the tree\n",
    "            \"\"\"\n",
    "            tmp = data.iloc[index]\n",
    "            leaf = len(variable_set[str(node)]['discrete']) == 0\n",
    "            leaf = leaf and len(variable_set[str(node)]['continuous']) == 0\n",
    "            leaf = leaf or len(np.unique(tmp[target])) == 1\n",
    "            # print(str(node) + \":\" + str(leaf))\n",
    "            if not leaf:\n",
    "                tmp_gini, variable, value, discrete = split_var(tmp, target, variable_set[str(node)])\n",
    "                if variable is not None:\n",
    "                    if discrete:\n",
    "                        variable_set[str(node)]['discrete'].remove(variable)\n",
    "                        variable_set[str(node * 2)] = copy.deepcopy(variable_set[str(node)])\n",
    "                        variable_set[str(node * 2 + 1)] = copy.deepcopy(variable_set[str(node)])\n",
    "\n",
    "                        index1 = tmp[tmp[variable] == value].index\n",
    "                        left_prediction = stats.mode(data.iloc[index1][target])[0][0]\n",
    "                        index2 = tmp[tmp[variable] != value].index\n",
    "                        right_prediction = stats.mode(data.iloc[index2][target])[0][0]\n",
    "                    else:\n",
    "                        variable_set[str(node)]['continuous'].remove(variable)\n",
    "                        variable_set[str(node * 2)] = copy.deepcopy(variable_set[str(node)])\n",
    "                        variable_set[str(node * 2 + 1)] = copy.deepcopy(variable_set[str(node)])\n",
    "\n",
    "                        index1 = tmp[tmp[variable] <= value].index\n",
    "                        left_prediction = stats.mode(data.iloc[index1][target])[0][0]\n",
    "                        index2 = tmp[tmp[variable] > value].index\n",
    "                        right_prediction = stats.mode(data.iloc[index2][target])[0][0]\n",
    "\n",
    "                    tree.loc[node] = [variable, value, discrete, left_prediction, right_prediction]\n",
    "                    if node < 2 ** max_layer - 1:\n",
    "                        build_tree(data=data, index=index1, variable_set=variable_set, tree=tree,\n",
    "                                   target=target, max_layer=max_layer, pre_gini=tmp_gini, node=node * 2)\n",
    "                        build_tree(data=data, index=index2, variable_set=variable_set, tree=tree,\n",
    "                                   target=target, max_layer=max_layer, pre_gini=tmp_gini, node=node * 2 + 1)\n",
    "\n",
    "        build_tree(data, index, self.variable_set, self.tree, target, max_layer)\n",
    "\n",
    "    def predict(self, data):\n",
    "        n = data.shape[0]\n",
    "        prediction = pd.Series()\n",
    "        for i in range(n):\n",
    "            tmp = data.iloc[i]\n",
    "            leaf = False\n",
    "            node = 1\n",
    "            while not leaf:\n",
    "                variable = self.tree.loc[node]['split_variable']\n",
    "                discrete = self.tree.loc[node]['discrete']\n",
    "                if discrete:\n",
    "                    left = tmp[variable] == self.tree.loc[node]['split_value']\n",
    "                else:\n",
    "                    left = tmp[variable] <= self.tree.loc[node]['split_value']\n",
    "                if left:\n",
    "                    prediction.loc[i] = self.tree.loc[node]['left_prediction']\n",
    "                    node = node * 2\n",
    "                else:\n",
    "                    prediction.loc[i] = self.tree.loc[node]['right_prediction']\n",
    "                    node = node * 2 + 1\n",
    "                leaf = not (node in self.tree.index)\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "修改的部分主要有三个：\n",
    "\n",
    "1. 在于*split_var*函数中，选取变量变为随机，此时可能出现某一类的变量被选取完之后无法抽样的可能，所以套用了一步try-except的调用。\n",
    "\n",
    "\n",
    "2. 在*split_val*函数中，将可划分节点进行随机打乱\n",
    "\n",
    "\n",
    "3. 在*fit*函数环境内加入一个局部的基尼系数，防止出现我们划分之后这个划分区间的基尼系数已经足够低，而当我们将这个子区间划分之后基尼系数反而比之前高的情况发生，在决策树的情况下每一步都是最优的划分，我们默认这种情况不会发生（其实也是当时我没有想到...）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T14:07:49.516606Z",
     "start_time": "2019-04-14T14:07:43.504110Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\37922\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:38: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy rate is: 0.7360308285163777\n"
     ]
    }
   ],
   "source": [
    "tree = Tree(car, check=False)\n",
    "tree.fit(data=car, index=train_index, target='acc', max_layer=5)\n",
    "\n",
    "prediction = tree.predict(car.iloc[test_index])\n",
    "prediction.index = test_index\n",
    "\n",
    "rate = np.sum(prediction == car.iloc[test_index]['acc'])/len(prediction)\n",
    "print('the accuracy rate is: '+str(rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准确率已经显著降下来了，而且这还是大样本情况，是件好事。试一试bagging一下。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T14:54:33.585685Z",
     "start_time": "2019-04-14T14:07:49.604589Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\37922\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:38: RuntimeWarning: invalid value encountered in longlong_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 0-th tree have been built\n",
      "the 1-th tree have been built\n",
      "the 2-th tree have been built\n",
      "the 3-th tree have been built\n",
      "the 4-th tree have been built\n",
      "the 5-th tree have been built\n",
      "the 6-th tree have been built\n",
      "the 7-th tree have been built\n",
      "the 8-th tree have been built\n",
      "the 9-th tree have been built\n",
      "the 10-th tree have been built\n",
      "the 11-th tree have been built\n",
      "the 12-th tree have been built\n",
      "the 13-th tree have been built\n",
      "the 14-th tree have been built\n",
      "the 15-th tree have been built\n",
      "the 16-th tree have been built\n",
      "the 17-th tree have been built\n",
      "the 18-th tree have been built\n",
      "the 19-th tree have been built\n",
      "the 20-th tree have been built\n",
      "the 21-th tree have been built\n",
      "the 22-th tree have been built\n",
      "the 23-th tree have been built\n",
      "the 24-th tree have been built\n",
      "the 25-th tree have been built\n",
      "the 26-th tree have been built\n",
      "the 27-th tree have been built\n",
      "the 28-th tree have been built\n",
      "the 29-th tree have been built\n",
      "the 30-th tree have been built\n",
      "the 31-th tree have been built\n",
      "the 32-th tree have been built\n",
      "the 33-th tree have been built\n",
      "the 34-th tree have been built\n",
      "the 35-th tree have been built\n",
      "the 36-th tree have been built\n",
      "the 37-th tree have been built\n",
      "the 38-th tree have been built\n",
      "the 39-th tree have been built\n",
      "the 40-th tree have been built\n",
      "the 41-th tree have been built\n",
      "the 42-th tree have been built\n",
      "the 43-th tree have been built\n",
      "the 44-th tree have been built\n",
      "the 45-th tree have been built\n",
      "the 46-th tree have been built\n",
      "the 47-th tree have been built\n",
      "the 48-th tree have been built\n",
      "the 49-th tree have been built\n",
      "the 50-th tree have been built\n",
      "the 51-th tree have been built\n",
      "the 52-th tree have been built\n",
      "the 53-th tree have been built\n",
      "the 54-th tree have been built\n",
      "the 55-th tree have been built\n",
      "the 56-th tree have been built\n",
      "the 57-th tree have been built\n",
      "the 58-th tree have been built\n",
      "the 59-th tree have been built\n",
      "the 60-th tree have been built\n",
      "the 61-th tree have been built\n",
      "the 62-th tree have been built\n",
      "the 63-th tree have been built\n",
      "the 64-th tree have been built\n",
      "the 65-th tree have been built\n",
      "the 66-th tree have been built\n",
      "the 67-th tree have been built\n",
      "the 68-th tree have been built\n",
      "the 69-th tree have been built\n",
      "the 70-th tree have been built\n",
      "the 71-th tree have been built\n",
      "the 72-th tree have been built\n",
      "the 73-th tree have been built\n",
      "the 74-th tree have been built\n",
      "the 75-th tree have been built\n",
      "the 76-th tree have been built\n",
      "the 77-th tree have been built\n",
      "the 78-th tree have been built\n",
      "the 79-th tree have been built\n",
      "the 80-th tree have been built\n",
      "the 81-th tree have been built\n",
      "the 82-th tree have been built\n",
      "the 83-th tree have been built\n",
      "the 84-th tree have been built\n",
      "the 85-th tree have been built\n",
      "the 86-th tree have been built\n",
      "the 87-th tree have been built\n",
      "the 88-th tree have been built\n",
      "the 89-th tree have been built\n",
      "the 90-th tree have been built\n",
      "the 91-th tree have been built\n",
      "the 92-th tree have been built\n",
      "the 93-th tree have been built\n",
      "the 94-th tree have been built\n",
      "the 95-th tree have been built\n",
      "the 96-th tree have been built\n",
      "the 97-th tree have been built\n",
      "the 98-th tree have been built\n",
      "the 99-th tree have been built\n",
      "the 100-th tree have been built\n",
      "the 101-th tree have been built\n",
      "the 102-th tree have been built\n",
      "the 103-th tree have been built\n",
      "the 104-th tree have been built\n",
      "the 105-th tree have been built\n",
      "the 106-th tree have been built\n",
      "the 107-th tree have been built\n",
      "the 108-th tree have been built\n",
      "the 109-th tree have been built\n",
      "the 110-th tree have been built\n",
      "the 111-th tree have been built\n",
      "the 112-th tree have been built\n",
      "the 113-th tree have been built\n",
      "the 114-th tree have been built\n",
      "the 115-th tree have been built\n",
      "the 116-th tree have been built\n",
      "the 117-th tree have been built\n",
      "the 118-th tree have been built\n",
      "the 119-th tree have been built\n",
      "the 120-th tree have been built\n",
      "the 121-th tree have been built\n",
      "the 122-th tree have been built\n",
      "the 123-th tree have been built\n",
      "the 124-th tree have been built\n",
      "the 125-th tree have been built\n",
      "the 126-th tree have been built\n",
      "the 127-th tree have been built\n",
      "the 128-th tree have been built\n",
      "the 129-th tree have been built\n",
      "the 130-th tree have been built\n",
      "the 131-th tree have been built\n",
      "the 132-th tree have been built\n",
      "the 133-th tree have been built\n",
      "the 134-th tree have been built\n",
      "the 135-th tree have been built\n",
      "the 136-th tree have been built\n",
      "the 137-th tree have been built\n",
      "the 138-th tree have been built\n",
      "the 139-th tree have been built\n",
      "the 140-th tree have been built\n",
      "the 141-th tree have been built\n",
      "the 142-th tree have been built\n",
      "the 143-th tree have been built\n",
      "the 144-th tree have been built\n",
      "the 145-th tree have been built\n",
      "the 146-th tree have been built\n",
      "the 147-th tree have been built\n",
      "the 148-th tree have been built\n",
      "the 149-th tree have been built\n",
      "the 150-th tree have been built\n",
      "the 151-th tree have been built\n",
      "the 152-th tree have been built\n",
      "the 153-th tree have been built\n",
      "the 154-th tree have been built\n",
      "the 155-th tree have been built\n",
      "the 156-th tree have been built\n",
      "the 157-th tree have been built\n",
      "the 158-th tree have been built\n",
      "the 159-th tree have been built\n",
      "the 160-th tree have been built\n",
      "the 161-th tree have been built\n",
      "the 162-th tree have been built\n",
      "the 163-th tree have been built\n",
      "the 164-th tree have been built\n",
      "the 165-th tree have been built\n",
      "the 166-th tree have been built\n",
      "the 167-th tree have been built\n",
      "the 168-th tree have been built\n",
      "the 169-th tree have been built\n",
      "the 170-th tree have been built\n",
      "the 171-th tree have been built\n",
      "the 172-th tree have been built\n",
      "the 173-th tree have been built\n",
      "the 174-th tree have been built\n",
      "the 175-th tree have been built\n",
      "the 176-th tree have been built\n",
      "the 177-th tree have been built\n",
      "the 178-th tree have been built\n",
      "the 179-th tree have been built\n",
      "the 180-th tree have been built\n",
      "the 181-th tree have been built\n",
      "the 182-th tree have been built\n",
      "the 183-th tree have been built\n",
      "the 184-th tree have been built\n",
      "the 185-th tree have been built\n",
      "the 186-th tree have been built\n",
      "the 187-th tree have been built\n",
      "the 188-th tree have been built\n",
      "the 189-th tree have been built\n",
      "the 190-th tree have been built\n",
      "the 191-th tree have been built\n",
      "the 192-th tree have been built\n",
      "the 193-th tree have been built\n",
      "the 194-th tree have been built\n",
      "the 195-th tree have been built\n",
      "the 196-th tree have been built\n",
      "the 197-th tree have been built\n",
      "the 198-th tree have been built\n",
      "the 199-th tree have been built\n",
      "the 200-th tree have been built\n",
      "the 201-th tree have been built\n",
      "the 202-th tree have been built\n",
      "the 203-th tree have been built\n",
      "the 204-th tree have been built\n",
      "the 205-th tree have been built\n",
      "the 206-th tree have been built\n",
      "the 207-th tree have been built\n",
      "the 208-th tree have been built\n",
      "the 209-th tree have been built\n",
      "the 210-th tree have been built\n",
      "the 211-th tree have been built\n",
      "the 212-th tree have been built\n",
      "the 213-th tree have been built\n",
      "the 214-th tree have been built\n",
      "the 215-th tree have been built\n",
      "the 216-th tree have been built\n",
      "the 217-th tree have been built\n",
      "the 218-th tree have been built\n",
      "the 219-th tree have been built\n",
      "the 220-th tree have been built\n",
      "the 221-th tree have been built\n",
      "the 222-th tree have been built\n",
      "the 223-th tree have been built\n",
      "the 224-th tree have been built\n",
      "the 225-th tree have been built\n",
      "the 226-th tree have been built\n",
      "the 227-th tree have been built\n",
      "the 228-th tree have been built\n",
      "the 229-th tree have been built\n",
      "the 230-th tree have been built\n",
      "the 231-th tree have been built\n",
      "the 232-th tree have been built\n",
      "the 233-th tree have been built\n",
      "the 234-th tree have been built\n",
      "the 235-th tree have been built\n",
      "the 236-th tree have been built\n",
      "the 237-th tree have been built\n",
      "the 238-th tree have been built\n",
      "the 239-th tree have been built\n",
      "the 240-th tree have been built\n",
      "the 241-th tree have been built\n",
      "the 242-th tree have been built\n",
      "the 243-th tree have been built\n",
      "the 244-th tree have been built\n",
      "the 245-th tree have been built\n",
      "the 246-th tree have been built\n",
      "the 247-th tree have been built\n",
      "the 248-th tree have been built\n",
      "the 249-th tree have been built\n",
      "the 250-th tree have been built\n",
      "the 251-th tree have been built\n",
      "the 252-th tree have been built\n",
      "the 253-th tree have been built\n",
      "the 254-th tree have been built\n",
      "the 255-th tree have been built\n",
      "the 256-th tree have been built\n",
      "the 257-th tree have been built\n",
      "the 258-th tree have been built\n",
      "the 259-th tree have been built\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 260-th tree have been built\n",
      "the 261-th tree have been built\n",
      "the 262-th tree have been built\n",
      "the 263-th tree have been built\n",
      "the 264-th tree have been built\n",
      "the 265-th tree have been built\n",
      "the 266-th tree have been built\n",
      "the 267-th tree have been built\n",
      "the 268-th tree have been built\n",
      "the 269-th tree have been built\n",
      "the 270-th tree have been built\n",
      "the 271-th tree have been built\n",
      "the 272-th tree have been built\n",
      "the 273-th tree have been built\n",
      "the 274-th tree have been built\n",
      "the 275-th tree have been built\n",
      "the 276-th tree have been built\n",
      "the 277-th tree have been built\n",
      "the 278-th tree have been built\n",
      "the 279-th tree have been built\n",
      "the 280-th tree have been built\n",
      "the 281-th tree have been built\n",
      "the 282-th tree have been built\n",
      "the 283-th tree have been built\n",
      "the 284-th tree have been built\n",
      "the 285-th tree have been built\n",
      "the 286-th tree have been built\n",
      "the 287-th tree have been built\n",
      "the 288-th tree have been built\n",
      "the 289-th tree have been built\n",
      "the 290-th tree have been built\n",
      "the 291-th tree have been built\n",
      "the 292-th tree have been built\n",
      "the 293-th tree have been built\n",
      "the 294-th tree have been built\n",
      "the 295-th tree have been built\n",
      "the 296-th tree have been built\n",
      "the 297-th tree have been built\n",
      "the 298-th tree have been built\n",
      "the 299-th tree have been built\n",
      "the 300-th tree have been built\n",
      "the 301-th tree have been built\n",
      "the 302-th tree have been built\n",
      "the 303-th tree have been built\n",
      "the 304-th tree have been built\n",
      "the 305-th tree have been built\n",
      "the 306-th tree have been built\n",
      "the 307-th tree have been built\n",
      "the 308-th tree have been built\n",
      "the 309-th tree have been built\n",
      "the 310-th tree have been built\n",
      "the 311-th tree have been built\n",
      "the 312-th tree have been built\n",
      "the 313-th tree have been built\n",
      "the 314-th tree have been built\n",
      "the 315-th tree have been built\n",
      "the 316-th tree have been built\n",
      "the 317-th tree have been built\n",
      "the 318-th tree have been built\n",
      "the 319-th tree have been built\n",
      "the 320-th tree have been built\n",
      "the 321-th tree have been built\n",
      "the 322-th tree have been built\n",
      "the 323-th tree have been built\n",
      "the 324-th tree have been built\n",
      "the 325-th tree have been built\n",
      "the 326-th tree have been built\n",
      "the 327-th tree have been built\n",
      "the 328-th tree have been built\n",
      "the 329-th tree have been built\n",
      "the 330-th tree have been built\n",
      "the 331-th tree have been built\n",
      "the 332-th tree have been built\n",
      "the 333-th tree have been built\n",
      "the 334-th tree have been built\n",
      "the 335-th tree have been built\n",
      "the 336-th tree have been built\n",
      "the 337-th tree have been built\n",
      "the 338-th tree have been built\n",
      "the 339-th tree have been built\n",
      "the 340-th tree have been built\n",
      "the 341-th tree have been built\n",
      "the 342-th tree have been built\n",
      "the 343-th tree have been built\n",
      "the 344-th tree have been built\n",
      "the 345-th tree have been built\n",
      "the 346-th tree have been built\n",
      "the 347-th tree have been built\n",
      "the 348-th tree have been built\n",
      "the 349-th tree have been built\n",
      "the 350-th tree have been built\n",
      "the 351-th tree have been built\n",
      "the 352-th tree have been built\n",
      "the 353-th tree have been built\n",
      "the 354-th tree have been built\n",
      "the 355-th tree have been built\n",
      "the 356-th tree have been built\n",
      "the 357-th tree have been built\n",
      "the 358-th tree have been built\n",
      "the 359-th tree have been built\n",
      "the 360-th tree have been built\n",
      "the 361-th tree have been built\n",
      "the 362-th tree have been built\n",
      "the 363-th tree have been built\n",
      "the 364-th tree have been built\n",
      "the 365-th tree have been built\n",
      "the 366-th tree have been built\n",
      "the 367-th tree have been built\n",
      "the 368-th tree have been built\n",
      "the 369-th tree have been built\n",
      "the 370-th tree have been built\n",
      "the 371-th tree have been built\n",
      "the 372-th tree have been built\n",
      "the 373-th tree have been built\n",
      "the 374-th tree have been built\n",
      "the 375-th tree have been built\n",
      "the 376-th tree have been built\n",
      "the 377-th tree have been built\n",
      "the 378-th tree have been built\n",
      "the 379-th tree have been built\n",
      "the 380-th tree have been built\n",
      "the 381-th tree have been built\n",
      "the 382-th tree have been built\n",
      "the 383-th tree have been built\n",
      "the 384-th tree have been built\n",
      "the 385-th tree have been built\n",
      "the 386-th tree have been built\n",
      "the 387-th tree have been built\n",
      "the 388-th tree have been built\n",
      "the 389-th tree have been built\n",
      "the 390-th tree have been built\n",
      "the 391-th tree have been built\n",
      "the 392-th tree have been built\n",
      "the 393-th tree have been built\n",
      "the 394-th tree have been built\n",
      "the 395-th tree have been built\n",
      "the 396-th tree have been built\n",
      "the 397-th tree have been built\n",
      "the 398-th tree have been built\n",
      "the 399-th tree have been built\n",
      "the 400-th tree have been built\n",
      "the 401-th tree have been built\n",
      "the 402-th tree have been built\n",
      "the 403-th tree have been built\n",
      "the 404-th tree have been built\n",
      "the 405-th tree have been built\n",
      "the 406-th tree have been built\n",
      "the 407-th tree have been built\n",
      "the 408-th tree have been built\n",
      "the 409-th tree have been built\n",
      "the 410-th tree have been built\n",
      "the 411-th tree have been built\n",
      "the 412-th tree have been built\n",
      "the 413-th tree have been built\n",
      "the 414-th tree have been built\n",
      "the 415-th tree have been built\n",
      "the 416-th tree have been built\n",
      "the 417-th tree have been built\n",
      "the 418-th tree have been built\n",
      "the 419-th tree have been built\n",
      "the 420-th tree have been built\n",
      "the 421-th tree have been built\n",
      "the 422-th tree have been built\n",
      "the 423-th tree have been built\n",
      "the 424-th tree have been built\n",
      "the 425-th tree have been built\n",
      "the 426-th tree have been built\n",
      "the 427-th tree have been built\n",
      "the 428-th tree have been built\n",
      "the 429-th tree have been built\n",
      "the 430-th tree have been built\n",
      "the 431-th tree have been built\n",
      "the 432-th tree have been built\n",
      "the 433-th tree have been built\n",
      "the 434-th tree have been built\n",
      "the 435-th tree have been built\n",
      "the 436-th tree have been built\n",
      "the 437-th tree have been built\n",
      "the 438-th tree have been built\n",
      "the 439-th tree have been built\n",
      "the 440-th tree have been built\n",
      "the 441-th tree have been built\n",
      "the 442-th tree have been built\n",
      "the 443-th tree have been built\n",
      "the 444-th tree have been built\n",
      "the 445-th tree have been built\n",
      "the 446-th tree have been built\n",
      "the 447-th tree have been built\n",
      "the 448-th tree have been built\n",
      "the 449-th tree have been built\n",
      "the 450-th tree have been built\n",
      "the 451-th tree have been built\n",
      "the 452-th tree have been built\n",
      "the 453-th tree have been built\n",
      "the 454-th tree have been built\n",
      "the 455-th tree have been built\n",
      "the 456-th tree have been built\n",
      "the 457-th tree have been built\n",
      "the 458-th tree have been built\n",
      "the 459-th tree have been built\n",
      "the 460-th tree have been built\n",
      "the 461-th tree have been built\n",
      "the 462-th tree have been built\n",
      "the 463-th tree have been built\n",
      "the 464-th tree have been built\n",
      "the 465-th tree have been built\n",
      "the 466-th tree have been built\n",
      "the 467-th tree have been built\n",
      "the 468-th tree have been built\n",
      "the 469-th tree have been built\n",
      "the 470-th tree have been built\n",
      "the 471-th tree have been built\n",
      "the 472-th tree have been built\n",
      "the 473-th tree have been built\n",
      "the 474-th tree have been built\n",
      "the 475-th tree have been built\n",
      "the 476-th tree have been built\n",
      "the 477-th tree have been built\n",
      "the 478-th tree have been built\n",
      "the 479-th tree have been built\n",
      "the 480-th tree have been built\n",
      "the 481-th tree have been built\n",
      "the 482-th tree have been built\n",
      "the 483-th tree have been built\n",
      "the 484-th tree have been built\n",
      "the 485-th tree have been built\n",
      "the 486-th tree have been built\n",
      "the 487-th tree have been built\n",
      "the 488-th tree have been built\n",
      "the 489-th tree have been built\n",
      "the 490-th tree have been built\n",
      "the 491-th tree have been built\n",
      "the 492-th tree have been built\n",
      "the 493-th tree have been built\n",
      "the 494-th tree have been built\n",
      "the 495-th tree have been built\n",
      "the 496-th tree have been built\n",
      "the 497-th tree have been built\n",
      "the 498-th tree have been built\n",
      "the 499-th tree have been built\n"
     ]
    }
   ],
   "source": [
    "def bagging(data, target, test, batch=256, n_tree=500, max_depth=4):\n",
    "    forest = {}\n",
    "    prediction = np.zeros((test.shape[0], 1))\n",
    "    batch_index = data.sample(batch).index\n",
    "    for i in range(n_tree):\n",
    "        tree = Tree(car, check=False)\n",
    "        tree.fit(data=car, index=batch_index, target=target, max_layer=max_depth)\n",
    "        forest[i] = tree\n",
    "        prediction = np.hstack((prediction, np.array(tree.predict(test)).reshape(test.shape[0], 1)))\n",
    "        print(\"the \" + str(i) + \"-th tree have been built\")\n",
    "    prediction = np.delete(prediction, 0, axis=1)\n",
    "    return forest, prediction\n",
    "\n",
    "\n",
    "tmp, prediction = bagging(car.iloc[train_index], target='acc', test=car.iloc[test_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "500棵确实需要训练一段时间...其实耗时最长的并不是训练，而是每棵树对测试集进行预测，我觉得这棵树还能写得更快，这样在bagging的时候耗时就会更短。\n",
    "\n",
    "此时的预测结果是一个*测试样本数*\\* *树的数量*的一个预测结果矩阵，第i行第j列表示第i个样本在第j棵树上的预测结果。\n",
    "\n",
    "这里我们的问题是多分类问题，在预测结果的呈现上考虑不一样的任务有不一样的需求，如果我们需要一个结果，那么我们可以对最后的结果逐行取众数。如果我们想要知道（所有分类的）概率值，譬如我们用似然函数评价模型时，那么我们需要统计每一行（也就是每个样本）各个类频次（也就是几百个弱学习器的结果）再做除法。\n",
    "\n",
    "这里的效果提升并不明显，推测是因为数据有偏差，如果你有兴趣详细看一下*acc*变量，你会发现*‘acc’*和*‘unacc’*的比例特别大，导致另外两个类别  *‘good’*，*‘vgood’*的样本比例较少。这种情况下很有可能我们采样时就会导致入样的*‘good’*和*‘vgood’*更少，甚至只有一两个，那么这种情况需要极细地分类才能使分类器产生这样的输出。而我们并不会将所有变量放进模型，这就进一步导致模型的偏差。这种情况需要靠抽样方法进行一定的调整，会在以后给出我了解的一些方法。\n",
    "\n",
    "下面的*organize*函数用的是普通的平均方法把所有的结果加和在一起然后除以树的棵数就得到了预测各类的概率值。\n",
    "\n",
    "如果你想用加权的投票法，也就是把让预测效果好的树权重变大，可以考虑直接用准确率进行加权，也就是在\n",
    "```Python\n",
    "res += prediction[:, i].reshape(n, 1) == labels\n",
    "```\n",
    "这一行中乘上一个准确率，在最后输出的时候除以所有树准确率的和。或者进行非线性的加权，用单增的函数比如指数函数计算准确率对应的函数值然后按照相同的方法进行加权。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T16:15:06.915878Z",
     "start_time": "2019-04-14T16:15:06.753903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(519, 4)\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "labels = labels.reshape(1, 4)\n",
    "\n",
    "def organize(prediction, labels):\n",
    "    \"\"\"\n",
    "    prediction is an n*n_tree matrix n_tree is # of trees\n",
    "    labels is a 1*p vector p is # of levels we need to predict\n",
    "    \"\"\"\n",
    "    n = prediction.shape[0]\n",
    "    # print(n, labels.shape[1])\n",
    "    res = np.zeros((n, labels.shape[1]))\n",
    "    for i in range(prediction.shape[1]):\n",
    "        res += prediction[:, i].reshape(n, 1) == labels\n",
    "    \n",
    "    return res/prediction.shape[1]\n",
    "\n",
    "output = organize(prediction, labels)\n",
    "print(output.shape)\n",
    "print(np.sum(output, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-14T16:26:03.891008Z",
     "start_time": "2019-04-14T16:26:03.875009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7591522157996147"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(labels[0][np.argmax(output, axis=1)] == car['acc'][test_index])/len(test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果相比单棵树有提升，但是相比完全生长的决策树还是差了一些。原因应该就是样本不均衡导致样本较少的类在拟合效果较差的树中输出的可能性更低了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

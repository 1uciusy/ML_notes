{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EM算法\n",
    "\n",
    "EM算法（expectation maximization algorithm）是具有浓厚概率论和数理统计学特点的算法，主要用于计算含有隐变量概率模型的极大似然估计。\n",
    "\n",
    "我们先前在朴素贝叶斯和高斯判别模型中求参数的方法就是极大似然估计，但是我们学习到的是预测变量和观测变量之间的直接关系。如果观测的变量和我们要预测的变量没有直接的关系，观测到的变量通过影响隐含的变量（这个变量可以是具有实际意义但我们观测不到的，也可以是没有实际意义我们创造出来试图进行解释和改善模型的）再影响到预测变量的情况下，我们就需要用到EM算法。\n",
    "\n",
    "## 一、直观理解\n",
    "\n",
    "考虑如下例子：我们有A、B、C三枚硬币，进行如下实验，先掷硬币A，如果正面朝上掷硬币B，如果反面朝上则掷硬币C，三个硬币正面向上的概率分别为$\\pi,p,q$。每次实验只记录最后的硬币结果，也就是我们不知道刚开始掷硬币A的结果，而只是通过最终的硬币向上的结果对三个参数进行估计。\n",
    "\n",
    "假设结果如下：\n",
    "\n",
    "$$\n",
    "1,1,0,1,0,0,1,0,1,1\n",
    "$$\n",
    "\n",
    "设最终的输出结果为y，硬币A的中间结果为z，则模型可以描述如下：\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    P(y|\\theta) &= \\sum_z P(y,z|\\theta) = \\sum_z P(z|\\theta)P(y|z,\\theta)\\\\\n",
    "        &= \\pi p^y(1-p)^{1-y} + (1-\\pi) q^y(1-q)^{1-y}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "此处的$\\theta$可以看作是广义的参数集合，y和z也可以看作是广义的预测变量和中间变量，而求和项则是针对隐变量所有的可能结果的求和,$\\pi$和$(1-\\pi)$分别是A正面和反面的概率$p^y(1-p)^{1-y}$和$q^y(1-q)^{1-y}$是硬币B和C掷出当前结果的概率，因此他们和$\\pi$、$(1-\\pi)$分别相乘就是已知实验结果的情况下硬币来自B和C的概率。\n",
    "\n",
    "其似然函数为：\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    L(Y|\\theta) &= \\prod_{j=1}^n \\left(\\sum_z P(z|\\theta)P(y|z,\\theta)\\right) \\\\\n",
    "        &= \\prod_{j=1}^n\\left[\\pi p^{y_j}(1-p)^{1-y_j} + (1-\\pi) q^{y_j}(1-q)^{1-y_j}\\right]\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "我们想要求的就是参数集合$\\theta = \\{\\pi,p,q\\}$的极大似然估计，也就是$\\hat \\theta = arg\\ \\underset{\\theta}{max}\\ ln\\left(likelihood\\right)$，因为似然函数累乘的内部是求和的形式，所以求对数后没办法直接展开求解析解，所以只能通过迭代求得数值解。EM就是求解的**其中一种**算法。\n",
    "\n",
    "EM算法需要选取参数的初值，记为$\\theta^{(0)} = \\{\\pi^{(0)},p^{(0)},q^{(0)}\\}$，然后通过E步求期望，M步求极大似然估计来更新参数，直到参数收敛为止。设第i次迭代之后的估计值为$\\theta^{(i)} = \\{\\pi^{(i)},p^{(i)},q^{(i)}\\}$，EM算法的第i+1次迭代如下（之所以称次而不是步是因为一次迭代涉及两步）：\n",
    "\n",
    "### E步：在已有观测数据y及第i步估计值$\\theta=\\theta^{(i)}$的条件下，求基于完全数据的对数似然函数的期望\n",
    "\n",
    "$$\n",
    "Q(\\theta|y, \\theta^{(i)}) = E_z\\left[lnL(y,z|\\theta^{(i)})\\right]\n",
    "$$\n",
    "\n",
    "计算在模型参数$\\theta^{(i)} = \\{\\pi^{(i)},p^{(i)},q^{(i)}\\}$的情况下观测到数据$y_i$来自硬币B的概率（也就是隐变量）为：\n",
    "\n",
    "$$\n",
    "\\hat \\pi = \\mu_j^{(i+1)} = \\frac{\\pi^{(i)} (p^{(i)})^{y_j}(1-p^{(i)})^{1-y_j}}{\\pi^{(i)} (p^{(i)})^{y_j}(1-p^{(i)})^{1-y_j} + (1-\\pi^{(i)}) (q^{(i)})^{y_j}(1-q)^{1-y_j}}\n",
    "$$\n",
    "\n",
    "其中分母是掷出当前结果（比如正面）的概率，分子是硬币B掷出当前结果的概率。所以这个分式就是观测到的数据来自硬币B的概率。\n",
    "\n",
    "### M步：求$Q(\\theta|y,\\theta^{(i)})$关于$\\theta$的最大值$\\theta^{(i+1)}$\n",
    "\n",
    "根据E步的概率求模型新的估计值\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    \\pi^{(i+1)} &= \\frac1n\\sum_{j=1}^n\\mu_j^{(i+1)} \\\\\n",
    "    \\\\\n",
    "    p^{(i+1)} &= \\frac{\\sum_{j=1}^n\\mu_j^{(i+1)}y_j}{\\sum_{j=1}^n\\mu_j^{(i+1)}}\\\\\n",
    "    \\\\\n",
    "    q^{(i+1)} &= \\frac{\\sum_{j=1}^n(1-\\mu_j^{(i+1)})y_j}{\\sum_{j=1}^n（1-\\mu_j^{(i+1)}）}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "观测来自于硬币B的概率就等价于A掷出正面的概率，所以第一个等式很好理解。而第二个等式分母表示来自硬币B的概率和，分子表示来自硬币B且掷出正面的概率和。第三个等式和第二个含义相同。\n",
    "\n",
    "假设模型的初值取$\\pi^{(0)}=0.5,p^{(0)}=0.5,q^{(0)}=0.5$,有公式可得到稳定的极大似然估计值为：$\\hat \\pi=0.5,\\hat p=0.6,\\hat q=0.6$。\n",
    "\n",
    "我们来实践一下\n",
    "\n",
    "*本例来自李航《统计学习方法》p155-158*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T18:09:13.190366Z",
     "start_time": "2019-04-09T18:09:13.172369Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5 0.6 0.6]\n",
      "[0.5 0.6 0.6]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y = np.array([1,1,0,1,0,0,1,0,1,1]).reshape((10, 1))\n",
    "theta = np.array([0.5, 0.5, 0.5]).reshape((3, 1)) # pi p and q\n",
    "tmp = np.zeros((3, 1))\n",
    "mu = 0\n",
    "\n",
    "while np.sum(theta-tmp) > 1e-6:\n",
    "    pi, p, q = theta[0], theta[1], theta[2]\n",
    "    mu = np.array([pi*p**i*(1-p)**(1-i)/(pi*p**i*(1-p)**(1-i) + (1-pi)*q**i*(1-q)**(1-i)) for i in y]).reshape((10, 1))\n",
    "    pi = np.mean(mu)\n",
    "    p = np.sum(mu*y)/np.sum(mu)\n",
    "    q = np.sum((1-mu)*y)/np.sum(1-mu)\n",
    "    tmp = theta.copy()\n",
    "    theta = np.array([pi, p, q])\n",
    "    print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T17:57:45.829184Z",
     "start_time": "2019-04-09T17:57:45.822186Z"
    }
   },
   "source": [
    "可以看到在第二次迭代的时候就已经稳定了，那么如果我们换一个初值呢？\n",
    "\n",
    "用$\\pi^{(0)}=0.4,p^{(0)}=0.6,q^{(0)}=0.7$进行尝试。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-09T18:11:36.976964Z",
     "start_time": "2019-04-09T18:11:36.910959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40641711 0.53684211 0.64324324]\n",
      "[0.40641711 0.53684211 0.64324324]\n"
     ]
    }
   ],
   "source": [
    "theta = np.array([0.4, 0.6, 0.7]).reshape((3, 1)) # pi p and q\n",
    "tmp = np.zeros((3, 1))\n",
    "mu = 0\n",
    "\n",
    "while np.sum((theta-tmp)**2) > 1e-6:\n",
    "    pi, p, q = theta[0], theta[1], theta[2]\n",
    "    mu = np.array([pi*p**i*(1-p)**(1-i)/(pi*p**i*(1-p)**(1-i) + (1-pi)*q**i*(1-q)**(1-i)) for i in y]).reshape((10, 1))\n",
    "    pi = np.mean(mu)\n",
    "    p = np.sum(mu*y)/np.sum(mu)\n",
    "    q = np.sum((1-mu)*y)/np.sum(1-mu)\n",
    "    tmp = theta.copy()\n",
    "    theta = np.array([pi, p, q])\n",
    "    print(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也是两步就稳定下来了，如果你有《统计学习方法》这本书会发现结论和书上的内容一致。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高斯混合模型\n",
    "\n",
    "EM算法就和梯度下降一样，是一个优化算法，优化算法只有找到适合自己的模型才能发挥它的作用。高斯混合模型就是EM算法的一个主要用武之地。\n",
    "\n",
    "高斯混合模型是用于聚类的算法，也就是监督学习算法。它假设数据是由K个高斯分布生成的，K就是我们希望聚类的类数，通过EM算法得到各个高斯分布的概率密度函数，最后根据样本点在哪个类的概率密度函数值乘上对应系数的值最大确定样本属于哪一类。\n",
    "\n",
    "### 模型形式\n",
    "\n",
    "高斯混合模型的模型形式为：\n",
    "\n",
    "$$\n",
    "P(x) = \\sum_{j=1}^K \\alpha_j \\phi(x|\\theta_j)\n",
    "$$\n",
    "\n",
    "其中$\\alpha_j$是系数且大于零小于一，$\\sum_{j=1}^K \\alpha_j = 1$；$\\phi(x|\\theta_j)$是正态分布密度函数（也叫高斯分布），$\\theta_j=(\\mu_j, \\sigma_j^2)$\n",
    "\n",
    "$$\n",
    "\\phi(x|\\theta_j) = \\frac{1}{\\sqrt{2\\pi}\\sigma_j}exp\\left(-\\frac{(x-\\mu_j)^2}{2\\sigma_j^2}\\right)\n",
    "$$\n",
    "\n",
    "一般混合模型可以用任意分布函数替代模型中的高斯函数，后续推导根据函数性质略有不同。\n",
    "\n",
    "由于$\\sum_{j=1}^K \\alpha_j = 1$，所以我们不难发现，高斯混合模型本质上是一个概率密度函数。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 高斯混合模型的EM估计\n",
    "\n",
    "假设观测数据$x_1, x_2, \\dots, x_n$由高斯混合模型生成，\n",
    "\n",
    "$$\n",
    "P(x|\\theta) = \\sum_{j=1}^K\\alpha_j \\phi(x|\\theta_j)\n",
    "$$\n",
    "\n",
    "其中$\\theta = \\{\\alpha_1, \\alpha_2, \\dots, \\alpha_K;\\theta_1, \\theta_2,\\dots, \\theta_K\\}$，$\\alpha_j$称为决定系数\n",
    "\n",
    "设隐变量为：\n",
    "\n",
    "$$\n",
    "\\gamma_{ij} = \\begin{cases}\n",
    "        1, &第i个观测来自第j个分模型\\\\\n",
    "        0, &其他\n",
    "    \\end{cases}\n",
    "$$\n",
    "\n",
    "有了观测数据$x_i$及未观测数据$\\gamma_{ij}$，那么完全数据是$\\left(x_i,\\gamma_{i1},\\gamma_{i2},\\dots,\\gamma_{iK}\\right)$\n",
    "\n",
    "于是我们的似然函数就是：\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    L(x,\\gamma|\\theta) &= \\prod_{i=1}^N P(x_i,\\gamma_{i1},\\gamma_{i2},\\dots,\\gamma_{iK}|\\theta)\\\\\n",
    "        &= \\prod_{i=1}^N \\prod_{j=1}^K \\left[\\alpha_j \\phi(x_i|\\theta_j)\\right]^{\\gamma_{ij}}\\\\\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "取对数之后：\n",
    "\n",
    "$$\n",
    "lnL(x,\\gamma |\\theta) = \\sum_{i=1}^N \\sum_{j=1}^K \\left[\\gamma_{ij}ln(\\alpha_j)+\\gamma_{ij}ln\\left(\\phi\\left(x_i|\\mu_j,\\sigma_j\\right)\\right) \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E步：\n",
    "\n",
    "对对数似然函数求期望：\n",
    "\n",
    "$$\n",
    "Q\\left(\\theta, \\theta^{(i)}\\right) = \\sum_{i=1}^N \\sum_{j=1}^K \\left[E\\left(\\gamma_{ij}\\right)ln(\\alpha_j)+E\\left(\\gamma_{ij}\\right)ln\\left(\\phi\\left(x_i|\\mu_j^{(i)},\\left(\\sigma_j^{(i)}\\right)^2\\right)\\right) \\right]\n",
    "$$\n",
    "\n",
    "回忆最开始的例子，E步需要计算第j个观测数据来自第k个高斯分布的概率，类比上例可以写作：\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    \\hat \\gamma_{ij} &= E(\\gamma_{ij}| x,\\theta^{(i)})=P(\\gamma_{ij}=1|x,\\theta^{(i)}) \\\\\n",
    "        \\\\\n",
    "        &= \\frac{P(\\gamma_{ij}=1,x_i|\\theta^{(i)})}{\\sum_{j=1}^K P(\\gamma_{ij}=1,x_i|\\theta^{(i)})}\\\\\n",
    "        \\\\\n",
    "        &= \\frac{P(x_i|\\gamma_{ij}=1,\\theta^{(i)})P(\\gamma_{ij}=1|\\theta^{(i)})}{\\sum_{j=1}^K P(x_i|\\gamma_{ij}=1,\\theta^{(i)})P(\\gamma_{ij}=1|\\theta^{(i)})}\\\\\n",
    "        \\\\\n",
    "        &= \\frac{\\alpha_j\\phi(x_i|\\theta_j^{(i)})}{\\sum_{j=1}^K\\alpha_j\\phi(x_i|\\theta_j^{(i)})}\n",
    "\\end{split}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### M步：\n",
    "\n",
    "M步是求解参数的过程。参数主要分两类：一类是有约束和分模型无关的，也就是我们的决定系数$\\alpha_j$；另一类是没有约束，能够决定单个分模型形状的概率分布参数$\\theta_j = \\{\\mu_j,\\sigma_j^2\\}$\n",
    "\n",
    "**决定系数**的求解是通过拉格朗日数乘法：\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    &min\\ Q(\\theta, \\theta^{(i)}) = \\sum_{i=1}^N \\sum_{j=1}^K \\left[E\\left(\\gamma_{ij}\\right)ln(\\alpha_j)+E\\left(\\gamma_{ij}\\right)ln\\left(\\phi\\left(x_i|\\mu_j^{(i)},\\left(\\sigma_j^{(i)}\\right)^2\\right)\\right) \\right]\\\\\n",
    "    \\\\\n",
    "    s.t.\\ &\\sum_{j=1}^K\\alpha_j = 1 \\\\\n",
    "    \\\\\n",
    "    \\Rightarrow &f\\left(\\theta^{(i)}, \\lambda \\right)=Q(\\theta|x, \\theta^{(i)}) + \\lambda \\left(1-\\sum_{j=1}^K\\alpha_j\\right)\\\\\n",
    "    \\\\\n",
    "    \\Rightarrow &\\begin{cases}\n",
    "        \\frac{\\partial f\\left(\\theta^{(i)}, \\lambda \\right)}{\\partial \\alpha_j} = \\frac{\\sum_{i=1}^N \\gamma_{ij}}{\\alpha_j}-\\lambda = 0\\\\\n",
    "        \\frac{\\partial f\\left(\\theta^{(i)}, \\lambda \\right)}{\\partial \\lambda} = 1-\\sum_{j=1}^K\\alpha_j\n",
    "    \\end{cases}\\\\\n",
    "    \\\\\n",
    "    \\Rightarrow & \\alpha_j = \\frac{\\sum_{i=1}^N \\hat \\gamma_{ij}}{\\sum_{i=1}^N \\sum_{j=1}^K \\hat \\gamma_{ij}}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "**分模型参数**是通过对对数似然函数求偏导，令其等于0得到：\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    &ln\\left(\\phi\\left(x_i|\\mu_j^{(i)},\\left(\\sigma_j^{(i)}\\right)^2\\right)\\right) = -\\frac12 ln(2\\pi) - \\frac12 ln \\left(\\sigma_j^{(i)}\\right)^2 - \\frac{\\left(x_i - \\mu_j^{(i)}\\right)^2}{2\\left(\\sigma_j^{(i)}\\right)^2}\\\\\n",
    "    \\Rightarrow &\\begin{cases}\n",
    "        \\frac{\\partial ln\\left(\\phi\\right)}{\\partial \\mu_j^{(i)}} = \\frac{x_i - \\mu_j^{(i)}}{\\left(\\sigma_j^{(i)}\\right)^2} \\\\\n",
    "        \\frac{\\partial ln\\left(\\phi\\right)}{\\partial \\left(\\sigma_j^{(i)}\\right)^2} = -\\frac12 \\frac{1}{\\left(\\sigma_j^{(i)}\\right)^2} + \\frac{\\left(x_i - \\mu_j^{(i)} \\right)}{2\\left(\\sigma_j^{(i)}\\right)^4}\n",
    "    \\end{cases}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "因为我们是对第j个分模型求参数的偏导，所以与其无关的分模型就被视为常数，这样就能直接去掉内部从1到K的求和，并且这里的i有两个，一个是作为指示样本的第i个样本，另一个是指示迭代次数的第i次迭代，要区分对待。\n",
    "\n",
    "$$\n",
    "\\frac{\\partial Q}{\\partial \\mu_j^{(i)}} = \\sum_{i=1}^N \\hat \\gamma_{ij}\\frac{x_i - \\mu_j^{(i)}}{\\left(\\sigma_j^{(i)}\\right)^2}\n",
    "$$\n",
    "\n",
    "令其为0，解得：\n",
    "\n",
    "$$\n",
    "\\hat \\mu_j = \\mu_j^{(i+1)} = \\frac{\\sum_{i=1}^N \\hat\\gamma_{ij}x_i}{\\sum_{i=1}^N \\hat \\gamma_{ij}}\n",
    "$$\n",
    "\n",
    "同样对$\\sigma$求导有：\n",
    "\n",
    "$$\n",
    "\\frac{\\partial Q}{\\left(\\sigma_j^{(i)}\\right)^2} = \\sum_{i=1}^N\\gamma_{ij} \\left[-\\frac{1}{2\\left(\\sigma_j^{(i)}\\right)^2}+\\frac{\\left(x_i - \\mu_j^{(i)} \\right)}{2\\left(\\sigma_j^{(i)}\\right)^4}\\right]\n",
    "$$\n",
    "\n",
    "令其等于0也有：\n",
    "\n",
    "$$\n",
    "\\hat \\sigma_j^2 = \\frac{\\sum_{i=1}^N \\hat\\gamma_{ij}\\left(x_i - \\mu_j^{(i)}\\right)^2}{\\sum_{i=1}^N \\hat \\gamma_{ij}}\n",
    "$$\n",
    "\n",
    "汇总一下：\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    &\\alpha_j = \\frac{\\sum_{i=1}^N \\hat \\gamma_{ij}}{\\sum_{i=1}^N \\sum_{j=1}^K \\hat \\gamma_{ij}}\\\\\n",
    "    &\\hat \\mu_j = \\frac{\\sum_{i=1}^N \\hat\\gamma_{ij}x_i}{\\sum_{i=1}^N \\hat \\gamma_{ij}}\\\\\n",
    "    &\\hat \\sigma_j^2 = \\frac{\\sum_{i=1}^N \\hat\\gamma_{ij}\\left(x_i - \\mu_j^{(i)}\\right)^2}{\\sum_{i=1}^N \\hat \\gamma_{ij}}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "这就完成了一次迭代。但这是简单的一维情况，通常情况下我们进行聚类还是以二维坐标或者更高维的例子为主。这种情况下依然可以有类似于上述的推导，但是我的相关知识不一定能解释清楚，所以我就直接用一维的向多维的情况进行扩展。此时对于一个p维的高斯混合模型，其迭代结果为：\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    &\\alpha_j = \\frac{\\sum_{i=1}^N \\hat \\gamma_{ij}}{\\sum_{i=1}^N \\sum_{j=1}^K \\hat \\gamma_{ij}}\\\\\n",
    "    &\\hat \\mu_j = \\frac{\\sum_{i=1}^N \\hat\\gamma_{ij}x_i}{\\sum_{i=1}^N \\hat \\gamma_{ij}}\\\\\n",
    "    &\\hat \\Sigma_j = \\frac{\\sum_{i=1}^N \\hat\\gamma_{ij}\\left(x_i - \\mu_j^{(i)}\\right)\\left(x_i - \\mu_j^{(i)}\\right)^T}{\\sum_{i=1}^N \\hat \\gamma_{ij}}\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "其中$\\alpha$含义不变，仍是表示概率的实数。$x_i.\\mu_j$都是p维列向量，$\\Sigma$是$p \\times p$维的协方差矩阵。如果你有一定的多元统计知识，对这种扩展应该能够理解。\n",
    "\n",
    "*原先是准备按照李航的《统计学习方法》来完成推导，但是他的推导用的符号等等对于我来说接受比较困难，包括西瓜书也是，所以最后决定自己推导*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测\n",
    "\n",
    "通常我们聚类不仅仅是希望把手头的样本数据进行无标签的分类，更多时候我们希望通过聚类对样本进行一种归纳和总结，然后将新的数据归于其中一类，也就是预测。\n",
    "\n",
    "这种预测我接触到的最大的用途就是填补缺失值，譬如我们的训练数据中有一列数据有缺失，我们需要补全缺失才能使模型正常工作（因为不管是NAN、None还是NULL在大部分编程语言中都是无法参与计算的）。这时候粗糙的补全方法就是连续变量用均值、离散变量用众数。\n",
    "\n",
    "但如果我们希望用更精细的方法进行补全，聚类就是一个很好的途径。像Kmeans、高斯混合模型这些聚类的本质就是找到一组假设原型（prototype）对数据进行刻画。Kmeans的原型是各个类的样本中心，而GMM的原型就是模型的各个组成部分，即各个高斯分布。\n",
    "\n",
    "当我们用GMM进行预测时，我们需要计算新样本属于每一类的概率值，然后将其划分至概率最高的那一类。计算时我们发现有两个选择，一是直接代入各个高斯分布，计算概率密度函数值进行比较；二是在上一步的基础上乘上决定系数$\\alpha_i$再进行比较。正确的选择是第二种做法，我们可以这样理解，$\\alpha_i$代表样本由各个分布产生的概率，所以我们进行比较的时候不但要计算在各个分模型中产生这个样本的概率，还要计算样本来自这个模型的概率。\n",
    "\n",
    "用公式表示就是：\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    P(y=i) &= \\alpha_i \\phi(y|\\mu_i, \\Sigma_i) \\\\\n",
    "    \\\\\n",
    "    \\hat y &= \\underset{i}{argmax} P(y=i)\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验\n",
    "\n",
    "实验将采用自己生成的二维数据进行聚类。这样可以保证迭代过程中的结果可视化。生成一个有协方差的二维的正态分布还需要一定的算法，暂时就用相互独立的正态分布二维数组代替。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T12:23:01.581634Z",
     "start_time": "2019-04-21T12:23:01.571637Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T12:23:03.320529Z",
     "start_time": "2019-04-21T12:23:03.305529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.30482392,  0.21606989],\n",
       "       [-0.94140543, -0.12730699],\n",
       "       [ 0.17705639, -0.38788887],\n",
       "       [ 0.45808672, -0.25490274],\n",
       "       [-0.26954995,  0.27232996],\n",
       "       [ 1.23130143, -0.94938901],\n",
       "       [ 0.46884256,  0.47357112],\n",
       "       [-0.35954475,  0.16750242],\n",
       "       [-1.61170733, -1.59745802],\n",
       "       [-0.54005553, -0.44964589]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = [0,0]\n",
    "sigma = [[1,0.5], [0.5, 1]]\n",
    "np.random.multivariate_normal(mean=mu, cov=sigma, size=10)\n",
    "#help(np.random.multivariate_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T12:23:04.295373Z",
     "start_time": "2019-04-21T12:23:04.283375Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(2099)\n",
    "\n",
    "mu = [[-1,-1],[5,1],[1, 5]]\n",
    "sigma = [[[2, -0.5], [-0.5, 2]], [[1, 0.5], [0.5, 1]], [[1, 0.5], [0.5, 1]]]\n",
    "data = np.array([0, 0]).reshape(1, 2)\n",
    "for i in range(3):\n",
    "    points = np.random.multivariate_normal(mean=mu[i], cov=sigma[i], size=50)\n",
    "    data = np.vstack((data, points))\n",
    "\n",
    "data = np.delete(data, 0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T12:23:05.152240Z",
     "start_time": "2019-04-21T12:23:05.143253Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T12:23:06.010108Z",
     "start_time": "2019-04-21T12:23:05.984109Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15915494]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def pdf(x, mu, sigma) -> float:\n",
    "    \"\"\"\n",
    "    x: a p*1 dimensional row vector\n",
    "    mu: a p*1 dimensional row vector, representing mean vector\n",
    "    sigma: a p*p dimensional covariance matrix\n",
    "    return the value of probability density\n",
    "    \"\"\"\n",
    "    try:\n",
    "        p = x.shape[0]\n",
    "        x = np.reshape(x, (p, 1))\n",
    "    except AttributeError:\n",
    "        p = len(x)\n",
    "        x = np.reshape(x, (p, 1))\n",
    "    # print(x)\n",
    "    \n",
    "    # computation = 1/(2pi^p/2 + |sigma|^1/2)\n",
    "    computation = np.power(2*np.pi, -p/2)/np.power(np.linalg.det(sigma), 0.5)\n",
    "    \n",
    "    #tmp = -1/2 * (x-mu)' sigma^-1 (x-mu)\n",
    "    tmp = np.dot((x-mu).T, np.linalg.inv(sigma))\n",
    "    tmp = -np.dot(tmp, (x-mu))/2\n",
    "    \n",
    "    # computaion * exp(tmp)\n",
    "    computation *= np.exp(tmp)\n",
    "    \n",
    "    return computation\n",
    "\n",
    "x = np.array([0,0]).reshape(2, 1)\n",
    "mu = np.array([0,0]).reshape(2, 1)\n",
    "sigma = np.array([[1, 0], [0, 1]])\n",
    "\n",
    "pdf(x, mu, sigma) # 1/2pi = 0.15915494"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T12:23:06.971953Z",
     "start_time": "2019-04-21T12:23:06.962954Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize the parameters\n",
    "alpha = [0.2, 0.4, 0.4]\n",
    "n_cluster = 3\n",
    "cluster = {\n",
    "    0: [np.array([1, 1]).reshape((2,1)), np.array([[0.7, 0.3], [0.3, 0.7]])],\n",
    "    1: [np.array([2, 2]).reshape((2,1)), np.array([[0.6, 0.4], [0.4, 0.6]])],\n",
    "    2: [np.array([3, 3]).reshape((2, 1)), np.array([[0.8, 0.2], [0.2, 0.8]])]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T12:23:08.140769Z",
     "start_time": "2019-04-21T12:23:07.967796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.98303303e-01 1.69563363e-03 1.06380072e-06]\n",
      " [9.64788809e-01 3.51699019e-02 4.12891350e-05]\n",
      " [9.97068874e-01 2.93078738e-03 3.38509087e-07]\n",
      " [9.99344901e-01 6.54015171e-04 1.08366723e-06]\n",
      " [9.93503833e-01 6.49250110e-03 3.66545326e-06]\n",
      " [9.87699057e-01 1.22963470e-02 4.59577547e-06]\n",
      " [9.95014350e-01 4.98230459e-03 3.34555732e-06]\n",
      " [9.99566631e-01 6.70288573e-05 3.66339801e-04]\n",
      " [9.99342013e-01 2.33046654e-04 4.24939916e-04]\n",
      " [9.91193278e-01 8.80444879e-03 2.27334083e-06]]\n",
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "def e_step(alpha, cluster, x):\n",
    "    \"\"\"\n",
    "    alpha: probability efficient\n",
    "    cluster: a diction containing all the clusters' parameters\n",
    "    x: data to cluster\n",
    "    return: gamma: the i-th row and j-th column's element presents \n",
    "            the probability of i-th sample belong to j-th cluster\n",
    "    \"\"\"\n",
    "    n, p = x.shape\n",
    "    k = len(cluster)\n",
    "    \n",
    "    gamma = np.zeros((n, k))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(k):\n",
    "            prob = pdf(x[i,:].reshape((p,1)), mu=cluster[j][0], sigma=cluster[j][1])\n",
    "            # print(str(i)+\" + \"+str(j), prob)\n",
    "            gamma[i][j] = alpha[j]*prob\n",
    "    \n",
    "    gamma = gamma/np.sum(gamma, axis=1).reshape((n, 1))\n",
    "    \n",
    "    return gamma\n",
    "\n",
    "tmp = e_step(alpha, cluster, data)\n",
    "print(tmp[0:10, :])\n",
    "print(np.sum(tmp[0:10, :], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T12:23:08.980668Z",
     "start_time": "2019-04-21T12:23:08.967663Z"
    }
   },
   "outputs": [],
   "source": [
    "def m_step(gamma, x, cluster):\n",
    "    \"\"\"\n",
    "    gamma: the i-th row and j-th column's element presents \n",
    "        the probability of i-th sample belong to j-th cluster\n",
    "    x: data to be clustered\n",
    "    cluster: the parameters after i-th iteration\n",
    "    \"\"\"\n",
    "    n, p = x.shape\n",
    "    tmp = np.sum(gamma, axis=0)\n",
    "    # print(tmp)\n",
    "    alpha = tmp/np.sum(gamma)\n",
    "    for j in range(len(cluster)):\n",
    "        cluster[j][1] = np.dot((x-cluster[j][0].T).T, gamma[:,j].reshape((n, 1))*(x-cluster[j][0].T))/tmp[j]\n",
    "        \n",
    "        cluster[j][0] = np.sum(gamma[:,j].reshape((n, 1))*x, axis=0)/tmp[j]\n",
    "        cluster[j][0] = cluster[j][0].reshape((p, 1))\n",
    "    return alpha, cluster\n",
    "\n",
    "alpha, cluster = m_step(tmp, data, cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T12:23:09.927601Z",
     "start_time": "2019-04-21T12:23:09.919603Z"
    }
   },
   "outputs": [],
   "source": [
    "def diff(pre_cluster, now_cluster, pre_alpha, now_alpha):\n",
    "    n = len(pre_cluster)\n",
    "    ans = np.sum(np.power(pre_alpha-now_alpha, 2))\n",
    "    # print(pre_cluster)\n",
    "    # print(cluster)\n",
    "    for i in range(n):\n",
    "        ans += np.sum(np.power(pre_cluster[i][0]-now_cluster[i][0], 2))\n",
    "        # print(str(i)+\" 0 \",ans)\n",
    "        ans += np.sum(np.power(pre_cluster[i][1]-now_cluster[i][1], 2))\n",
    "        # print(str(i)+\" 1 \",ans)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T12:23:12.116257Z",
     "start_time": "2019-04-21T12:23:10.966437Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0.3, 0.3, 0.4]\n",
      "{0: [array([[1],\n",
      "       [1]]), array([[0.7, 0.3],\n",
      "       [0.3, 0.7]])], 1: [array([[3],\n",
      "       [1]]), array([[0.6, 0.4],\n",
      "       [0.4, 0.6]])], 2: [array([[1],\n",
      "       [3]]), array([[0.8, 0.2],\n",
      "       [0.2, 0.8]])]}\n",
      "1\n",
      "[0.25227719 0.36350805 0.38421476]\n",
      "{0: [array([[-0.94015085],\n",
      "       [-1.1290606 ]]), array([[4.89593644, 4.01957729],\n",
      "       [4.01957729, 5.68940975]])], 1: [array([[4.70871414],\n",
      "       [0.61540341]]), array([[5.17519599, 0.64406705],\n",
      "       [0.64406705, 1.58334871]])], 2: [array([[0.89842806],\n",
      "       [4.61334936]]), array([[2.21508384, 2.00289225],\n",
      "       [2.00289225, 5.6129532 ]])]}\n",
      "2\n",
      "[0.24464568 0.36575251 0.38960181]\n",
      "{0: [array([[-0.86593758],\n",
      "       [-1.05515292]]), array([[1.69655003, 0.06170443],\n",
      "       [0.06170443, 1.87307197]])], 1: [array([[4.60871231],\n",
      "       [0.65139321]]), array([[2.97672254, 1.17745608],\n",
      "       [1.17745608, 1.28086845]])], 2: [array([[0.88774234],\n",
      "       [4.44370289]]), array([[2.02107524, 2.27823698],\n",
      "       [2.27823698, 4.03496651]])]}\n",
      "3\n",
      "[0.26700211 0.35526294 0.37773495]\n",
      "{0: [array([[-0.98521171],\n",
      "       [-1.11675696]]), array([[ 1.32349644, -0.37350521],\n",
      "       [-0.37350521,  1.32485609]])], 1: [array([[4.80237017],\n",
      "       [0.69869504]]), array([[1.98990005, 1.00020222],\n",
      "       [1.00020222, 1.19318248]])], 2: [array([[0.99703685],\n",
      "       [4.66290127]]), array([[1.79657629, 1.87387114],\n",
      "       [1.87387114, 2.99022462]])]}\n",
      "4\n",
      "[0.28077156 0.35041641 0.36881203]\n",
      "{0: [array([[-1.00636274],\n",
      "       [-1.08959643]]), array([[ 1.29557787, -0.41314294],\n",
      "       [-0.41314294,  1.31581627]])], 1: [array([[4.87078048],\n",
      "       [0.72736487]]), array([[1.65115918, 0.86243967],\n",
      "       [0.86243967, 1.13671089]])], 2: [array([[1.07215276],\n",
      "       [4.7786724 ]]), array([[1.5862924 , 1.54464972],\n",
      "       [1.54464972, 2.44955624]])]}\n",
      "5\n",
      "[0.29234046 0.34776745 0.35989209]\n",
      "{0: [array([[-1.00141468],\n",
      "       [-1.02613192]]), array([[ 1.33007333, -0.42127979],\n",
      "       [-0.42127979,  1.41085396]])], 1: [array([[4.89869876],\n",
      "       [0.74110857]]), array([[1.55454714, 0.81568636],\n",
      "       [0.81568636, 1.11523891]])], 2: [array([[1.13593007],\n",
      "       [4.87265841]]), array([[1.42984723, 1.3282022 ],\n",
      "       [1.3282022 , 2.13125651]])]}\n",
      "6\n",
      "[0.30285185 0.34612402 0.35102413]\n",
      "{0: [array([[-0.99549571],\n",
      "       [-0.96016075]]), array([[ 1.34948086, -0.42251168],\n",
      "       [-0.42251168,  1.51241734]])], 1: [array([[4.91469605],\n",
      "       [0.74923524]]), array([[1.50624787, 0.79186007],\n",
      "       [0.79186007, 1.10468024]])], 2: [array([[1.19666867],\n",
      "       [4.96502316]]), array([[1.29195023, 1.13243311],\n",
      "       [1.13243311, 1.83392696]])]}\n",
      "7\n",
      "[0.31101438 0.34514693 0.34383869]\n",
      "{0: [array([[-0.99187738],\n",
      "       [-0.90720654]]), array([[ 1.35428311, -0.42151854],\n",
      "       [-0.42151854,  1.59394044]])], 1: [array([[4.92409084],\n",
      "       [0.75403664]]), array([[1.47850186, 0.77813978],\n",
      "       [0.77813978, 1.09868479]])], 2: [array([[1.24657157],\n",
      "       [5.04098486]]), array([[1.18007141, 0.96839   ],\n",
      "       [0.96839   , 1.58447978]])]}\n",
      "8\n",
      "[0.31618365 0.3446213  0.33919505]\n",
      "{0: [array([[-0.98954095],\n",
      "       [-0.87266519]]), array([[ 1.35251858, -0.41899638],\n",
      "       [-0.41899638,  1.64897974]])], 1: [array([[4.92914736],\n",
      "       [0.75660883]]), array([[1.46360767, 0.77080209],\n",
      "       [0.77080209, 1.09552903]])], 2: [array([[1.27906859],\n",
      "       [5.09017958]]), array([[1.10859062, 0.86041412],\n",
      "       [0.86041412, 1.42176609]])]}\n",
      "9\n",
      "[0.31881011 0.34436508 0.33682481]\n",
      "{0: [array([[-0.98790961],\n",
      "       [-0.85467979]]), array([[ 1.3503444 , -0.41630773],\n",
      "       [-0.41630773,  1.6790961 ]])], 1: [array([[4.93162549],\n",
      "       [0.75784638]]), array([[1.456287  , 0.76725423],\n",
      "       [0.76725423, 1.09405657]])], 2: [array([[1.29545734],\n",
      "       [5.11509079]]), array([[1.07391949, 0.80637937],\n",
      "       [0.80637937, 1.34019953]])]}\n",
      "10\n",
      "[0.31991401 0.3442455  0.33584049]\n",
      "{0: [array([[-0.98694482],\n",
      "       [-0.84707205]]), array([[ 1.34948278, -0.41466599],\n",
      "       [-0.41466599,  1.69244124]])], 1: [array([[4.93278582],\n",
      "       [0.75841755]]), array([[1.45285472, 0.76561303],\n",
      "       [0.76561303, 1.09339493]])], 2: [array([[1.30214902],\n",
      "       [5.12532948]]), array([[1.06032542, 0.78470299],\n",
      "       [0.78470299, 1.3072781 ]])]}\n",
      "11\n",
      "[0.32032975 0.34418926 0.33548099]\n",
      "{0: [array([[-0.9864485 ],\n",
      "       [-0.84426214]]), array([[ 1.34938284, -0.41393848],\n",
      "       [-0.41393848,  1.69752378]])], 1: [array([[4.93332989],\n",
      "       [0.75868827]]), array([[1.4512514 , 0.7648382 ],\n",
      "       [0.7648382 , 1.09307711]])], 2: [array([[1.30456233],\n",
      "       [5.12903786]]), array([[1.05555891, 0.77701115],\n",
      "       [0.77701115, 1.2955451 ]])]}\n",
      "12\n",
      "[0.32048042 0.34416221 0.33535737]\n",
      "{0: [array([[-0.98620637],\n",
      "       [-0.84329367]]), array([[ 1.34949385, -0.41366767],\n",
      "       [-0.41366767,  1.6992913 ]])], 1: [array([[4.93358985],\n",
      "       [0.75882146]]), array([[1.45049031, 0.76445933],\n",
      "       [0.76445933, 1.09291367]])], 2: [array([[1.30538618],\n",
      "       [5.13030685]]), array([[1.05395551, 0.77440962],\n",
      "       [0.77440962, 1.29156692]])]}\n",
      "13\n",
      "[0.32053515 0.34414898 0.33531587]\n",
      "{0: [array([[-0.98608919],\n",
      "       [-0.84297042]]), array([[ 1.34961029, -0.41357575],\n",
      "       [-0.41357575,  1.69987567]])], 1: [array([[4.93371614],\n",
      "       [0.75888824]]), array([[1.45012279, 0.76427034],\n",
      "       [0.76427034, 1.09282785]])], 2: [array([[1.3056617],\n",
      "       [5.1307319]]), array([[1.0534229 , 0.7735432 ],\n",
      "       [0.7735432 , 1.29023984]])]}\n"
     ]
    }
   ],
   "source": [
    "alpha = [0.3, 0.3, 0.4]\n",
    "n_cluster = 3\n",
    "cluster = {\n",
    "    0: [np.array([1, 1]).reshape((2,1)), np.array([[0.7, 0.3], [0.3, 0.7]])],\n",
    "    1: [np.array([3, 1]).reshape((2,1)), np.array([[0.6, 0.4], [0.4, 0.6]])],\n",
    "    2: [np.array([1, 3]).reshape((2, 1)), np.array([[0.8, 0.2], [0.2, 0.8]])]\n",
    "}\n",
    "dif, iteration = 1, 0\n",
    "\n",
    "while dif > 1e-6:\n",
    "    print(iteration)\n",
    "    iteration += 1\n",
    "    pre_cluster = copy.deepcopy(cluster) \n",
    "    pre_alpha = alpha.copy()\n",
    "    \n",
    "    print(alpha)\n",
    "    print(cluster)\n",
    "    \n",
    "    gamma = e_step(alpha, cluster, data)\n",
    "    # print(gamma)\n",
    "    alpha, cluster = m_step(gamma, data, cluster)\n",
    "    \n",
    "    dif = diff(pre_cluster, cluster, pre_alpha, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，对于有明显分类的数据来说，高斯混合模型效果还是很好的，而且需要的迭代数也较少。\n",
    "\n",
    "当数据较稠密不易分类时（比如均值为(1,1)(4,2)(2,4)时），则无论是迭代次数还是训练效果都会相应的打折扣\n",
    "\n",
    "先前设置的生成数据的方差就是括号内的均值，导致性能比现在差很多（有兴趣可以试一下）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T12:23:17.939823Z",
     "start_time": "2019-04-21T12:23:17.923839Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.05127712]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(cluster)\n",
    "belong = []\n",
    "print(data[0].shape)\n",
    "pdf(data[0], cluster[0][0], cluster[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T12:23:19.009660Z",
     "start_time": "2019-04-21T12:23:18.880676Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(data, cluster):\n",
    "    \"\"\"\n",
    "    data: data that needs clustered\n",
    "    cluster: a diction containing all the Gaussian cluster information\n",
    "    \"\"\"\n",
    "    n_cluster = len(cluster)\n",
    "    belong = []\n",
    "    for i in data:\n",
    "        prob = [pdf(i, cluster[j][0], cluster[j][1]) for j in range(n_cluster)]\n",
    "        belong.append(np.argmax(prob))\n",
    "    return belong\n",
    "\n",
    "index = predict(data, cluster)\n",
    "index = np.reshape(index, (data.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T12:23:20.410296Z",
     "start_time": "2019-04-21T12:23:19.917372Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(data[:, 0][np.where(index==0)[0]], data[:, 1][np.where(index==0)[0]], \"ro\", color=\"red\")\n",
    "plt.plot(data[:, 0][np.where(index==1)[0]], data[:, 1][np.where(index==1)[0]], \"ro\", color=\"green\")\n",
    "plt.plot(data[:, 0][np.where(index==2)[0]], data[:, 1][np.where(index==2)[0]], \"ro\", color=\"blue\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
